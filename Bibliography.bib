@book{asimov:WrongRel,
    Author={Asimov, Isaac},
    Title={The relativity of wrong},
    Subtitle={Essays on the Solar System and Beyond},
    Publisher = {Oxford University Press},
    Address = {Guernsey, Channels Islands, Great Britain},
    Year= {1989},
    ISBN={978-0-19-282632-9},
    Chapter={Beginning with Bone}
}

@book{lee:2006,
    Author={Lee, Mei-Ling},
    Title={Analysis of Microarray Gene Expression Data},
    Publisher={Springer},
    Place={New York},
    ISBN={978-0792370871},
    Year={2006}
}

@book{molBiolCell,
  Title     = {Molecular Biology of the Cell},
  Author    = {Alberts, Bruce and Johnson, Alexander and Lewis, Julian and
               Raff, Martin and Roberts, Keith and Walter, Peter},
  Abstract  = {Molecular Biology of the Cell is the classic in-depth text
               reference in cell biology. By extracting fundamental concepts
               and meaning from this enormous and ever-growing field, the
               authors tell the story of cell biology, and create a coherent
               framework through which non-expert readers may approach the
               subject. Written in clear and concise language, and illustrated
               with original drawings, the book is enjoyable to read, and
               provides a sense of the excitement of modern biology. Molecular
               Biology of the Cell not only sets forth the current
               understanding of cell biology (updated as of Fall 2001), but
               also explores the intriguing implications and possibilities of
               that which remains unknown.},
  Publisher = {Garland Science},
  Year      =  {2002},
  Language  = {en}
}

@book{biochbook,
  Title     = {Biochemistry},
  Author    = {Davidson, Victor L and Sittman, Donald B},
  Publisher = {Lippincott Williams \& Wilkins},
  Year      =  {1999},
  Language  = {en}
}

@book{BiomolBio,
  Title     = {Biochemistry and Molecular Biology},
  Author    = {Papachristodoulou, Despo and Snape, Alison and Elliott, William
               H and Elliott, Daphne C},
  Abstract  = {Now in its fifth edition Biochemistry and Molecular Biology
               features a new author team, who have retained the much-praised
               clarity of previous editions, while adding a more biomedical
               focus and incorporating a discussion of recent developments in
               research. A new chapter on the general principles of nutrition
               emphasises the key principles underlying complex metabolic
               pathways, enabling students to appreciate an integrated view of
               human metabolism and nutrition. Also new to the fifth edition, a
               chapter on the control of gene expression reflects our
               increasing understanding of the importance and power of gene
               regulation. With an integrated approach covering both
               biochemistry and molecular biology, complemented by frequent
               diagrams and clear explanations, and all presented in a broader
               cellular context, this text is the perfect introduction for any
               student new to the subject. Online Resource Centre: The Online
               Resource Centre features: For registered adopters of the book:
               Figures from the book available to download For students:
               Further reading organised by chapter, linked to the book via QR
               codes· An extensive bank of multiple-choice questions for
               self-directed learning · Links to 3D molecular structures},
  Publisher = {OUP Oxford},
  Year      = {2014},
  Language  = {en},
  Isbn      = {9780199609499}
}

@article{schwanhausserglobal:2011,
    Abstract = {Gene expression is a multistep process that involves the
        transcription, translation and turnover of messenger {RNAs} and proteins.
            Although it is one of the most fundamental processes of life, the
            entire cascade has never been quantified on a genome-wide scale.
            Here we simultaneously measured absolute {mRNA} and protein abundance
            and turnover by parallel metabolic pulse labelling for more than
            5,000 genes in mammalian cells. Whereas {mRNA} and protein levels
            correlated better than previously thought, corresponding half-lives
            showed no correlation. Using a quantitative model we have obtained the
            first genome-scale prediction of synthesis rates of {mRNAs} and
            proteins. We find that the cellular abundance of proteins is
            predominantly controlled at the level of translation. Genes with
            similar combinations of {mRNA} and protein stability shared functional
            properties, indicating that half-lives evolved under energetic and
            dynamic constraints. Quantitative information about all stages of
            gene expression provides a rich resource and helps to provide a
            greater understanding of the underlying design principles.},
    Author = {Schwanh{\"a}usser, Bj{\"o}rn and Busse, Dorothea and Li, Na and
        Dittmar, Gunnar and Schuchhardt, Johannes and Wolf, Jana and Chen, Wei
            and Selbach, Matthias},
    Title = {Global quantification of mammalian gene expression control.},
    Doi = {10.1038/nature10098},
    Journal = {Nature},
    Number = {7347},
    Pages = {337--342},
    Url = {http://dx.doi.org/10.1038/nature10098},
    Volume = {473},
    Year = {2011}
}

@article{licomparing:2015,
    Abstract = {Recently, rapid improvements in technology and decrease in sequencing
        costs have made {RNA-Seq} a widely used technique to quantify gene
            expression levels. Various normalization approaches have been proposed,
        owing to the importance of normalization in the analysis of {RNA-Seq} data.
            A comparison of recently proposed normalization methods is required to
            generate suitable guidelines for the selection of the most appropriate
            approach for future experiments.},
    Author = {Li, Peipei and Piao, Yongjun and Shon, Ho S and Ryu, Keun H},
    Doi = {10.1186/s12859-015-0778-7},
    Journal = {BMC Bioinformatics},
    Pages = {347},
    Title = {Comparing the normalization methods for the differential analysis
        of Illumina high-throughput {RNA-Seq} data.},
    Url = {http://dx.doi.org/10.1186/s12859-015-0778-7},
    Volume = {16},
    Year = {2015}
}

@article{vandamgenefriends:2014,
    Abstract = {Co-expression networks have proven effective at assigning putative
        functions to genes based on the functional annotation of their
            co-expressed partners, in candidate gene prioritization studies and in
            improving our understanding of regulatory networks. The growing number
            of genome resequencing efforts and genome-wide association studies
            often identify loci containing novel genes and there is a need to infer
            their functions and interaction partners. To facilitate this we have
            expanded {GeneFriends,} an online database that allows users to
            identify co-expressed genes with one or more user-defined genes. This
            expansion entails an {RNA-seq-based} co-expression map that includes
            genes and transcripts that are not present in the microarray-based
            co-expression maps, including over 10 000 non-coding {RNAs.}
        The results users obtain from {GeneFriends} include a co-expression network
            as well as a summary of the functional enrichment among the
            co-expressed genes. Novel insights can be gathered from this database
            for different splice variants and {ncRNAs,} such as {microRNAs} and
            {lincRNAs.} Furthermore, our updated tool allows candidate transcripts
        to be linked to diseases and processes using a guilt-by-association
            approach. {GeneFriends} is freely available from
            {http://www.GeneFriends.org} and can be used to quickly identify and
        rank candidate targets relevant to the process or disease under study.},
    Author = {van Dam, Sipko and Craig, Thomas and de Magalh{\~a}es, Jo{\~a}o P},
    Doi = {10.1093/nar/gku1042},
    Journal = {Nucleic Acids Research},
    Title = {{GeneFriends:} a human {RNA-seq-based} gene and transcript
        co-expression database.},
    Url = {http://dx.doi.org/10.1093/nar/gku1042},
    Year = {2014}
}

@article{rinnrna:2014,
    Author = {Rinn, John and Guttman, Mitchell},
    Doi = {10.1126/science.1252966},
    Journal = {Science},
    Number = {6202},
    Pages = {1240-1241},
    Title = {{RNA} Function. {RNA} and dynamic nuclear organization.},
    Url = {http://dx.doi.org/10.1126/science.1252966},
    Volume = {345},
    Year = {2014}
}

@article{aresmethods:2014,
    Abstract = {High-throughput sequencing {(HTS)} methods for analyzing {RNA}
            populations {(RNA-Seq)} are gaining rapid application to many
            experimental situations. The steps in an {RNA-Seq} experiment
            require thought and planning, especially because the expense in
            time and materials is currently higher and the protocols are far
            less routine than those used for other high-throughput methods,
            such as microarrays. As always, good experimental design will make
            analysis and interpretation easier. Having a clear biological
            question, an idea about the best way to do the experiment,
            and an understanding of the number of replicates needed will make
            the entire process more satisfying. Whether the goal is capturing
            transcriptome complexity from a tissue or identifying small
            fragments of {RNA} cross-linked to a protein of interest,
            conversion of the {RNA} to {cDNA} followed by direct sequencing
            using the latest methods is a developing practice, with new
            technical modifications and applications appearing every day.
            Even more rapid are the development and improvement of methods
            for analysis of the very large amounts of data that arrive at
            the end of an {RNA-Seq} experiment, making considerations regarding
            reproducibility, validation, visualization, and interpretation
            increasingly important. This introduction is designed to review and
            emphasize a pathway of analysis from experimental design through data
            presentation that is likely to be successful, with the recognition
            that better methods are right around the corner.},
    Author = {Ares, Manuel},
    Doi = {10.1101/pdb.top083352},
    Journal = {Cold Spring Harbor protocols},
    Number = {11},
    Pages = {pdb.top083352},
    Title = {Methods for processing high-throughput {RNA} sequencing data.},
    Url = {http://dx.doi.org/10.1101/pdb.top083352},
    Volume = {2014},
    Year = {2014}
}

@article{ramskoldan:2009,
    Abstract = {The parts of the genome transcribed by a cell or tissue reflect the
            biological processes and functions it carries out. We characterized
            the features of mammalian tissue transcriptomes at the gene level
            through analysis of {RNA} deep sequencing {(RNA-Seq)} data across
            human and mouse tissues and cell lines. We observed that
            roughly 8,000 protein-coding genes were ubiquitously expressed,
            contributing to around 75\% of all {mRNAs} by message copy number
            in most tissues. These {mRNAs} encoded proteins that were often
            intracellular, and tended to be involved in metabolism,
            transcription, {RNA} processing or translation. In contrast,
            genes for secreted or plasma membrane proteins were generally
            expressed in only a subset of tissues. The distribution of expression
            levels was broad but fairly continuous: no support was found for the
            concept of distinct expression classes of genes. Expression estimates
            that included reads mapping to coding exons only correlated better
            with {qRT-PCR} data than estimates which also included 3'
            untranslated regions {(UTRs).} Muscle and liver had the least
            complex transcriptomes, in that they expressed predominantly
            ubiquitous genes and a large fraction of the transcripts came from a
            few highly expressed genes, whereas brain, kidney and testis
            expressed more complex transcriptomes with the vast majority of
            genes expressed and relatively small contributions from the most
            expressed genes. {mRNAs} expressed in brain had unusually long
            {3'UTRs,} and mean {3'UTR} length was higher for genes involved in
            development, morphogenesis and signal transduction, suggesting added
            complexity of {UTR-based} regulation for these genes. Our results
            support a model in which variable exterior components feed into a
            large, densely connected core composed of ubiquitously expressed
            intracellular proteins.},
    Author = {Ramsk{\"o}ld, Daniel and Wang, Eric T and Burge,
        Christopher B and Sandberg, Rickard},
    Doi = {10.1371/journal.pcbi.1000598},
    Journal = {PLoS Computational Biology},
    Number = {12},
    Pages = {e1000598},
    Title = {An abundance of ubiquitously expressed genes revealed by tissue
        transcriptome sequence data.},
    Url = {http://dx.doi.org/10.1371/journal.pcbi.1000598},
    Volume = {5},
    Year = {2009}
}

@article {Uhlen:2016,
    Author = {Uhl{\'e}n, Mathias and Hallstr{\"o}m, Bj{\"o}rn M and Lindskog,
        Cecilia and Mardinoglu, Adil and Pont{\'e}n, Fredrik and Nielsen, Jens},
    Title = {Transcriptomics resources of human tissues and~organs},
    Volume = {12},
    Number = {4},
    Year = {2016},
    Doi = {10.15252/msb.20155865},
    Abstract = {Quantifying the differential expression of genes in various
        human organs, tissues, and cell types is vital to understand human
        physiology and disease. Recently, several large-scale transcriptomics
        studies have analyzed the expression of protein-coding genes across
        tissues. These datasets provide a framework for defining the
        molecular constituents of the human body as well as for generating
        comprehensive lists of proteins expressed across tissues or in a
        tissue-restricted manner. Here, we review publicly available human
        transcriptome resources and discuss body-wide data from independent
        genome-wide transcriptome analyses of different tissues.
        Gene expression measurements from these independent datasets,
        generated using samples from fresh frozen surgical specimens and
        postmortem tissues, are consistent. Overall, the different
        genome-wide analyses support a distribution in which many proteins
        are found in all tissues and relatively few in a tissue-restricted
        manner. Moreover, we discuss the applications of publicly available
        omics data for building genome-scale metabolic models, used for
        analyzing cell and tissue functions both in physiological and in
        disease contexts. Mol Syst Biol. (2016) 12: 862},\\
    Issn = {1744-4292},
    URL = {http://msb.embopress.org/content/12/4/862},
    Eprint = {http://msb.embopress.org/content/12/4/862.full.pdf},
    Journal = {Molecular Systems Biology}
}

@article{Crick:1958,
    Author = {Crick, Francis},
    Title = {Central Dogma of Molecular Biology},
    Journal = {Nature},
    Volume = {227},
    Year = {1970},
    Pages = {561-563}
}

@article{Hebenstreit:2011,
    Author = {Hebenstreit, Daniel and Fang, Miaoqing and Gu, Muxin and
        Charoensawan, Varodom and van Oudenaarden, Alexander and
            Teichmann, Sarah A},
    Title = {RNA sequencing reveals two major classes of gene expression levels
        in metazoan cells},
    Volume = {7},
    Number = {1},
    Year = {2011},
    Doi = {10.1038/msb.2011.28},
    Abstract = {The expression level of a gene is often used as a proxy for
        determining whether the protein or RNA product is functional in a cell
        or tissue. Therefore, it is of fundamental importance to understand
        the global distribution of gene expression levels, and to be able to
        interpret it mechanistically and functionally. Here we use RNA
        sequencing (RNA-seq) of mouse Th2 cells, coupled with a range of
        other techniques, to show that all genes can be separated, based on
        their expression abundance, into two distinct groups: one group
        comprised of lowly expressed and putatively non-functional mRNAs,
        and the other of highly expressed mRNAs
        with active chromatin marks at their promoters.
        These observations are confirmed in many other microarray and
        RNA-seq data sets of metazoan cell types. Mol Syst Biol. 7: 497},
    Issn = {1744-4292},
    URL = {http://msb.embopress.org/content/7/1/497},
    Eprint = {http://msb.embopress.org/content/7/1/497.full.pdf},
    Journal = {Molecular Systems Biology}
}

@article{ProteomeXchange:2014,
    PMID={PMID:24727771},
    Title = {ProteomeXchange provides globally coordinated proteomics data
        submission and dissemination},
    Author = {Vizcaíno, Juan A and Deutsch, Eric W and Wang, Rui and Csordas,
        Attila and Reisinger, Florian and Ríos, Daniel and Dianes, José A and
            Sun, Zhi and Farrah, Terry and Bandeira, Nuno and Binz, Pierre-Alain
            and Xenarios, Ioannis and Eisenacher, Martin and Mayer, Gerhard and
            Gatto, Laurent and Campos, Alex and Chalkley, Robert J and Kraus,
        Hans-Joachim and Albar, Juan Pablo and Martinez-Bartolomé, Salvador and
            Apweiler, Rolf and Omenn, Gilbert S and Martens, Lennart and Jones,
        Andrew R and Hermjakob, Henning},
    DOI = {10.1038/nbt.2839},
    Number = {3},
    Volume = {32},
    Month = {03},
    Year = {2014},
    Journal = {Nature Biotechnology},
    ISSN = {1087-0156},
    Pages = {223—226},
    URL = {http://europepmc.org/articles/PMC3986813}
}

@article{Pride:2016,
    Author = {Vizcaíno, Juan Antonio and Csordas, Attila and del-Toro, Noemi
        and Dianes, José A. and Griss, Johannes and Lavidas, Ilias and Mayer,
        Gerhard and Perez-Riverol, Yasset and Reisinger, Florian and Ternent,
        Tobias and Xu, Qing-Wei and Wang, Rui and Hermjakob, Henning},
    Title = {2016 update of the PRIDE database and its related tools},
    Volume = {44},
    Number = {D1},
    Pages = {D447-D456},
    Year = {2016},
    Doi = {10.1093/nar/gkv1145},
    Abstract ={The PRoteomics IDEntifications (PRIDE) database is one of the
        world-leading data repositories of mass spectrometry (MS)-based
            proteomics data. Since the beginning of 2014, PRIDE Archive
            (http://www.ebi.ac.uk/pride/archive/) is the new PRIDE archival
            system, replacing the original PRIDE database. Here we summarize
            the developments in PRIDE resources and related tools since the
            previous update manuscript in the Database Issue in 2013. PRIDE
            Archive constitutes a complete redevelopment of the original PRIDE,
            comprising a new storage backend, data submission system and web
            interface, among other components. PRIDE Archive supports the
            most-widely used PSI (Proteomics Standards Initiative) data
            standard formats (mzML and mzIdentML) and implements the data
            requirements and guidelines of the ProteomeXchange Consortium.
            The wide adoption of ProteomeXchange within the community has
            triggered an unprecedented increase in the number of submitted data
            sets (around 150 data sets per month). We outline some statistics
            on the current PRIDE Archive data contents. We also report on the
            status of the PRIDE related stand-alone tools: PRIDE Inspector,
            PRIDE Converter 2 and the ProteomeXchange submission tool. Finally,
            we will give a brief update on the resources under development
            ‘PRIDE Cluster’ and ‘PRIDE Proteomes’, which provide a complementary
            view and quality-scored information of the peptide and protein
            identification data available in PRIDE Archive.},
    URL = {http://nar.oxfordjournals.org/content/44/D1/D447.abstract},
    Eprint = {http://nar.oxfordjournals.org/content/44/D1/D447.full.pdf+html},
    Journal = {Nucleic Acids Research}
}

@article{SciRep2016,
    Author = {Kosti, Idit and Jain,Nishant and Aran, Dvir and  Butte, Atul J.
        and Sirota, Marina},
    Journal = {Scientific Reports},
    Day = {04},
    Month= {05},
    Year = {2016},
    Volume = {6},
    Pages = {24799ep},
    DOI = {http://dx.doi.org/10.1038/srep24799},
    Url  = {http://www.nature.com/articles/srep24799#supplementary-information},
    Title = {Cross-tissue Analysis of Gene and Protein Expression in Normal and
        Cancer Tissues}
}

@article{numbermRNA,
    Annote = {10.1038/70487},
    Author = {Velculescu, Victor E and Madden, Stephen L and Zhang, Lin and
        Lash, Alex E and Yu, Jian and Rago, Carlo and Lal, Anita and
            Wang, Clarence J and Beaudry, Gary A and Ciriello, Kristin M and
            Cook, Brian P and Dufault, Michael R and Ferguson, Anne T and
            Gao, Yuhong and He, Tong-Chuan and Hermeking, Heiko and
            Hiraldo, Siewleng K and Hwang, Paul M and Lopez, Marissa A and
            Luderer, Hilary F and Mathews, Brynna and Petroziello, Joseph M and
            Polyak, Kornelia and Zawel, Leigh and Zhang, Wen and Zhang, Xiaoming
            and Zhou, Wei and Haluska, Frank G and Jen, Jin and
            Sukumar, Saraswati and Landes, Gregory M and Riggins, Gregory J and
            Vogelstein, Bert and Kinzler, Kenneth W},
    Date = {1999/12//print},
    Journal = {Nature Genetics},
    URL = {http://www.nature.com/ng/journal/v23/n4/suppinfo/ng1299_387b_S1.html},
    M3 = {10.1038/70487},
    Month = {12},
    Number = {4},
    Pages = {387--388},
    Title = {Analysis of human transcriptomes},
    DOI = {http://dx.doi.org/10.1038/70487},
    Volume = {23},
    Year = {1999}
}

@article{castleData,
    Author = {Castle, John C. and Armour, Christopher D. and Löwer, Martin and
        Haynor, David and Biery, Matthew and Bouzek, Heather and Chen, Ronghua and
            Jackson, Stuart and Johnson, Jason M. and Rohl, Carol A. and
            Raymond, Christopher K.},
    Journal = {PLOS ONE},
    Title = {Digital Genome-Wide ncRNA Expression, Including SnoRNAs, across 11
        Human Tissues Using PolyA-Neutral Amplification},
    Year = {2010},
    Month = {07},
    Volume = {5},
    Url = {http://dx.doi.org/10.1371%2Fjournal.pone.0011779},
    Pages = {1-9},
    Abstract = {Non-coding RNAs (ncRNAs) are an essential class of molecular
        species that have been difficult to monitor on high throughput platforms
            due to frequent lack of polyadenylation. Using a
            polyadenylation-neutral amplification protocol and next-generation
            sequencing, we explore ncRNA expression in eleven human tissues.
            ncRNAs 7SL, U2, 7SK, and HBII-52 are expressed at levels far
            exceeding mRNAs. C/D and H/ACA box snoRNAs are associated with rRNA
            methylation and pseudouridylation, respectively: spleen expresses
            both, hypothalamus expresses mainly C/D box snoRNAs, and testes show
            enriched expression of both H/ACA box snoRNAs and RNA telomerase TERC.
            Within the snoRNA 14q cluster, 14q(I-6) is expressed at much higher
            levels than other cluster members. More reads align to mitochondrial
            than nuclear tRNAs. Many lincRNAs are actively transcribed,
        particularly those overlapping known ncRNAs. Within the Prader-Willi
            syndrome loci, the snoRNA HBII-85 (group I) cluster is highly
            expressed in hypothalamus, greater than in other tissues and greater
            than group II or III. Additionally, within the disease locus we find
            novel transcription across a 400,000 nt span in ovaries.
            This genome-wide polyA-neutral expression compendium demonstrates
            the richness of ncRNA expression, their high expression patterns,
        their function-specific expression patterns, and is publicly available.},
    Number = {7},
    DOI = {10.1371/journal.pone.0011779}
}

@article{Burge,
    Author={Wang, Eric T. and Sandberg, Rickard and Sandberg, Rickard and
        Sandberg, Rickard and Zhang, Lu and Mayr, Christine and
            Kingsmore, Stephen F. and
        Schroth, Gary P. and Burge, Christopher B.},
    Journal={Nature},
    Title={Alternative isoform regulation in human tissue transcriptomes},
    Abstract={Through alternative processing of pre-messenger RNAs, individual
        mammalian genes often produce multiple mRNA and protein isoforms that may
        have related, distinct or even opposing functions. Here we report an
        in-depth analysis of 15 diverse human tissue and cell line transcriptomes
        on the basis of deep sequencing of complementary DNA fragments, yielding
        a digital inventory of gene and mRNA isoform expression. Analyses in which
        sequence reads are mapped to exon–exon junctions indicated that 92–94\% of
        human genes undergo alternative splicing, ~86\% with a minor isoform
        frequency of 15\% or more. Differences in isoform-specific read densities
        indicated that most alternative splicing and alternative cleavage and
        polyadenylation events vary between tissues, whereas variation between
        individuals was approximately twofold to threefold less common. Extreme
        or ‘switch-like’ regulation of splicing between tissues was associated
        with increased sequence conservation in regulatory regions and with
        generation of full-length open reading frames. Patterns of alternative
        splicing and alternative cleavage and polyadenylation were strongly
        correlated across tissues, suggesting coordinated regulation of these
        processes, and sequence conservation of a subset of known regulatory
        motifs in both alternative introns and 3′ untranslated regions suggested
        common involvement of specific factors in tissue-level regulation of both
        splicing and polyadenylation.},
    Year={2008},
    Month={11},
    Day={27},
    Volume={456},
    Issue={7221},
    Pages={470--476},
    DOI={http://dx.doi.org/10.1038/nature07509},
    Url={http://www.nature.com/nature/journal/v456/n7221/suppinfo/nature07509_S1.html}
}

@manual{illuminaBM,
    Author={Illumina},
    Title={Considerations for Designing a Successful TruSeq{\textregistered}
        Targeted RNA Expression Experiment},
    Year={2013},
    Url={http://www.illumina.com/content/dam/illumina-marketing/documents/products/technotes/truseq_targ_rna_design.pdf}
}

@article{Armour:2009,
    Author = {Armour, Christopher D and Castle, John C and Chen, Ronghua and
        Babak, Tomas and Loerch, Patrick and Jackson, Stuart and Shah, Jyoti K and
            Dey, John and Rohl, Carol A and Johnson, Jason M and
            Raymond, Christopher K},
    Journal = {Nature Methods},
    Month = {09},
    Number = {9},
    Pages = {647--649},
    Title = {Digital transcriptome profiling using selective hexamer priming for
        cDNA synthesis},
    Doi = {http://dx.doi.org/10.1038/nmeth.1360},
    Volume = {6},
    Year = {2009}
}

@article{VTpaper,
    Title       = {The evolution of gene expression levels in mammalian organs},
    Author      = {Brawand, David and Soumillon, Magali and Necsulea, Anamaria
                 and Julien, Philippe and Cs{\'a}rdi, G{\'a}bor and Harrigan,
                 Patrick and Weier, Manuela and Liechti, Ang{\'e}lica and
                 Aximu-Petri, Ayinuer and Kircher, Martin and Albert, Frank W
                 and Zeller, Ulrich and Khaitovich, Philipp and Gr{\"u}tzner,
                 Frank and Bergmann, Sven and Nielsen, Rasmus and
                 P{\"a}{\"a}bo, Svante and Kaessmann, Henrik},
    Abstract    = {Changes in gene expression are thought to underlie many of the
                 phenotypic differences between species. However, large-scale
                 analyses of gene expression evolution were until recently
                 prevented by technological limitations. Here we report the
                 sequencing of polyadenylated RNA from six organs across ten
                 species that represent all major mammalian lineages
                 (placentals, marsupials and monotremes) and birds (the
                 evolutionary outgroup), with the goal of understanding the
                 dynamics of mammalian transcriptome evolution. We show that
                 the rate of gene expression evolution varies among organs,
                 lineages and chromosomes, owing to differences in selective
                 pressures: transcriptome change was slow in nervous tissues
                 and rapid in testes, slower in rodents than in apes and
                 monotremes, and rapid for the X chromosome right after its
                 formation. Although gene expression evolution in mammals was
                 strongly shaped by purifying selection, we identify numerous
                 potentially selectively driven expression switches, which
                 occurred at different rates across lineages and tissues and
                 which probably contributed to the specific organ biology of
                 various mammals.},
    Journal     = {Nature},
    Volume      = {478},
    Number      = {7369},
    Pages       = {343--348},
    Month       = {10},
    Year        = {2011},
    Language    = {en}
}

@article{Merkin:2012,
    Author={Merkin, Jason and Russell, Caitlin and Chen, Ping and Burge, Christopher B},
    Title={Evolutionary dynamics of gene and isoform regulation in Mammalian tissues.},
    Journal={Science},
    Year={2012},
    Abstract={Most mammalian genes produce multiple distinct messenger {RNAs}
        through alternative splicing, but the extent of splicing conservation is
            not clear. To assess tissue-specific transcriptome variation across
            mammals, we sequenced complementary {DNA} from nine tissues from four
            mammals and one bird in biological triplicate, at unprecedented
            depth. We find that while tissue-specific gene expression programs
            are largely conserved, alternative splicing is well conserved in only
            a subset of tissues and is frequently lineage-specific. Thousands of
            previously unknown, lineage-specific, and conserved alternative exons
            were identified; widely conserved alternative exons had signatures of
            binding by {MBNL,} {PTB,} {RBFOX,} {STAR,} and {TIA} family splicing
            factors, implicating them as ancestral mammalian splicing regulators.
            Our data also indicate that alternative splicing often alters protein
            phosphorylatability, delimiting the scope of kinase signaling.},
    Doi={10.1126/science.1228186},
    Pages={1593-9},
    Pmid={23258891},
    Volume={338},
    Number={6114},
    Issn={0036-8075},
    Pmcid={PMC3568499}
}

@article{ibmrelatedpaper,
    Author={Barbosa-Morais, Nuno L and Irimia, Manuel and Pan, Qun and
        Xiong, Hui Y and Gueroussov, Serge and Lee, Leo J and
            Slobodeniuc, Valentina and Kutter, Claudia and Watt, Stephen and
            Colak, Recep and Kim, TaeHyung and Misquitta-Ali, Christine M and
            Wilson, Michael D and Kim, Philip M and Odom, Duncan T and
            Frey, Brendan J and Blencowe, Benjamin J},
    Abstract={How species with similar repertoires of protein-coding genes
        differ so markedly at the phenotypic level is poorly understood.
            By comparing organ transcriptomes from vertebrate species spanning
            about 350 million years of evolution, we observed significant
            differences in alternative splicing complexity between vertebrate
            lineages, with the highest complexity in primates.
            Within 6 million years, the splicing profiles of physiologically
            equivalent organs diverged such that they are more strongly related
            to the identity of a species than they are to organ type. Most
            vertebrate species-specific splicing patterns are cis-directed.
            However, a subset of pronounced splicing changes are predicted to
            remodel protein interactions involving trans-acting regulators.
            These events likely further contributed to the diversification of
            splicing and other transcriptomic changes that underlie phenotypic
            differences among vertebrate species.},
    Title={The evolutionary landscape of alternative splicing in vertebrate species.},
    Journal={Science},
    Year={2012},
    Volume={338},
    Number={6114},
    Pages={1587-93},
    Doi={10.1126/science.1230612},
    Pmid={23258890},
    issn={0036-8075}
}

@article{DNA1953,
    Author={Watson, J D and Crick, F H},
    Title= {Molecular structure of nucleic acids; a structure for deoxyribose
        nucleic acid},
    Journal={Nature},
    Volume={171},
    Number={4356},
    Pages={737--738},
    Month={04},
    Year={1953}
}

@article{annotationDiff,
  Title    = {Comparison of {GENCODE} and {RefSeq} gene annotation and the
              impact of reference geneset on variant effect prediction},
  Author   = {Frankish, Adam and Uszczynska, Barbara and Ritchie, Graham R S
              and Gonzalez, Jose M and Pervouchine, Dmitri and Petryszak,
              Robert and Mudge, Jonathan M and Fonseca, Nuno and Brazma, Alvis
              and Guigo, Roderic and Harrow, Jennifer},
  Abstract = {BACKGROUND: A vast amount of DNA variation is being identified by
              increasingly large-scale exome and genome sequencing projects. To
              be useful, variants require accurate functional annotation and a
              wide range of tools are available to this end. McCarthy et al
              recently demonstrated the large differences in prediction of
              loss-of-function (LoF) variation when RefSeq and Ensembl
              transcripts are used for annotation, highlighting the importance
              of the reference transcripts on which variant functional
              annotation is based. RESULTS: We describe a detailed analysis of
              the similarities and differences between the gene and transcript
              annotation in the GENCODE and RefSeq genesets. We demonstrate
              that the GENCODE Comprehensive set is richer in alternative
              splicing, novel CDSs, novel exons and has higher genomic coverage
              than RefSeq, while the GENCODE Basic set is very similar to
              RefSeq. Using RNAseq data we show that exons and introns unique
              to one geneset are expressed at a similar level to those common
              to both. We present evidence that the differences in gene
              annotation lead to large differences in variant annotation where
              GENCODE and RefSeq are used as reference transcripts, although
              this is predominantly confined to non-coding transcripts and UTR
              sequence, with at most ~30\% of LoF variants annotated
              discordantly. We also describe an investigation of dominant
              transcript expression, showing that it both supports the utility
              of the GENCODE Basic set in providing a smaller set of more
              highly expressed transcripts and provides a useful,
              biologically-relevant filter for further reducing the complexity
              of the transcriptome. CONCLUSIONS: The reference transcripts
              selected for variant functional annotation do have a large effect
              on the outcome. The GENCODE Comprehensive transcripts contain
              more exons, have greater genomic coverage and capture many more
              variants than RefSeq in both genome and exome datasets, while the
              GENCODE Basic set shows a higher degree of concordance with
              RefSeq and has fewer unique features. We propose that the GENCODE
              Comprehensive set has great utility for the discovery of new
              variants with functional potential, while the GENCODE Basic set
              is more suitable for applications demanding less complex
              interpretation of functional variants.},
  Journal  = {BMC Genomics},
  Volume   = {16 Suppl 8},
  Pages    = {S2},
  Month    =  {06},
  Year     =  {2015},
  Language = {en}
}

% Uhlén first paper
@article{Uhlen2014,
  Title       = {Analysis of the human tissue-specific expression by
                 genome-wide integration of transcriptomics and antibody-based
                 proteomics},
  Author      = {Fagerberg, Linn and Hallstr{\"o}m, Bj{\"o}rn M and Oksvold,
                 Per and Kampf, Caroline and Djureinovic, Dijana and Odeberg,
                 Jacob and Habuka, Masato and Tahmasebpoor, Simin and
                 Danielsson, Angelika and Edlund, Karolina and Asplund, Anna
                 and Sj{\"o}stedt, Evelina and Lundberg, Emma and Szigyarto,
                 Cristina Al-Khalili and Skogs, Marie and Takanen, Jenny
                 Ottosson and Berling, Holger and Tegel, Hanna and Mulder, Jan
                 and Nilsson, Peter and Schwenk, Jochen M and Lindskog, Cecilia
                 and Danielsson, Frida and Mardinoglu, Adil and Sivertsson, Asa
                 and von Feilitzen, Kalle and Forsberg, Mattias and Zwahlen,
                 Martin and Olsson, Ingmarie and Navani, Sanjay and Huss,
                 Mikael and Nielsen, Jens and Ponten, Fredrik and Uhl{\'e}n,
                 Mathias},
  Abstract    = {Global classification of the human proteins with regards to
                 spatial expression patterns across organs and tissues is
                 important for studies of human biology and disease. Here, we
                 used a quantitative transcriptomics analysis (RNA-Seq) to
                 classify the tissue-specific expression of genes across a
                 representative set of all major human organs and tissues and
                 combined this analysis with antibody-based profiling of the
                 same tissues. To present the data, we launch a new version of
                 the Human Protein Atlas that integrates RNA and protein
                 expression data corresponding to ∼80\% of the human
                 protein-coding genes with access to the primary data for both
                 the RNA and the protein analysis on an individual gene level.
                 We present a classification of all human protein-coding genes
                 with regards to tissue-specificity and spatial expression
                 pattern. The integrative human expression map can be used as a
                 starting point to explore the molecular constituents of the
                 human body.},
  Journal     = {Molecular \& Cellullar Proteomics},
  Volume      =  {13},
  Number      =  {2},
  Pages       = {397--406},
  Month       =  {02},
  Year        =  {2014},
  Language    = {en}
}

%Uhlen second paper
@article{Uhlen2015,
  Title   = {Tissue-based map of the human proteome},
  Author = {Uhl{\'e}n, Mathias and Fagerberg, Linn and
            Hallstr{\"o}m, Bj{\"o}rn M. and Lindskog, Cecilia and
            Oksvold, Per and Mardinoglu, Adil and Sivertsson, {\r A}sa and
            Kampf, Caroline and Sj{\"o}stedt, Evelina and Asplund, Anna and
            Olsson, IngMarie and Edlund, Karolina and Lundberg, Emma and
            Navani, Sanjay and Szigyarto, Cristina Al-Khalili and
            Odeberg, Jacob and Djureinovic, Dijana and
            Takanen, Jenny Ottosson and Hober, Sophia and Alm, Tove and
            Edqvist, Per-Henrik and Berling, Holger and Tegel, Hanna and
            Mulder, Jan and Rockberg, Johan and Nilsson, Peter and
            Schwenk, Jochen M. and Hamsten, Marica and von Feilitzen, Kalle
            and Forsberg, Mattias and Persson, Lukas and
            Johansson, Fredric and Zwahlen, Martin and
            von Heijne, Gunnar and Nielsen, Jens and Pont{\'e}n, Fredrik},
  Volume = {347},
  Number = {6220},
  Year = {2015},
  Doi = {10.1126/science.1260419},
  Publisher = {American Association for the Advancement of Science},
  Abstract = {Sequencing the human genome gave new insights into human biology and disease.
      However, the ultimate goal is to understand the dynamic expression of each
          of the approximately 20,000 protein-coding genes and the function of
          each protein. Uhl{\'e}n et al. now present a map of protein expression
          across 32 human tissues. They not only measured expression at an RNA
          level, but also used antibody profiling to precisely localize the
          corresponding proteins. An interactive website allows exploration of
          expression patterns across the human body. Resolving the molecular
          details of proteome variation in the different tissues and organs of
          the human body would greatly increase our knowledge of human biology
          and disease. Here, we present a map of the human tissue proteome based
          on quantitative transcriptomics on a tissue and organ level combined
          with protein profiling using microarray-based immunohistochemistry to
          achieve spatial localization of proteins down to the single-cell level.
          We provide a global analysis of the secreted and membrane proteins, as
          well as an analysis of the expression profiles for all proteins
          targeted by pharmaceutical drugs and proteins implicated in cancer.
          RATIONALE We have used an integrative omics approach to study the
          spatial human proteome. Samples representing all major tissues and
          organs (n = 44) in the human body have been analyzed based on 24,028
          antibodies corresponding to 16,975 protein-encoding genes,
      complemented with RNA-sequencing data for 32 of the tissues. The antibodies
          have been used to produce more than 13 million tissue-based
          immunohistochemistry images, each annotated by pathologists for all
          sampled tissues. To facilitate integration with other biological
          resources, all data are available for download and cross-referencing.
          RESULTS: We report a genome-wide analysis of the tissue specificity of
          RNA and protein expression covering more than 90\% of the putative
          protein-coding genes, complemented with analyses of various subproteomes,
          such as predicted secreted proteins (n = 3171) and membrane-bound
          proteins (n = 5570). The analysis shows that almost half of the genes
          are expressed in all analyzed tissues, which suggests that the gene
          products are needed in all cells to maintain
          {\textquotedblleft}housekeeping{\textquotedblright} functions such as
      cell growth, energy generation, and basic metabolism. Furthermore, there is
          enrichment in metabolism among these genes, as 60\% of all metabolic
          enzymes are expressed in all analyzed tissues. The largest number of
          tissue-enriched genes is found in the testis, followed by the brain
          and the liver. Analysis of the 618 proteins targeted by clinically
          approved drugs unexpectedly showed that 30\% are expressed in all
          analyzed tissues. An analysis of metabolic activity based on
          genome-scale metabolic models (GEMS) revealed liver as the most
          metabolically active tissue, followed by adipose tissue and skeletal
          muscle.
          CONCLUSIONSA freely available interactive resource is presented as
          part of the Human Protein Atlas portal (www.proteinatlas.org),
          offering the possibility to explore the tissue-elevated proteomes
          in tissues and organs and to analyze tissue profiles for specific
          protein classes. Comprehensive lists of proteins expressed at elevated
          levels in the different tissues have been compiled to provide a spatial
          context with localization of the proteins in the subcompartments of
          each tissue and organ down to the single-cell level.The human
          tissue{\textendash}enriched proteins.All tissue-enriched proteins are
          shown for 13 representative tissues or groups of tissues, stratified
          according to their predicted subcellular localization. Enriched
          proteins are mainly intracellular in testis, mainly membrane bound in
          brain and kidney, and mainly secreted in pancreas and liver.Resolving
          the molecular details of proteome variation in the different tissues
          and organs of the human body will greatly increase our knowledge of
          human biology and disease. Here, we present a map of the human tissue
          proteome based on an integrated omics approach that involves
          quantitative transcriptomics at the tissue and organ level, combined
          with tissue microarray{\textendash}based immunohistochemistry, to
          achieve spatial localization of proteins down to the single-cell
          level. Our tissue-based analysis detected more than 90\% of the
          putative protein-coding genes. We used this approach to explore
          the human secretome, the membrane proteome, the druggable proteome,
          the cancer proteome, and the metabolic functions in 32 different
          tissues and organs. All the data are integrated in an interactive
          Web-based database that allows exploration of individual proteins,
          as well as navigation of global expression patterns, in all major
         tissues and organs in the human body.},
  Issn = {0036-8075},
  URL = {http://science.sciencemag.org/content/347/6220/1260419},
  Eprint = {http://science.sciencemag.org/content/347/6220/1260419.full.pdf},
  Journal = {Science}
}

%Gtex - presentation paper
@article{GTEx2013,
  Title       = {The {Genotype-Tissue} Expression ({GTEx}) project},
  Author      = {{GTEx Consortium}},
  Abstract    = {Genome-wide association studies have identified thousands of
                 loci for common diseases, but, for the majority of these, the
                 mechanisms underlying disease susceptibility remain unknown.
                 Most associated variants are not correlated with
                 protein-coding changes, suggesting that polymorphisms in
                 regulatory regions probably contribute to many disease
                 phenotypes. Here we describe the Genotype-Tissue Expression
                 (GTEx) project, which will establish a resource database and
                 associated tissue bank for the scientific community to study
                 the relationship between genetic variation and gene expression
                 in human tissues.},
  Journal     = {Nature Genetics},
  Publisher   = {Nature Research},
  Volume      =  {45},
  Number      =  {6},
  Pages       = {580--585},
  Month       =  {06},
  Year        =  {2013},
  Language    = {en}
}

%Gtex - Transcriptomic paper
@article{GTExTranscript,
    Title   =   {The human transcriptome across tissues and individuals},
    Author  =   {Mel{\'e}, Marta and Ferreira, Pedro G. and Reverter, Ferran and
            DeLuca, David S. and Monlong, Jean and Sammeth, Michael and
            Young, aTaylor R. and Goldmann, Jakob M and
            Pervouchine, Dmitri D. and  Sullivan, Timothy J. and
            Johnson, Rory and S{\'e}gr{\`e}, Ayellet V. and Djebali, Sarah and
            Niarchou, Anastasia and The GTEx Consortium and Wright, Fred A. and
            Lappalainen, Tuuli and Calvo, Miquel and Getz, Gad and
            Dermitzakis, Emmanouil T. and Ardlie, Kristin G. and
            Guig{\'o}, Roderic},
    Abstract={Transcriptional regulation and posttranscriptional processing
        underlie many cellular and organismal phenotypes. We used RNA sequence
            data generated by Genotype-Tissue Expression (GTEx) project to
            investigate the patterns of transcriptome variation across individuals
            and tissues. Tissues exhibit characteristic transcriptional
            signatures that show stability in postmortem samples. These signatures
            are dominated by a relatively small number of genes—which is most
            clearly seen in blood—though few are exclusive to a particular tissue
            and vary more across tissues than individuals. Genes exhibiting high
            interindividual expression variation include disease candidates
            associated with sex, ethnicity, and age. Primary transcription is
            the major driver of cellular specificity, with splicing playing
            mostly a complementary role; except for the brain, which exhibits a
            more divergent splicing program. Variation in splicing, despite its
            stochasticity, may play in contrast a comparatively greater role in
            defining individual phenotypes.},
    Journal ={Science},
    Year    ={2015},
    Volume  ={348},
    Number  ={6235},
    Pages   ={660--665},
    Month   ={05}
}

@online{ibmEnsembl,
    Author={{Ensembl Blog}},
    Title={Human BodyMap 2.0 data from Illumina},
    Year={2011},
    Url={http://www.ensembl.info/blog/2011/05/24/human-bodymap-2-0-data-from-illumina/},
    urldate={2013-03-11}
}

@misc{Desrosieres,
    Author = {Desrosi{\`e}res },
    Title = {Orbituary segment - JT du 13h - France 2},
    Year = {2013}
}

@article{UhlenGastro,
  Title       = {The human gastrointestinal tract-specific transcriptome and
                 proteome as defined by {RNA} sequencing and antibody-based
                 profiling},
  Author      = {Gremel, Gabriela and Wanders, Alkwin and Cedernaes, Jonathan
                 and Fagerberg, Linn and Hallstr{\"o}m, Bj{\"o}rn and Edlund,
                 Karolina and Sj{\"o}stedt, Evelina and Uhl{\'e}n, Mathias and
                 Pont{\'e}n, Fredrik},
  Abstract    = {BACKGROUND: The gastrointestinal tract (GIT) is subdivided
                 into different anatomical organs with many shared functions
                 and characteristics, but also distinct differences. We have
                 combined a genome-wide transcriptomics analysis with
                 immunohistochemistry-based protein profiling to describe the
                 gene and protein expression patterns that define the human
                 GIT. METHODS: RNA sequencing data derived from stomach,
                 duodenum, jejunum/ileum and colon specimens were compared to
                 gene expression levels in 23 other normal human tissues
                 analysed with the same method. Protein profiling based on
                 immunohistochemistry and tissue microarrays was used to
                 sub-localize the corresponding proteins with GIT-specific
                 expression into sub-cellular compartments and cell types.
                 RESULTS: Approximately 75\% of all human protein-coding genes
                 were expressed in at least one of the GIT tissues. Only 51
                 genes showed enriched expression in either one of the GIT
                 tissues and an additional 83 genes were enriched in two or
                 more GIT tissues. The list of GIT-enriched genes with
                 validated protein expression patterns included various
                 well-known but also previously uncharacterised or poorly
                 studied genes. For instance, the colon-enriched expression of
                 NXPE family member 1 (NXPE1) was established, while NLR
                 family, pyrin domain-containing 6 (NLRP6) expression was
                 primarily found in the human small intestine. CONCLUSIONS: We
                 have applied a genome-wide analysis based on transcriptomics
                 and antibody-based protein profiling to identify genes that
                 are expressed in a specific manner within the human GIT. These
                 genes and proteins constitute important starting points for an
                 improved understanding of the normal function and the
                 different states of disease associated with the GIT.},
  Journal     = {Journal of Gastroenterolog},
  Volume      =  {50},
  Number      =  {1},
  Pages       = {46--57},
  Month       = {01},
  Year        =  {2015},
  Language    = {en}
}

@article{lowNoiseLimit,
  title       = {The Low Noise Limit in Gene Expression},
  Author      = {Dar, Roy D and Razooky, Brandon S and Weinberger, Leor S and
                 Cox, Chris D and Simpson, Michael L},
  Abstract    = {Protein noise measurements are increasingly used to elucidate
                 biophysical parameters. Unfortunately noise analyses are often
                 at odds with directly measured parameters. Here we show that
                 these inconsistencies arise from two problematic analytical
                 choices: (i) the assumption that protein translation rate is
                 invariant for different proteins of different abundances,
                 which has inadvertently led to (ii) the assumption that a
                 large constitutive extrinsic noise sets the low noise limit in
                 gene expression. While growing evidence suggests that
                 transcriptional bursting may set the low noise limit,
                 variability in translational bursting has been largely
                 ignored. We show that genome-wide systematic variation in
                 translational efficiency can-and in the case of E. coli
                 does-control the low noise limit in gene expression. Therefore
                 constitutive extrinsic noise is small and only plays a role in
                 the absence of a systematic variation in translational
                 efficiency. These results show the existence of two distinct
                 expression noise patterns: (1) a global noise floor uniformly
                 imposed on all genes by expression bursting; and (2) high
                 noise distributed to only a select group of genes.},
  Journal     = {PLoS ONE},
  Volume      =  {10},
  Number      =  {10},
  Pages       = {e0140969},
  Month       =  {10} ,
  Year        =  {2015},
  Language    = {en}
}

@article{rnaseq-2009,
  Title       = {RNA-Seq: a revolutionary tool for transcriptomics},
  Author      = {Wang, Zhong and Gerstein, Mark and Snyder, Michael},
  Abstract    = {RNA-Seq is a recently developed approach to transcriptome
                 profiling that uses deep-sequencing technologies. Studies
                 using this method have already altered our view of the extent
                 and complexity of eukaryotic transcriptomes. RNA-Seq also
                 provides a far more precise measurement of levels of
                 transcripts and their isoforms than other methods. This
                 article describes the RNA-Seq approach, the challenges
                 associated with its application, and the advances made so far
                 in characterizing several eukaryote transcriptomes.},
  Journal     = {Nature Reviews Genetics},
  Volume      =  {10},
  Number      =  {1},
  Pages       = {57--63},
  Month       =  {01},
  Year        =  {2009},
  Language    = {en}
}

@article{PandeyData,
  Title       = {A draft map of the human proteome},
  Author      = {Kim, Min-Sik and Pinto, Sneha M and Getnet, Derese and
                 Nirujogi, Raja Sekhar and Manda, Srikanth S and Chaerkady,
                 Raghothama and Madugundu, Anil K and Kelkar, Dhanashree S and
                 Isserlin, Ruth and Jain, Shobhit and Thomas, Joji K and
                 Muthusamy, Babylakshmi and Leal-Rojas, Pamela and Kumar,
                 Praveen and Sahasrabuddhe, Nandini A and Balakrishnan, Lavanya
                 and Advani, Jayshree and George, Bijesh and Renuse, Santosh
                 and Selvan, Lakshmi Dhevi N and Patil, Arun H and Nanjappa,
                 Vishalakshi and Radhakrishnan, Aneesha and Prasad, Samarjeet
                 and Subbannayya, Tejaswini and Raju, Rajesh and Kumar, Manish
                 and Sreenivasamurthy, Sreelakshmi K and Marimuthu, Arivusudar
                 and Sathe, Gajanan J and Chavan, Sandip and Datta, Keshava K
                 and Subbannayya, Yashwanth and Sahu, Apeksha and Yelamanchi,
                 Soujanya D and Jayaram, Savita and Rajagopalan, Pavithra and
                 Sharma, Jyoti and Murthy, Krishna R and Syed, Nazia and Goel,
                 Renu and Khan, Aafaque A and Ahmad, Sartaj and Dey, Gourav and
                 Mudgal, Keshav and Chatterjee, Aditi and Huang, Tai-Chung and
                 Zhong, Jun and Wu, Xinyan and Shaw, Patrick G and Freed,
                 Donald and Zahari, Muhammad S and Mukherjee, Kanchan K and
                 Shankar, Subramanian and Mahadevan, Anita and Lam, Henry and
                 Mitchell, Christopher J and Shankar, Susarla Krishna and
                 Satishchandra, Parthasarathy and Schroeder, John T and
                 Sirdeshmukh, Ravi and Maitra, Anirban and Leach, Steven D and
                 Drake, Charles G and Halushka, Marc K and Prasad, T S Keshava
                 and Hruban, Ralph H and Kerr, Candace L and Bader, Gary D and
                 Iacobuzio-Donahue, Christine A and Gowda, Harsha and Pandey,
                 Akhilesh},
  Abstract    = {The availability of human genome sequence has transformed
                 biomedical research over the past decade. However, an
                 equivalent map for the human proteome with direct measurements
                 of proteins and peptides does not exist yet. Here we present a
                 draft map of the human proteome using high-resolution
                 Fourier-transform mass spectrometry. In-depth proteomic
                 profiling of 30 histologically normal human samples, including
                 17 adult tissues, 7 fetal tissues and 6 purified primary
                 haematopoietic cells, resulted in identification of proteins
                 encoded by 17,294 genes accounting for approximately 84\% of
                 the total annotated protein-coding genes in humans. A unique
                 and comprehensive strategy for proteogenomic analysis enabled
                 us to discover a number of novel protein-coding regions, which
                 includes translated pseudogenes, non-coding RNAs and upstream
                 open reading frames. This large human proteome catalogue
                 (available as an interactive web-based resource at
                 http://www.humanproteomemap.org) will complement available
                 human genome and transcriptome data to accelerate biomedical
                 research in health and disease.},
  Journal     = {Nature},
  Volume      =  {509},
  Number      =  {7502},
  Pages       = {575--581},
  Month       =  {05},
  Year        =  {2014},
  Language    = {en}
}

@article{KusterData,
  Title       = {Mass-spectrometry-based draft of the human proteome},
  Author      = {Wilhelm, Mathias and Schlegl, Judith and Hahne, Hannes and
                 Gholami, Amin Moghaddas and Lieberenz, Marcus and Savitski,
                 Mikhail M and Ziegler, Emanuel and Butzmann, Lars and
                 Gessulat, Siegfried and Marx, Harald and Mathieson, Toby and
                 Lemeer, Simone and Schnatbaum, Karsten and Reimer, Ulf and
                 Wenschuh, Holger and Mollenhauer, Martin and Slotta-Huspenina,
                 Julia and Boese, Joos-Hendrik and Bantscheff, Marcus and
                 Gerstmair, Anja and Faerber, Franz and Kuster, Bernhard},
  Abstract    = {Proteomes are characterized by large protein-abundance
                 differences, cell-type- and time-dependent expression patterns
                 and post-translational modifications, all of which carry
                 biological information that is not accessible by genomics or
                 transcriptomics. Here we present a mass-spectrometry-based
                 draft of the human proteome and a public, high-performance,
                 in-memory database for real-time analysis of terabytes of big
                 data, called ProteomicsDB. The information assembled from
                 human tissues, cell lines and body fluids enabled estimation
                 of the size of the protein-coding genome, and identified
                 organ-specific proteins and a large number of translated
                 lincRNAs (long intergenic non-coding RNAs). Analysis of
                 messenger RNA and protein-expression profiles of human tissues
                 revealed conserved control of protein abundance, and
                 integration of drug-sensitivity data enabled the
                 identification of proteins predicting resistance or
                 sensitivity. The proteome profiles also hold considerable
                 promise for analysing the composition and stoichiometry of
                 protein complexes. ProteomicsDB thus enables navigation of
                 proteomes, provides biological insight and fosters the
                 development of proteomic technology.},
  Journal     = {Nature},
  Volume      =  {509},
  Number      =  {7502},
  Pages       = {582--587},
  Month       =  {05},
  Year        =  {2014},
  Language    = {en}
}

@article{Ezkurdia2014-qx,
  Title       = {Analyzing the first drafts of the human proteome},
  Author      = {Ezkurdia, Iakes and V{\'a}zquez, Jes{\'u}s and Valencia,
                 Alfonso and Tress, Michael},
  Abstract    = {This letter analyzes two large-scale proteomics studies
                 published in the same issue of Nature. At the time of the
                 release, both studies were portrayed as draft maps of the
                 human proteome and great advances in the field. As with the
                 initial publication of the human genome, these papers have
                 broad appeal and will no doubt lead to a great deal of further
                 analysis by the scientific community. However, we were
                 intrigued by the number of protein-coding genes detected by
                 the two studies, numbers that far exceeded what has been
                 reported for the multinational Human Proteome Project effort.
                 We carried out a simple quality test on the data using the
                 olfactory receptor family. A high-quality proteomics
                 experiment that does not specifically analyze nasal tissues
                 should not expect to detect many peptides for olfactory
                 receptors. Neither of the studies carried out experiments on
                 nasal tissues, yet we found peptide evidence for more than 100
                 olfactory receptors in the two studies. These results suggest
                 that the two studies are substantially overestimating the
                 number of protein coding genes they identify. We conclude that
                 the experimental data from these two studies should be used
                 with caution.},
  Journal     = {Journal of Proteome Research},
  Volume      =  {13},
  Number      =  {8},
  Pages       = {3854--3855},
  Month       =  {08},
  Year        =  {2014},
  Keywords    = {Nature; human proteome; olfactory receptors; protein coding
                 genes; proteomics},
  Language    = {en}
}

@article{PeptideAtlas,
    Title={The PeptideAtlas project},
    Author={Desiere, Frank and Deutsch, Eric W and King, Nichole L and
        Nesvizhskii, Alexey I and Mallick, Parag and Eng, Jimmy and Chen, Sharon
            and Eddes, James and Loevenich, Sandra N and Aebersold, Ruedi},
    Abstract={The completion of the sequencing of the human genome and the
        concurrent, rapid development of high-throughput proteomic methods have
            resulted in an increasing need for automated approaches to archive
            proteomic data in a repository that enables the exchange of data
            among researchers and also accurate integration with genomic data.
            PeptideAtlas (http://www.peptideatlas.org/) addresses these needs by
            identifying peptides by tandem mass spectrometry (MS/MS),
        statistically validating those identifications and then mapping
            identified sequences to the genomes of eukaryotic organisms.
            A meaningful comparison of data across different experiments
            generated by different groups using different types of instruments
            is enabled by the implementation of a uniform analytic process.
            This uniform statistical validation ensures a consistent and
            high-quality set of peptide and protein identifications. The raw
            data from many diverse proteomic experiments are made available in
            the associated PeptideAtlas repository in several formats. Here we
            present a summary of our process and details about the Human,
        Drosophila and Yeast PeptideAtlas builds.},
    Journal={Nucleic Acids Research},
    Volume={34},
    Number={Suppl. 1},
    Pages={D655},
    Year={2006},
    Month={01},
    DOI={10.1093/nar/gkj040}
}

@article{anscombe,
    Title     = {Graphs in Statistical Analysis},
    Author    = {Anscombe, F J},
    Journal   = {American Statistician},
    Volume    =  {27},
    Number    =  {1},
    Pages     = {17--21},
    Year      =  {1973}
}

@article{Krupp2012,
    Title       = {{RNA-Seq} Atlas--a reference database for gene expression
        profiling in normal tissue by next-generation sequencing},
    Author      = {Krupp, Markus and Marquardt, Jens U and Sahin, Ugur and Galle,
        Peter R and Castle, John and Teufel, Andreas},
    Abstract    = {MOTIVATION: Next-generation sequencing technology enables an
        entirely new perspective for clinical research and will speed
            up personalized medicine. In contrast to microarray-based
            approaches, RNA-Seq analysis provides a much more
            comprehensive and unbiased view of gene expression. Although
            the perspective is clear and the long-term success of this new
            technology obvious, bioinformatics resources making these data
            easily available especially to the biomedical research
            community are still evolving. RESULTS: We have generated
            RNA-Seq Atlas, a web-based repository of RNA-Seq gene
            expression profiles and query tools. The website offers open
            and easy access to RNA-Seq gene expression profiles and tools
            to both compare tissues and find genes with specific
            expression patterns. To enlarge the scope of the RNA-Seq
            Atlas, the data were linked to common functional and genetic
            databases, in particular offering information on the
            respective gene, signaling pathway analysis and evaluation of
            biological functions by means of gene ontologies.
            Additionally, data were linked to several microarray gene
            profiles, including BioGPS normal tissue profiles and NCI60
            cancer cell line expression data. Our data search interface
            allows an integrative detailed comparison between our RNA-Seq
            data and the microarray information. This is the first
            database providing data mining tools and open access to large
            scale RNA-Seq expression profiles. Its applications will be
            versatile, as it will be beneficial in identifying tissue
            specific genes and expression profiles, comparison of gene
            expression profiles among diverse tissues, but also systems
            biology approaches linking tissue function to gene expression
            changes. AVAILABILITY AND IMPLEMENTATION:
            http://medicalgenomics.org/rna\_seq\_atlas.},
    Journal     = {Bioinformatics},
    Volume      =  {28},
    Number      =  {8},
    Pages       = {1184--1185},
    Month       =  {04},
    Year        =  {2012}
}

@article{BioGPS1,
  Title       = {{BioGPS} and {MyGene.info}: organizing online, gene-centric
                 information},
  Author      = {Wu, Chunlei and Macleod, Ian and Su, Andrew I},
  Abstract    = {Fast-evolving technologies have enabled researchers to easily
                 generate data at genome scale, and using these technologies to
                 compare biological states typically results in a list of
                 candidate genes. Researchers are then faced with the daunting
                 task of prioritizing these candidate genes for follow-up
                 studies. There are hundreds, possibly even thousands, of
                 web-based gene annotation resources available, but it quickly
                 becomes impractical to manually access and review all of these
                 sites for each gene in a candidate gene list. BioGPS
                 (http://biogps.org) was created as a centralized gene portal
                 for aggregating distributed gene annotation resources,
                 emphasizing community extensibility and user customizability.
                 BioGPS serves as a convenient tool for users to access known
                 gene-centric resources, as well as a mechanism to discover new
                 resources that were previously unknown to the user. This
                 article describes updates to BioGPS made after its initial
                 release in 2008. We summarize recent additions of features and
                 data, as well as the robust user activity that underlies this
                 community intelligence application. Finally, we describe
                 MyGene.info (http://mygene.info) and related web services that
                 provide programmatic access to BioGPS.},
  Journal     = {Nucleic Acids Research},
  Volume      =  {41},
  Number      = {Database issue},
  Pages       = {D561--5},
  Month       =  {01},
  Year        =  {2013},
  Language    = {en}
}

@article{Wu2009-lw,
  Title       = {{BioGPS:} an extensible and customizable portal for querying
                 and organizing gene annotation resources},
  Author      = {Wu, Chunlei and Orozco, Camilo and Boyer, Jason and Leglise,
                 Marc and Goodale, James and Batalov, Serge and Hodge,
                 Christopher L and Haase, James and Janes, Jeff and Huss, 3rd,
                 Jon W and Su, Andrew I},
  Abstract    = {Online gene annotation resources are indispensable for
                 analysis of genomics data. However, the landscape of these
                 online resources is highly fragmented, and scientists often
                 visit dozens of these sites for each gene in a candidate gene
                 list. Here, we introduce BioGPS http://biogps.gnf.org, a
                 centralized gene portal for aggregating distributed gene
                 annotation resources. Moreover, BioGPS embraces the principle
                 of community intelligence, enabling any user to easily and
                 directly contribute to the BioGPS platform.},
  Journal     = {Genome Biology},
  Volume      =  {10},
  Number      =  {11},
  Pages       = {R130},
  Month       =  {11},
  Year        =  {2009},
  Language    = {en}
}

@article{Fonseca2014,
  Title       = {{RNA-Seq} gene profiling--a systematic empirical comparison},
  Author      = {Fonseca, Nuno A and Marioni, John and Brazma, Alvis},
  Abstract    = {Accurately quantifying gene expression levels is a key goal of
                 experiments using RNA-sequencing to assay the transcriptome.
                 This typically requires aligning the short reads generated to
                 the genome or transcriptome before quantifying expression of
                 pre-defined sets of genes. Differences in the
                 alignment/quantification tools can have a major effect upon
                 the expression levels found with important consequences for
                 biological interpretation. Here we address two main issues: do
                 different analysis pipelines affect the gene expression levels
                 inferred from RNA-seq data? And, how close are the expression
                 levels inferred to the ``true'' expression levels? We evaluate
                 fifty gene profiling pipelines in experimental and simulated
                 data sets with different characteristics (e.g, read length and
                 sequencing depth). In the absence of knowledge of the 'ground
                 truth' in real RNAseq data sets, we used simulated data to
                 assess the differences between the ``true'' expression and
                 those reconstructed by the analysis pipelines. Even though
                 this approach does not take into account all known biases
                 present in RNAseq data, it still allows to estimate the
                 accuracy of the gene expression values inferred by different
                 analysis pipelines. The results show that i) overall there is
                 a high correlation between the expression levels inferred by
                 the best pipelines and the true quantification values; ii) the
                 error in the estimated gene expression values can vary
                 considerably across genes; and iii) a small set of genes have
                 expression estimates with consistently high error (across data
                 sets and methods). Finally, although the mapping software is
                 important, the quantification method makes a greater
                 difference to the results.},
  Journal     = {PLoS ONE},
  Volume      =  {9},
  Number      =  {9},
  Pages       = {e107026},
  Month       =  {09},
  Year        =  {2014},
  Language    = {en}
}

@article{contaminationRNAseq,
  Title       = {{HeLa} nucleic acid contamination in the cancer genome atlas
                 leads to the misidentification of human papillomavirus 18},
  Author      = {Cantalupo, Paul G and Katz, Joshua P and Pipas, James M},
  Abstract    = { We searched The Cancer Genome Atlas (TCGA)
                 database for viruses by comparing non-human reads present in
                 transcriptome sequencing (RNA-Seq) and whole-exome sequencing
                 (WXS) data to viral sequence databases. Human papillomavirus
                 18 (HPV18) is an etiologic agent of cervical cancer, and as
                 expected, we found robust expression of HPV18 genes in
                 cervical cancer samples. In agreement with previous studies,
                 we also found HPV18 transcripts in non-cervical cancer
                 samples, including those from the colon, rectum, and normal
                 kidney. However, in each of these cases, HPV18 gene expression
                 was low, and single-nucleotide variants and positions of
                 genomic alignments matched the integrated portion of HPV18
                 present in HeLa cells. Chimeric reads that match a known
                 virus-cell junction of HPV18 integrated in HeLa cells were
                 also present in some samples. We hypothesize that HPV18
                 sequences in these non-cervical samples are due to nucleic
                 acid contamination from HeLa cells. This finding highlights
                 the problems that contamination presents in computational
                 virus detection pipelines. IMPORTANCE: Viruses associated with
                 cancer can be detected by searching tumor sequence databases.
                 Several studies involving searches of the TCGA database have
                 reported the presence of HPV18, a known cause of cervical
                 cancer, in a small number of additional cancers, including
                 those of the rectum, kidney, and colon. We have determined
                 that the sequences related to HPV18 in non-cervical samples
                 are due to nucleic acid contamination from HeLa cells. To our
                 knowledge, this is the first report of the misidentification
                 of viruses in next-generation sequencing data of tumors due to
                 contamination with a cancer cell line. These results raise
                 awareness of the difficulty of accurately identifying viruses
                 in human sequence databases.},
  Journal     = {Journal of Virology},
  Volume      =  {89},
  Number      =  {8},
  Pages       = {4051--4057},
  Month       =  {04},
  Year        =  {2015},
  Language    = {en}
}

@article{Dillies2013,
  Title       = {A comprehensive evaluation of normalization methods for
                 Illumina high-throughput {RNA} sequencing data analysis},
  Author      = {Dillies, Marie-Agn{\`e}s and Rau, Andrea and Aubert, Julie and
                 Hennequet-Antier, Christelle and Jeanmougin, Marine and
                 Servant, Nicolas and Keime, C{\'e}line and Marot, Guillemette
                 and Castel, David and Estelle, Jordi and Guernec, Gregory and
                 Jagla, Bernd and Jouneau, Luc and Lalo{\"e}, Denis and Le
                 Gall, Caroline and Scha{\"e}ffer, Brigitte and Le Crom,
                 St{\'e}phane and Guedj, Micka{\"e}l and Jaffr{\'e}zic,
                 Florence and {French StatOmique Consortium}},
  Abstract    = {During the last 3 years, a number of approaches for the
                 normalization of RNA sequencing data have emerged in the
                 literature, differing both in the type of bias adjustment and
                 in the statistical strategy adopted. However, as data continue
                 to accumulate, there has been no clear consensus on the
                 appropriate normalization method to be used or the impact of a
                 chosen method on the downstream analysis. In this work, we
                 focus on a comprehensive comparison of seven recently proposed
                 normalization methods for the differential analysis of RNA-seq
                 data, with an emphasis on the use of varied real and simulated
                 datasets involving different species and experimental designs
                 to represent data characteristics commonly observed in
                 practice. Based on this comparison study, we propose practical
                 recommendations on the appropriate normalization method to be
                 used and its impact on the differential analysis of RNA-seq
                 data.},
  Journal     = {Briefings in Bioinformatics},
  Volume      =  {14},
  Number      =  {6},
  Pages       = {671--683},
  Month       =  {11},
  Year        =  {2013},
  Keywords    = {RNA-seq; differential analysis; high-throughput sequencing;
                 normalization},
  Language    = {en}
}

@software{fastqc,
  author = {Babraham Bioinformatics},
  title = {Fastqc - A quality control tool for high throughput sequence data.},
  url = {https://www.bioinformatics.babraham.ac.uk/projects/fastqc/},
  version = {0.10.1},
  date = {2013-01-25}
}

@article{seqcmaqc,
  Title    = {A comprehensive assessment of {RNA-seq} accuracy, reproducibility
              and information content by the Sequencing Quality Control
              Consortium},
  Author   = {{SEQC/MAQC-III Consortium}},
  Abstract = {We present primary results from the Sequencing Quality Control
              (SEQC) project, coordinated by the US Food and Drug
              Administration. Examining Illumina HiSeq, Life Technologies SOLiD
              and Roche 454 platforms at multiple laboratory sites using
              reference RNA samples with built-in controls, we assess RNA
              sequencing (RNA-seq) performance for junction discovery and
              differential expression profiling and compare it to microarray
              and quantitative PCR (qPCR) data using complementary metrics. At
              all sequencing depths, we discover unannotated exon-exon
              junctions, with >80\% validated by qPCR. We find that
              measurements of relative expression are accurate and reproducible
              across sites and platforms if specific filters are used. In
              contrast, RNA-seq and microarrays do not provide accurate
              absolute measurements, and gene-specific biases are observed for
              all examined platforms, including qPCR. Measurement performance
              depends on the platform and data analysis pipeline, and variation
              is large for transcript-level profiling. The complete SEQC data
              sets, comprising >100 billion reads (10Tb), provide unique
              resources for evaluating RNA-seq analyses for clinical and
              regulatory settings.},
  Journal  = {Nature Biotechnoly},
  Volume   =  {32},
  Number   =  {9},
  Pages    = {903--914},
  Month    =  {09},
  Year     =  {2014},
  Language = {en}
}

@article {EBIgxa,
  Title = {Expression Atlas update---an integrated database of gene and protein
        expression in humans, animals and plants},
  Author = {Petryszak, Robert and Keays, Maria and Tang, Y Amy and
        Fonseca, Nuno A and Barrera, Elisabet and Burdett, Tony and
        F{\"u}llgrabe,Anja and Fuentes, Alfonso Muñoz-Pomer and Jupp, Simon and
        Koskinen, Satu and Mannion, Oliver and Huerta, Laura and Megy, Karine
        and Snow, Catherine and Williams, Eleanor and Barzine, Mitra and
        Hastings, Emma and Weisser, Hendrik and Wright, James and
        Jaiswal, Pankaj and Huber, Wolfgang and Choudhary, Jyoti and
        Parkinson, Helen E and Brazma, Alvis},
  Abstract ={Expression Atlas (http://www.ebi.ac.uk/gxa) provides information
        about gene and protein expression in animal and plant samples of
        different cell types, organism parts, developmental stages, diseases
        and other conditions. It consists of selected microarray and
        RNA-sequencing studies from ArrayExpress, which have been manually
        curated, annotated with ontology terms, checked for high quality and
        processed using standardised analysis methods. Since the last update,
        Atlas has grown seven-fold (1572 studies as of August 2015), and
        incorporates baseline expression profiles of tissues from Human Protein
        Atlas, GTEx and FANTOM5, and of cancer cell lines from ENCODE, CCLE and
        Genentech projects. Plant studies constitute a quarter of Atlas data.
        For genes of interest, the user can view baseline expression in tissues,
        and differential expression for biologically meaningful pairwise
        comparisons—estimated using consistent methodology across all of Atlas.
        Our first proteomics study in human tissues is now displayed alongside
        transcriptomics data in the same tissues. Novel analyses and
        visualisations include: ‘enrichment’ in each differential comparison of
        GO terms, Reactome, Plant Reactome pathways and InterPro domains;
        hierarchical clustering (by baseline expression) of most variable genes
        and experimental conditions; and, for a given gene-condition,
        distribution of baseline expression across biological replicates.},
  DOI = {10.1093/nar/gkv1045},
  Number = {D1},
  Volume = {44},
  Month = {01},
  Year = {2015},
  Journal = {Nucleic Acids Research},
  ISSN = {0305-1048},
  Pages = {D746—52},
  URL = {http://nar.oxfordjournals.org/content/early/2015/10/19/nar.gkv1045.abstrac},
  Eprint = {http://nar.oxfordjournals.org/content/early/2015/10/19/nar.gkv1045.full.pdf+html},
  PMID = {26481351}
}

@article{Harmonizome,
  Title       = {The harmonizome: a collection of processed datasets gathered
                 to serve and mine knowledge about genes and proteins},
  Author      = {Rouillard, Andrew D and Gundersen, Gregory W and Fernandez,
                 Nicolas F and Wang, Zichen and Monteiro, Caroline D and
                 McDermott, Michael G and Ma'ayan, Avi},
  Abstract    = {Genomics, epigenomics, transcriptomics, proteomics and
                 metabolomics efforts rapidly generate a plethora of data on
                 the activity and levels of biomolecules within mammalian
                 cells. At the same time, curation projects that organize
                 knowledge from the biomedical literature into online databases
                 are expanding. Hence, there is a wealth of information about
                 genes, proteins and their associations, with an urgent need
                 for data integration to achieve better knowledge extraction
                 and data reuse. For this purpose, we developed the
                 Harmonizome: a collection of processed datasets gathered to
                 serve and mine knowledge about genes and proteins from over 70
                 major online resources. We extracted, abstracted and organized
                 data into ∼72 million functional associations between
                 genes/proteins and their attributes. Such attributes could be
                 physical relationships with other biomolecules, expression in
                 cell lines and tissues, genetic associations with knockout
                 mouse or human phenotypes, or changes in expression after drug
                 treatment. We stored these associations in a relational
                 database along with rich metadata for the genes/proteins,
                 their attributes and the original resources. The freely
                 available Harmonizome web portal provides a graphical user
                 interface, a web service and a mobile app for querying,
                 browsing and downloading all of the collected data. To
                 demonstrate the utility of the Harmonizome, we computed and
                 visualized gene-gene and attribute-attribute similarity
                 networks, and through unsupervised clustering, identified many
                 unexpected relationships by combining pairs of datasets such
                 as the association between kinase perturbations and disease
                 signatures. We also applied supervised machine learning
                 methods to predict novel substrates for kinases, endogenous
                 ligands for G-protein coupled receptors, mouse phenotypes for
                 knockout genes, and classified unannotated transmembrane
                 proteins for likelihood of being ion channels. The Harmonizome
                 is a comprehensive resource of knowledge about genes and
                 proteins, and as such, it enables researchers to discover
                 novel relationships between biological entities, as well as
                 form novel data-driven hypotheses for experimental
                 validation.Database URL:
                 http://amp.pharm.mssm.edu/Harmonizome.},
  Journal     = {Database},
  Volume      =  {2016},
  Month       =  {07},
  Year        =  {2016},
  Language    = {en}
}

@article{qualityRNAseq,
  Title       = {Quality Control for {RNA-Seq} ({QuaCRS}): An Integrated
                 Quality Control Pipeline},
  Author      = {Kroll, Karl W and Mokaram, Nima E and Pelletier, Alexander R
                 and Frankhouser, David E and Westphal, Maximillian S and
                 Stump, Paige A and Stump, Cameron L and Bundschuh, Ralf and
                 Blachly, James S and Yan, Pearlly},
  Abstract    = {QuaCRS (Quality Control for RNA-Seq) is an integrated,
                 simplified quality control (QC) system for RNA-seq data that
                 allows easy execution of several open-source QC tools,
                 aggregation of their output, and the ability to quickly
                 identify quality issues by performing meta-analyses on QC
                 metrics across large numbers of samples in different studies.
                 It comprises two main sections. First is the QC Pack wrapper,
                 which executes three QC tools: FastQC, RNA-SeQC, and selected
                 functions from RSeQC. Combining these three tools into one
                 wrapper provides increased ease of use and provides a much
                 more complete view of sample data quality than any individual
                 tool. Second is the QC database, which displays the resulting
                 metrics in a user-friendly web interface. It was designed to
                 allow users with less computational experience to easily
                 generate and view QC information for their data, to
                 investigate individual samples and aggregate reports of sample
                 groups, and to sort and search samples based on quality. The
                 structure of the QuaCRS database is designed to enable
                 expansion with additional tools and metrics in the future. The
                 source code for not-for-profit use and a fully functional
                 sample user interface with mock data are available at
                 http://bioserv.mps.ohio-state.edu/QuaCRS/.},
  Journal     = {Cancer Informatics},
  Volume      =  {13},
  Number      = {Suppl 3},
  Pages       = {7--14},
  Month       =  {10},
  Year        =  {2014},
  Keywords    = {FastQC; RNA-SeQC; RNA-seq; RSeQC; database; quality control},
  Language    = {en}
}

@article{h38vsh37,
  Title       = {Improvements and impacts of {GRCh38} human reference on high
                 throughput sequencing data analysis},
  Author      = {Guo, Yan and Dai, Yulin and Yu, Hui and Zhao, Shilin and
                 Samuels, David C and Shyr, Yu},
  Abstract    = {Analyses of high throughput sequencing data starts with
                 alignment against a reference genome, which is the foundation
                 for all re-sequencing data analyses. Each new release of the
                 human reference genome has been augmented with improved
                 accuracy and completeness. It is presumed that the latest
                 release of human reference genome, GRCh38 will contribute more
                 to high throughput sequencing data analysis by providing more
                 accuracy. But the amount of improvement has not yet been
                 quantified. We conducted a study to compare the genomic
                 analysis results between the GRCh38 reference and its
                 predecessor GRCh37. Through analyses of alignment, single
                 nucleotide polymorphisms, small insertion/deletions, copy
                 number and structural variants, we show that GRCh38 offers
                 overall more accurate analysis of human sequencing data. More
                 importantly, GRCh38 produced fewer false positive structural
                 variants. In conclusion, GRCh38 is an improvement over GRCh37
                 not only from the genome assembly aspect, but also yields more
                 reliable genomic analysis results.},
  Journal     = {Genomics},
  Volume      =  {109},
  Number      =  {2},
  Pages       = {83--90},
  Month       =  {03},
  Year        =  {2017},
  Keywords    = {Copy number variation; GRCh37; GRCh38; High throughput
                 sequencing; Human reference genome; SNP; Structural variant},
  Language    = {en}
}

@article{RNAseqBench2016,
  Title       = {A benchmark for {RNA-seq} quantification pipelines},
  Author      = {Teng, Mingxiang and Love, Michael I and Davis, Carrie A and
                 Djebali, Sarah and Dobin, Alexander and Graveley, Brenton R
                 and Li, Sheng and Mason, Christopher E and Olson, Sara and
                 Pervouchine, Dmitri and Sloan, Cricket A and Wei, Xintao and
                 Zhan, Lijun and Irizarry, Rafael A},
  Abstract    = {Obtaining RNA-seq measurements involves a complex data
                 analytical process with a large number of competing algorithms
                 as options. There is much debate about which of these methods
                 provides the best approach. Unfortunately, it is currently
                 difficult to evaluate their performance due in part to a lack
                 of sensitive assessment metrics. We present a series of
                 statistical summaries and plots to evaluate the performance in
                 terms of specificity and sensitivity, available as a
                 R/Bioconductor package (
                 http://bioconductor.org/packages/rnaseqcomp ). Using two
                 independent datasets, we assessed seven competing pipelines.
                 Performance was generally poor, with two methods clearly
                 underperforming and RSEM slightly outperforming the rest.},
  Journal     = {Genome Biology},
  Volume      =  {17},
  Pages       = {74},
  Month       =  {04},
  Year        =  {2016},
  Language    = {en}
}

@article{Trimwisely,
  Title       = {Trimming of sequence reads alters {RNA-Seq} gene expression
                 estimates},
  Author      = {Williams, Claire R and Baccarella, Alyssa and Parrish, Jay Z
                 and Kim, Charles C},
  Abstract    = {BACKGROUND: High-throughput RNA-Sequencing (RNA-Seq) has
                 become the preferred technique for studying gene expression
                 differences between biological samples and for discovering
                 novel isoforms, though the techniques to analyze the resulting
                 data are still immature. One pre-processing step that is
                 widely but heterogeneously applied is trimming, in which low
                 quality bases, identified by the probability that they are
                 called incorrectly, are removed. However, the impact of
                 trimming on subsequent alignment to a genome could influence
                 downstream analyses including gene expression estimation; we
                 hypothesized that this might occur in an inconsistent manner
                 across different genes, resulting in differential bias.
                 RESULTS: To assess the effects of trimming on gene expression,
                 we generated RNA-Seq data sets from four samples of larval
                 Drosophila melanogaster sensory neurons, and used three
                 trimming algorithms--SolexaQA, Trimmomatic, and ConDeTri-to
                 perform quality-based trimming across a wide range of
                 stringencies. After aligning the reads to the D. melanogaster
                 genome with TopHat2, we used Cuffdiff2 to compare the
                 original, untrimmed gene expression estimates to those
                 following trimming. With the most aggressive trimming
                 parameters, over ten percent of genes had significant changes
                 in their estimated expression levels. This trend was seen with
                 two additional RNA-Seq data sets and with alternative
                 differential expression analysis pipelines. We found that the
                 majority of the expression changes could be mitigated by
                 imposing a minimum length filter following trimming,
                 suggesting that the differential gene expression was primarily
                 being driven by spurious mapping of short reads. Slight
                 differences with the untrimmed data set remained after length
                 filtering, which were associated with genes with low exon
                 numbers and high GC content. Finally, an analysis of paired
                 RNA-seq/microarray data sets suggests that no or modest
                 trimming results in the most biologically accurate gene
                 expression estimates. CONCLUSIONS: We find that aggressive
                 quality-based trimming has a large impact on the apparent
                 makeup of RNA-Seq-based gene expression estimates, and that
                 short reads can have a particularly strong impact. We conclude
                 that implementation of trimming in RNA-Seq analysis workflows
                 warrants caution, and if used, should be used in conjunction
                 with a minimum read length filter to minimize the introduction
                 of unpredictable changes in expression estimates.},
  Journal     = {BMC Bioinformatics},
  Volume      =  {17},
  Pages       = {103},
  Month       =  {02},
  Year        =  {2016},
  Language    = {en}
}

@article{tophat2,
  Title    = {{TopHat2}: accurate alignment of transcriptomes in the presence
              of insertions, deletions and gene fusions},
  Author   = {Kim, Daehwan and Pertea, Geo and Trapnell, Cole and Pimentel,
              Harold and Kelley, Ryan and Salzberg, Steven L},
  Abstract = {TopHat is a popular spliced aligner for RNA-sequence (RNA-seq)
              experiments. In this paper, we describe TopHat2, which
              incorporates many significant enhancements to TopHat. TopHat2 can
              align reads of various lengths produced by the latest sequencing
              technologies, while allowing for variable-length indels with
              respect to the reference genome. In addition to de novo spliced
              alignment, TopHat2 can align reads across fusion breaks, which
              can occur after genomic translocations. TopHat2 combines the
              ability to identify novel splice sites with direct mapping to
              known transcripts, producing sensitive and accurate alignments,
              even for highly repetitive genomes or in the presence of
              pseudogenes. TopHat2 is available at
              http://ccb.jhu.edu/software/tophat.},
  Journal  = {Genome Biology},
  Volume   =  {14},
  Number   =  {4},
  Pages    = {R36},
  Month    =  {04},
  Year     =  {2013},
  Language = {en}
}

@article{cufflinks,
  Title       = {Transcript assembly and quantification by {RNA-Seq} reveals
                 unannotated transcripts and isoform switching during cell
                 differentiation},
  Author      = {Trapnell, Cole and Williams, Brian A and Pertea, Geo and
                 Mortazavi, Ali and Kwan, Gordon and van Baren, Marijke J and
                 Salzberg, Steven L and Wold, Barbara J and Pachter, Lior},
  Abstract    = {High-throughput mRNA sequencing (RNA-Seq) promises
                 simultaneous transcript discovery and abundance estimation.
                 However, this would require algorithms that are not restricted
                 by prior gene annotations and that account for alternative
                 transcription and splicing. Here we introduce such algorithms
                 in an open-source software program called Cufflinks. To test
                 Cufflinks, we sequenced and analyzed >430 million paired 75-bp
                 RNA-Seq reads from a mouse myoblast cell line over a
                 differentiation time series. We detected 13,692 known
                 transcripts and 3,724 previously unannotated ones, 62\% of
                 which are supported by independent expression data or by
                 homologous genes in other species. Over the time series, 330
                 genes showed complete switches in the dominant transcription
                 start site (TSS) or splice isoform, and we observed more
                 subtle shifts in 1,304 other genes. These results suggest that
                 Cufflinks can illuminate the substantial regulatory
                 flexibility and complexity in even this well-studied model of
                 muscle development and that it can improve transcriptome-based
                 genome annotation.},
  Journal     =  {Nature Biotechnology},
  Volume      =  {28},
  Number      =  {5},
  Pages       =  {511--515},
  Month       =  {05},
  Year        =  {2010},
  Language    =  {en}
}

@article{ernestRNA,
  Title    = {A comparative study of {RNA-seq} analysis strategies},
  Author   = {J{\"a}nes, J{\"u}rgen and Hu, Fengyuan and Lewin, Alexandra and
              Turro, Ernest},
  Abstract = {Three principal approaches have been proposed for inferring the
              set of transcripts expressed in RNA samples using RNA-seq. The
              simplest approach uses curated annotations, which assumes the
              transcripts in a sample are a subset of the transcripts listed in
              a curated database. A more ambitious method involves aligning
              reads to a reference genome and using the alignments to infer the
              transcript structures, possibly with the aid of a curated
              transcript database. The most challenging approach is to assemble
              reads into putative transcripts de novo without the aid of
              reference data. We have systematically assessed the properties of
              these three approaches through a simulation study. We have found
              that the sensitivity of computational transcript set estimation
              is severely limited. Computational approaches (both genome-guided
              and de novo assembly) produce a large number of artefacts, which
              are assigned large expression estimates and absorb a substantial
              proportion of the signal when performing expression analysis. The
              approach using curated annotations shows good expression
              correlation even when the annotations are incomplete.
              Furthermore, any incorrect transcripts present in a curated set
              do not absorb much signal, so it is preferable to have a curation
              set with high sensitivity than high precision. Software to
              simulate transcript sets, expression values and sequence reads
              under a wider range of parameter values and to compare
              sensitivity, precision and signal-to-noise ratios of different
              methods is freely available online
              (https://github.com/boboppie/RSSS) and can be expanded by
              interested parties to include methods other than the exemplars
              presented in this article.},
  Journal  = {Briefings in Bioinformatics},
  Volume   =  {16},
  Number   =  {6},
  Pages    = {932--940},
  Month    =  {11},
  Year     =  {2015},
  Keywords = {RNA splicing; RNA-seq; gene expression; transcriptome assembly},
  Language = {en}
}

@article{tamaraRNA,
  Title       = {Systematic evaluation of spliced alignment programs for
                 {RNA-seq} data},
  Author      = {Engstr{\"o}m, P{\"a}r G and Steijger, Tamara and Sipos, Botond
                 and Grant, Gregory R and Kahles, Andr{\'e} and R{\"a}tsch,
                 Gunnar and Goldman, Nick and Hubbard, Tim J and Harrow,
                 Jennifer and Guig{\'o}, Roderic and Bertone, Paul and {RGASP
                 Consortium}},
  Abstract    = {High-throughput RNA sequencing is an increasingly accessible
                 method for studying gene structure and activity on a
                 genome-wide scale. A critical step in RNA-seq data analysis is
                 the alignment of partial transcript reads to a reference
                 genome sequence. To assess the performance of current mapping
                 software, we invited developers of RNA-seq aligners to process
                 four large human and mouse RNA-seq data sets. In total, we
                 compared 26 mapping protocols based on 11 programs and
                 pipelines and found major performance differences between
                 methods on numerous benchmarks, including alignment yield,
                 basewise accuracy, mismatch and gap placement, exon junction
                 discovery and suitability of alignments for transcript
                 reconstruction. We observed concordant results on real and
                 simulated RNA-seq data, confirming the relevance of the
                 metrics employed. Future developments in RNA-seq alignment
                 methods would benefit from improved placement of multimapped
                 reads, balanced utilization of existing gene annotation and a
                 reduced false discovery rate for splice junctions.},
  Journal     = {Nature Methods},
  Volume      =  {10},
  Number      =  {12},
  Pages       = {1185--1191},
  Month       =  {12},
  Year        =  {2013},
  Language    = {en}
}

@article{microarrayAreTheBest,
  Title       = {{RNA} sequencing and transcriptome arrays analyses show
                 opposing results for alternative splicing in patient derived
                 samples},
  Author      = {Nazarov, Petr V and Muller, Arnaud and Kaoma, Tony and Nicot,
                 Nathalie and Maximo, Cristina and Birembaut, Philippe and
                 Tran, Nhan L and Dittmar, Gunnar and Vallar, Laurent},
  Abstract    = {BACKGROUND: RNA sequencing (RNA-seq) and microarrays are two
                 transcriptomics techniques aimed at the quantification of
                 transcribed genes and their isoforms. Here we compare the
                 latest Affymetrix HTA 2.0 microarray with Illumina 2000
                 RNA-seq for the analysis of patient samples - normal lung
                 epithelium tissue and squamous cell carcinoma lung tumours.
                 Protein coding mRNAs and long non-coding RNAs (lncRNAs) were
                 included in the study. RESULTS: Both platforms performed
                 equally well for protein-coding RNAs, however the stochastic
                 variability was higher for the sequencing data than for
                 microarrays. This reduced the number of differentially
                 expressed genes and genes with predictive potential for
                 RNA-seq compared to microarray data. Analysis of this
                 variability revealed a lack of reads for short and low
                 abundant genes; lncRNAs, being shorter and less abundant RNAs,
                 were found especially susceptible to this issue. A major
                 difference between the two platforms was uncovered by analysis
                 of alternatively spliced genes. Investigation of differential
                 exon abundance showed insufficient reads for many exons and
                 exon junctions in RNA-seq while the detection on the array
                 platform was more stable. Nevertheless, we identified 207
                 genes which undergo alternative splicing and were consistently
                 detected by both techniques. CONCLUSIONS: Despite the fact
                 that the results of gene expression analysis were highly
                 consistent between Human Transcriptome Arrays and RNA-seq
                 platforms, the analysis of alternative splicing produced
                 discordant results. We concluded that modern microarrays can
                 still outperform sequencing for standard analysis of gene
                 expression in terms of reproducibility and cost.},
  Journal     = {BMC Genomics},
  Volume      =  {18},
  Number      =  {1},
  Pages       = {443},
  Month       =  {06},
  Year        =  {2017},
  Keywords    = {Differential exon usage; Differential expression analysis;
                 Microarrays; RNA sequencing; Splicing},
  Language    = {en}
}

@article{rnaseqProtocols,
  Title       = {Coming of age: ten years of next-generation sequencing
                 technologies},
  Author      = {Goodwin, Sara and McPherson, John D and McCombie, W Richard},
  Abstract    = {Since the completion of the human genome project in 2003,
                 extraordinary progress has been made in genome sequencing
                 technologies, which has led to a decreased cost per megabase
                 and an increase in the number and diversity of sequenced
                 genomes. An astonishing complexity of genome architecture has
                 been revealed, bringing these sequencing technologies to even
                 greater advancements. Some approaches maximize the number of
                 bases sequenced in the least amount of time, generating a
                 wealth of data that can be used to understand increasingly
                 complex phenotypes. Alternatively, other approaches now aim to
                 sequence longer contiguous pieces of DNA, which are essential
                 for resolving structurally complex regions. These and other
                 strategies are providing researchers and clinicians a variety
                 of tools to probe genomes in greater depth, leading to an
                 enhanced understanding of how genome sequence variants
                 underlie phenotype and disease.},
  Journal     = {Nature Reviews Genetics},
  Volume      =  {17},
  Number      =  {6},
  Pages       = {333--351},
  Month       =  {05},
  Year        =  {2016},
  Language    = {en}
}

@article{IlluminaCheap,
  Title       = {Ten years of next-generation sequencing technology},
  Author      = {van Dijk, Erwin L and Auger, H{\'e}l{\`e}ne and Jaszczyszyn,
                 Yan and Thermes, Claude},
  Abstract    = {Ten years ago next-generation sequencing (NGS) technologies
                 appeared on the market. During the past decade, tremendous
                 progress has been made in terms of speed, read length, and
                 throughput, along with a sharp reduction in per-base cost.
                 Together, these advances democratized NGS and paved the way
                 for the development of a large number of novel NGS
                 applications in basic science as well as in translational
                 research areas such as clinical diagnostics, agrigenomics, and
                 forensic science. Here we provide an overview of the evolution
                 of NGS and discuss the most significant improvements in
                 sequencing technologies and library preparation protocols. We
                 also explore the current landscape of NGS applications and
                 provide a perspective for future developments.},
  Journal     = {Trends in Genetics},
  Volume      =  {30},
  Number      =  {9},
  Pages       = {418--426},
  Month       =  {09},
  Year        =  {2014},
  Keywords    = {ChIP-seq; DNA-seq; NGS library preparation; Next-generation
                 sequencing (NGS); RNA-seq; genomics},
  Language    = {en}
}

@online{rnaseqlopedia,
        Author={{Cresko Lab}},
        Title={RNA-seqlopedia},
        Year={2017},
        Url={http://rnaseq.uoregon.edu}
}

@article{Mortazavi2008,
  Title       = {Mapping and quantifying mammalian transcriptomes by {RNA-Seq}},
  Author      = {Mortazavi, Ali and Williams, Brian A and McCue, Kenneth and
                 Schaeffer, Lorian and Wold, Barbara},
  Abstract    = {We have mapped and quantified mouse transcriptomes by deeply
                 sequencing them and recording how frequently each gene is
                 represented in the sequence sample (RNA-Seq). This provides a
                 digital measure of the presence and prevalence of transcripts
                 from known and previously unknown genes. We report reference
                 measurements composed of 41-52 million mapped 25-base-pair
                 reads for poly(A)-selected RNA from adult mouse brain, liver
                 and skeletal muscle tissues. We used RNA standards to quantify
                 transcript prevalence and to test the linear range of
                 transcript detection, which spanned five orders of magnitude.
                 Although >90\% of uniquely mapped reads fell within known
                 exons, the remaining data suggest new and revised gene models,
                 including changed or additional promoters, exons and 3'
                 untranscribed regions, as well as new candidate microRNA
                 precursors. RNA splice events, which are not readily measured
                 by standard gene expression microarray or serial analysis of
                 gene expression methods, were detected directly by mapping
                 splice-crossing sequence reads. We observed 1.45 x 10(5)
                 distinct splices, and alternative splices were prominent, with
                 3,500 different genes expressing one or more alternate
                 internal splices.},
  Journal     = {Nature Methods},
  Publisher   = {Nature Publishing Group},
  Volume      =  {5},
  Number      =  {7},
  Pages       = {621--628},
  Month       =  {07},
  Year        =  {2008},
  Language    = {en}
}

@article{Cui2010,
  Title       = {A comparison between ribo-minus {RNA-sequencing} and
                 polyA-selected {RNA-sequencing}},
  Author      = {Cui, Peng and Lin, Qiang and Ding, Feng and Xin, Chengqi and
                 Gong, Wei and Zhang, Lingfang and Geng, Jianing and Zhang,
                 Bing and Yu, Xiaomin and Yang, Jin and Hu, Songnian and Yu,
                 Jun},
  Abstract    = {To compare the two RNA-sequencing protocols, ribo-minus
                 RNA-sequencing (rmRNA-seq) and polyA-selected RNA-sequencing
                 (mRNA-seq), we acquired transcriptomic data-52 and 32 million
                 alignable reads of 35 bases in length-from the mouse cerebrum,
                 respectively. We found that a higher proportion, 44\% and
                 25\%, of the uniquely alignable rmRNA-seq reads, is in
                 intergenic and intronic regions, respectively, as compared to
                 23\% and 15\% from the mRNA-seq dataset. Further analysis made
                 an additional discovery of transcripts of protein-coding genes
                 (such as Histone, Heg1, and Dux), ncRNAs, snoRNAs, snRNAs, and
                 novel ncRNAs as well as repeat elements in rmRNA-seq dataset.
                 This result suggests that rmRNA-seq method should detect more
                 polyA- or bimorphic transcripts. Finally, through comparative
                 analyses of gene expression profiles among multiple datasets,
                 we demonstrated that different RNA sample preparations may
                 result in significant variations in gene expression profiles.},
  Journal     = {Genomics},
  Volume      =  {96},
  Number      =  {5},
  Pages       = {259--265},
  Month       =  {11},
  Year        =  {2010},
  Language    = {en}
}

@online{ribominus,
  Title    = {{RiboMinus} Technology},
  Abstract = {RiboMinus technology is designed to enrich the whole spectrum of
              RNA transcripts by selectively depleting ribosomal RNA molecules
              (rRNA), regardless of their polyadenylation status or the
              presence of of a 5'-cap structure. The RiboMinus™ method has been
              shown to remove the vast majority of the most abundant ribosomal
              RNA molecules (up to 99.9\%) to allow for greater interrogation
              of less abundant transcripts.},
  Year={2011},
  Urldate={2017-06-15}
}

@article{polyAlncRNA,
  Title       = {Transcriptional maps of 10 human chromosomes at 5-nucleotide
                 resolution},
  Author      = {Cheng, Jill and Kapranov, Philipp and Drenkow, Jorg and Dike,
                 Sujit and Brubaker, Shane and Patel, Sandeep and Long, Jeffrey
                 and Stern, David and Tammana, Hari and Helt, Gregg and
                 Sementchenko, Victor and Piccolboni, Antonio and Bekiranov,
                 Stefan and Bailey, Dione K and Ganesh, Madhavan and Ghosh,
                 Srinka and Bell, Ian and Gerhard, Daniela S and Gingeras,
                 Thomas R},
  Abstract    = {Sites of transcription of polyadenylated and nonpolyadenylated
                 RNAs for 10 human chromosomes were mapped at 5-base pair
                 resolution in eight cell lines. Unannotated, nonpolyadenylated
                 transcripts comprise the major proportion of the
                 transcriptional output of the human genome. Of all transcribed
                 sequences, 19.4, 43.7, and 36.9\% were observed to be
                 polyadenylated, nonpolyadenylated, and bimorphic,
                 respectively. Half of all transcribed sequences are found only
                 in the nucleus and for the most part are unannotated. Overall,
                 the transcribed portions of the human genome are predominantly
                 composed of interlaced networks of both poly A+ and poly A-
                 annotated transcripts and unannotated transcripts of unknown
                 function. This organization has important implications for
                 interpreting genotype-phenotype associations, regulation of
                 gene expression, and the definition of a gene.},
  Journal     = {Science},
  Volume      =  {308},
  Number      =  {5725},
  Pages       = {1149--1154},
  Month       =  {06},
  Year        =  {2005},
  Language    = {en}
}

@article{captureSeq,
  Title       = {Improved definition of the mouse transcriptome via targeted
                 {RNA} sequencing},
  Author      = {Bussotti, Giovanni and Leonardi, Tommaso and Clark, Michael B
                 and Mercer, Tim R and Crawford, Joanna and Malquori, Lorenzo
                 and Notredame, Cedric and Dinger, Marcel E and Mattick, John S
                 and Enright, Anton J},
  Abstract    = {Targeted RNA sequencing (CaptureSeq) uses oligonucleotide
                 probes to capture RNAs for sequencing, providing enriched read
                 coverage, accurate measurement of gene expression, and
                 quantitative expression data. We applied CaptureSeq to refine
                 transcript annotations in the current murine GRCm38 assembly.
                 More than 23,000 regions corresponding to putative or
                 annotated long noncoding RNAs (lncRNAs) and 154,281 known
                 splicing junction sites were selected for targeted sequencing
                 across five mouse tissues and three brain subregions. The
                 results illustrate that the mouse transcriptome is
                 considerably more complex than previously thought. We assemble
                 more complete transcript isoforms than GENCODE, expand
                 transcript boundaries, and connect interspersed islands of
                 mapped reads. We describe a novel filtering pipeline that
                 identifies previously unannotated but high-quality transcript
                 isoforms. In this set, 911 GENCODE neighboring genes are
                 condensed into 400 expanded gene models. Additionally, 594
                 GENCODE lncRNAs acquire an open reading frame (ORF) when their
                 structure is extended with CaptureSeq. Finally, we validate
                 our observations using current FANTOM and Mouse ENCODE
                 resources.},
  Journal     = {Genome Research},
  Volume      =  {26},
  Number      =  {5},
  Pages       = {705--716},
  Month       =  {06},
  Year        =  {2016},
  Language    = {en}
}

@article{ribodepletion,
  Title       = {Selective depletion of {rRNA} enables whole transcriptome
                 profiling of archival fixed tissue},
  Author      = {Morlan, John D and Qu, Kunbin and Sinicropi, Dominick V},
  Abstract    = {We report a method for Selective Depletion of abundant RNA
                 (SDRNA) species from Human total RNA isolated from
                 formalin-fixed, paraffin-embedded (FFPE) tissue, here
                 demonstrating removal of ribosomal and mitochondrial
                 transcripts from clinical FFPE tissue RNA archived up to 20
                 years. Importantly, SDRNA removes 98\% of targeted RNAs while
                 preserving relative abundance profiles of non-targeted RNAs,
                 enabling routine whole transcriptome analysis of clinically
                 valuable archival tissue specimens by Next-Generation
                 Sequencing.},
  Journal     = {PLoS ONE},
  Volume      =  {7},
  Number      =  {8},
  Pages       = {e42882},
  Month       =  {08},
  Year        =  {2012},
  Language    = {en}
}

@article{moreReplicates,
  Title       = {{RNA-seq} differential expression studies: more sequence or
                 more replication?},
  Author      = {Liu, Yuwen and Zhou, Jie and White, Kevin P},
  Abstract    = {MOTIVATION: RNA-seq is replacing microarrays as the primary
                 tool for gene expression studies. Many RNA-seq studies have
                 used insufficient biological replicates, resulting in low
                 statistical power and inefficient use of sequencing resources.
                 RESULTS: We show the explicit trade-off between more
                 biological replicates and deeper sequencing in increasing
                 power to detect differentially expressed (DE) genes. In the
                 human cell line MCF7, adding more sequencing depth after 10 M
                 reads gives diminishing returns on power to detect DE genes,
                 whereas adding biological replicates improves power
                 significantly regardless of sequencing depth. We also propose
                 a cost-effectiveness metric for guiding the design of
                 large-scale RNA-seq DE studies. Our analysis showed that
                 sequencing less reads and performing more biological
                 replication is an effective strategy to increase power and
                 accuracy in large-scale differential expression RNA-seq
                 studies, and provided new insights into efficient experiment
                 design of RNA-seq studies. AVAILABILITY AND IMPLEMENTATION:
                 The code used in this paper is provided on:
                 http://home.uchicago.edu/∼jiezhou/replication/. The expression
                 data is deposited in the Gene Expression Omnibus under the
                 accession ID GSE51403.},
  Journal     = {Bioinformatics},
  Volume      =  {30},
  Number      =  {3},
  Pages       = {301--304},
  Month       =  {02},
  Year        =  {2014},
  Language    = {en}
}

@article{prepMethodBias,
  Title       = {Addressing Bias in Small {RNA} Library Preparation for
                 Sequencing: A New Protocol Recovers {MicroRNAs} that Evade
                 Capture by Current Methods},
  Author      = {Baran-Gale, Jeanette and Kurtz, C Lisa and Erdos, Michael R
                 and Sison, Christina and Young, Alice and Fannin, Emily E and
                 Chines, Peter S and Sethupathy, Praveen},
  Abstract    = {Recent advances in sequencing technology have helped unveil
                 the unexpected complexity and diversity of small RNAs. A
                 critical step in small RNA library preparation for sequencing
                 is the ligation of adapter sequences to both the 5' and 3'
                 ends of small RNAs. Studies have shown that adapter ligation
                 introduces a significant but widely unappreciated bias in the
                 results of high-throughput small RNA sequencing. We show that
                 due to this bias the two widely used Illumina library
                 preparation protocols produce strikingly different microRNA
                 (miRNA) expression profiles in the same batch of cells. There
                 are 102 highly expressed miRNAs that are >5-fold
                 differentially detected and some miRNAs, such as miR-24-3p,
                 are over 30-fold differentially detected. While some level of
                 bias in library preparation is not surprising, the apparent
                 massive differential bias between these two widely used
                 adapter sets is not well appreciated. In an attempt to
                 mitigate this bias, the new Bioo Scientific NEXTflex V2
                 protocol utilizes a pool of adapters with random nucleotides
                 at the ligation boundary. We show that this protocol is able
                 to detect robustly several miRNAs that evade capture by the
                 Illumina-based methods. While these analyses do not indicate a
                 definitive gold standard for small RNA library preparation,
                 the results of the NEXTflex protocol do correlate best with
                 RT-qPCR. As increasingly more laboratories seek to study small
                 RNAs, researchers should be aware of the extent to which the
                 results may differ with different protocols, and should make
                 an informed decision about the protocol that best fits their
                 study.},
  Journal     = {Frontiers in Genetics},
  Volume      =  {6},
  Pages       = {352},
  Month       =  {12},
  Year        =  {2015},
  Keywords    = {adapter dimers; adapter ligation bias; microRNA; sequencing;
                 small RNA library preparation},
  Language    = {en}
}

@article{RNAextraction,
  Title    = {Influence of {RNA} extraction methods and library selection
              schemes on {RNA-seq} data},
  Author   = {Sultan, Marc and Amstislavskiy, Vyacheslav and Risch, Thomas and
              Schuette, Moritz and D{\"o}kel, Simon and Ralser, Meryem and
              Balzereit, Daniela and Lehrach, Hans and Yaspo, Marie-Laure},
  Abstract = {Gene expression analysis by RNA sequencing is now widely used in
              a number of applications surveying the whole transcriptomes of
              cells and tissues. The recent introduction of ribosomal RNA
              depletion protocols, such as RiboZero, has extended the view of
              the polyadenylated transcriptome to the poly(A)- fraction of the
              RNA. However, substantial amounts of intronic transcriptional
              activity has been reported in RiboZero protocols, raising issues
              regarding their potential nuclear origin and the impact on the
              actual sequence depth in exonic regions.},
  Journal  = {BMC Genomics},
  Volume   =  {15},
  Number   =  {1},
  Pages    = {675},
  Year     =  {2014}
}

@article{notSoRandom,
  Title       = {Biases in Illumina transcriptome sequencing caused by random
                 hexamer priming},
  Author      = {Hansen, Kasper D and Brenner, Steven E and Dudoit, Sandrine},
  Abstract    = {Generation of cDNA using random hexamer priming induces biases
                 in the nucleotide composition at the beginning of
                 transcriptome sequencing reads from the Illumina Genome
                 Analyzer. The bias is independent of organism and laboratory
                 and impacts the uniformity of the reads along the
                 transcriptome. We provide a read count reweighting scheme,
                 based on the nucleotide frequencies of the reads, that
                 mitigates the impact of the bias.},
  Journal     = {Nucleic Acids Research},
  Volume      =  {38},
  Number      =  {12},
  Pages       = {e131},
  Month       =  {07},
  Year        =  {2010},
  Language    = {en}
}

@article{strandSpecific,
  Title       = {Comprehensive comparative analysis of strand-specific {RNA}
                 sequencing methods},
  Author      = {Levin, Joshua Z and Yassour, Moran and Adiconis, Xian and
                 Nusbaum, Chad and Thompson, Dawn Anne and Friedman, Nir and
                 Gnirke, Andreas and Regev, Aviv},
  Abstract    = {Strand-specific, massively parallel cDNA sequencing (RNA-seq)
                 is a powerful tool for transcript discovery, genome annotation
                 and expression profiling. There are multiple published methods
                 for strand-specific RNA-seq, but no consensus exists as to how
                 to choose between them. Here we developed a comprehensive
                 computational pipeline to compare library quality metrics from
                 any RNA-seq method. Using the well-annotated Saccharomyces
                 cerevisiae transcriptome as a benchmark, we compared seven
                 library-construction protocols, including both published and
                 our own methods. We found marked differences in strand
                 specificity, library complexity, evenness and continuity of
                 coverage, agreement with known annotations and accuracy for
                 expression profiling. Weighing each method's performance and
                 ease, we identified the dUTP second-strand marking and the
                 Illumina RNA ligation methods as the leading protocols, with
                 the former benefitting from the current availability of
                 paired-end sequencing. Our analysis provides a comprehensive
                 benchmark, and our computational pipeline is applicable for
                 assessment of future protocols in other organisms},
  Journal     = {Nature Methods},
  Volume      =  {7},
  Number      =  {9},
  Pages       = {709--715},
  Month       =  {09},
  Year        =  {2010},
  Language    = {en}
}

@article{strandSpe,
  Title       = {Transcriptome analysis by strand-specific sequencing of
                 complementary {DNA}},
  Author      = {Parkhomchuk, Dmitri and Borodina, Tatiana and Amstislavskiy,
                 Vyacheslav and Banaru, Maria and Hallen, Linda and Krobitsch,
                 Sylvia and Lehrach, Hans and Soldatov, Alexey},
  Abstract    = {High-throughput complementary DNA sequencing (RNA-Seq) is a
                 powerful tool for whole-transcriptome analysis, supplying
                 information about a transcript's expression level and
                 structure. However, it is difficult to determine the polarity
                 of transcripts, and therefore identify which strand is
                 transcribed. Here, we present a simple cDNA sequencing
                 protocol that preserves information about a transcript's
                 direction. Using Saccharomyces cerevisiae and mouse brain
                 transcriptomes as models, we demonstrate that knowing the
                 transcript's orientation allows more accurate determination of
                 the structure and expression of genes. It also helps to
                 identify new genes and enables studying promoter-associated
                 and antisense transcription. The transcriptional landscapes we
                 obtained are available online.},
  Journal     = {Nucleic Acids Research},
  Volume      =  {37},
  Number      =  {18},
  Pages       = {e123},
  Month       =  {10},
  Year        =  {2009},
  Language    = {en}
}

@article{smallRNAprotocol,
  Title     = {Small {RNA} Expression Profiling by {High-Throughput}
               Sequencing: Implications of Enzymatic Manipulation},
  Author    = {Zhuang, Fanglei and Fuchs, Ryan T and Robb, G Brett},
  Abstract  = {Eukaryotic regulatory small RNAs (sRNAs) play significant roles
               in many fundamental cellular processes. As such, they have
               emerged as useful biomarkers for diseases and cell
               differentiation states. sRNA-based biomarkers outperform
               traditional messenger RNA-based biomarkers by testing fewer
               targets with greater accuracy and providing earlier detection
               for disease states. Therefore, expression profiling of sRNAs is
               fundamentally important to further advance the understanding of
               biological processes, as well as diagnosis and treatment of
               diseases. High-throughput sequencing (HTS) is a powerful
               approach for both sRNA discovery and expression profiling. Here,
               we discuss the general considerations for sRNA-based HTS
               profiling methods from RNA preparation to sequencing library
               construction, with a focus on the causes of systematic error. By
               examining the enzymatic manipulation steps of sRNA expression
               profiling, this paper aims to demystify current HTS-based sRNA
               profiling approaches and to aid researchers in the informed
               design and interpretation of profiling experiments.},
  Journal   = {Journal of Nucleic Acids},
  Publisher = {Hindawi Publishing Corporation},
  Volume    =  {2012},
  Month     =  {06},
  Year      =  {2012},
  Language  = {en}
}

@article{batchEffect,
  Title       = {Tackling the widespread and critical impact of batch effects
                 in high-throughput data},
  Author      = {Leek, Jeffrey T and Scharpf, Robert B and Bravo, H{\'e}ctor
                 Corrada and Simcha, David and Langmead, Benjamin and Johnson,
                 W Evan and Geman, Donald and Baggerly, Keith and Irizarry,
                 Rafael A},
  Abstract    = {High-throughput technologies are widely used, for example to
                 assay genetic variants, gene and protein expression, and
                 epigenetic modifications. One often overlooked complication
                 with such studies is batch effects, which occur because
                 measurements are affected by laboratory conditions, reagent
                 lots and personnel differences. This becomes a major problem
                 when batch effects are correlated with an outcome of interest
                 and lead to incorrect conclusions. Using both published
                 studies and our own analyses, we argue that batch effects (as
                 well as other technical and biological artefacts) are
                 widespread and critical to address. We review experimental and
                 computational approaches for doing so.},
  Journal     = {Nature Reviews Genetics},
  Volume      =  {11},
  Number      =  {10},
  Pages       = {733--739},
  Month       =  {10},
  Year        =  {2010},
  Language    = {en}
}

@article{multiplexBatchEffect,
  Title       = {Statistical design and analysis of {RNA} sequencing data},
  Author      = {Auer, Paul L and Doerge, R W},
  Abstract    = {Next-generation sequencing technologies are quickly becoming
                 the preferred approach for characterizing and quantifying
                 entire genomes. Even though data produced from these
                 technologies are proving to be the most informative of any
                 thus far, very little attention has been paid to fundamental
                 design aspects of data collection and analysis, namely
                 sampling, randomization, replication, and blocking. We discuss
                 these concepts in an RNA sequencing framework. Using
                 simulations we demonstrate the benefits of collecting
                 replicated RNA sequencing data according to well known
                 statistical designs that partition the sources of biological
                 and technical variation. Examples of these designs and their
                 corresponding models are presented with the goal of testing
                 differential expression.},
  Journal     = {Genetics},
  Volume      =  {185},
  Number      =  {2},
  Pages       = {405--416},
  Month       =  {06},
  Year        =  {2010},
  Language    = {en},
  Issn        = {0016-6731, 1943-2631},
  Pmid        = {20439781},
  Doi         = {10.1534/genetics.110.114983},
  Pmc         = {PMC2881125}
}

@article{multiplexCheaper,
  Title       = {A cost-effective {RNA} sequencing protocol for large-scale
                 gene expression studies},
  Author      = {Hou, Zhonggang and Jiang, Peng and Swanson, Scott A and
                 Elwell, Angela L and Nguyen, Bao Kim S and Bolin, Jennifer M
                 and Stewart, Ron and Thomson, James A},
  Abstract    = {RNA sequencing has increasingly become an indispensable tool
                 for biological research. While sequencing costs have fallen
                 dramatically in recent years, the current cost of RNA
                 sequencing, nonetheless, remains a barrier to even more
                 widespread adoption. Here, we present a simple RNA sequencing
                 protocol with substantially reduced costs. This protocol uses
                 as little as 10 ng of total RNA, allows multiplex sequencing
                 of up to 96 samples per lane, and is strand specific.
                 Extensive validation using human embryonic stem cells showed
                 high consistency between technical replicates at various
                 multiplexing levels.},
  Journal     = {Scientific Reports},
  Volume      =  {5},
  Pages       = {9570},
  Month       = {04},
  Year        =  {2015},
  Language    = {en},
  Issn        = {2045-2322},
  Pmid        = {25831155},
  Doi         = {10.1038/srep09570},
  Pmc         = {PMC4381617}
}

@online{IlluminaYoutube,
    Title={Illumina Sequencing by Synthesis},
    Author={{Illumina Inc}},
    date={2016},
    Url={https://youtu.be/fCd6B5HRaZ8}
}

@article{seqBySynth,
  Title       = {Accurate whole human genome sequencing using reversible
                 terminator chemistry},
  Author      = {Bentley, David R and Balasubramanian, Shankar and Swerdlow,
                 Harold P and Smith, Geoffrey P and Milton, John and Brown,
                 Clive G and Hall, Kevin P and Evers, Dirk J and Barnes, Colin
                 L and Bignell, Helen R and Boutell, Jonathan M and Bryant,
                 Jason and Carter, Richard J and Keira Cheetham, R and Cox,
                 Anthony J and Ellis, Darren J and Flatbush, Michael R and
                 Gormley, Niall A and Humphray, Sean J and Irving, Leslie J and
                 Karbelashvili, Mirian S and Kirk, Scott M and Li, Heng and
                 Liu, Xiaohai and Maisinger, Klaus S and Murray, Lisa J and
                 Obradovic, Bojan and Ost, Tobias and Parkinson, Michael L and
                 Pratt, Mark R and Rasolonjatovo, Isabelle M J and Reed, Mark T
                 and Rigatti, Roberto and Rodighiero, Chiara and Ross, Mark T
                 and Sabot, Andrea and Sankar, Subramanian V and Scally, Aylwyn
                 and Schroth, Gary P and Smith, Mark E and Smith, Vincent P and
                 Spiridou, Anastassia and Torrance, Peta E and Tzonev, Svilen S
                 and Vermaas, Eric H and Walter, Klaudia and Wu, Xiaolin and
                 Zhang, Lu and Alam, Mohammed D and Anastasi, Carole and
                 Aniebo, Ify C and Bailey, David M D and Bancarz, Iain R and
                 Banerjee, Saibal and Barbour, Selena G and Baybayan, Primo A
                 and Benoit, Vincent A and Benson, Kevin F and Bevis, Claire
                 and Black, Phillip J and Boodhun, Asha and Brennan, Joe S and
                 Bridgham, John A and Brown, Rob C and Brown, Andrew A and
                 Buermann, Dale H and Bundu, Abass A and Burrows, James C and
                 Carter, Nigel P and Castillo, Nestor and Chiara E Catenazzi,
                 Maria and Chang, Simon and Neil Cooley, R and Crake, Natasha R
                 and Dada, Olubunmi O and Diakoumakos, Konstantinos D and
                 Dominguez-Fernandez, Belen and Earnshaw, David J and Egbujor,
                 Ugonna C and Elmore, David W and Etchin, Sergey S and Ewan,
                 Mark R and Fedurco, Milan and Fraser, Louise J and Fuentes
                 Fajardo, Karin V and Scott Furey, W and George, David and
                 Gietzen, Kimberley J and Goddard, Colin P and Golda, George S
                 and Granieri, Philip A and Green, David E and Gustafson, David
                 L and Hansen, Nancy F and Harnish, Kevin and Haudenschild,
                 Christian D and Heyer, Narinder I and Hims, Matthew M and Ho,
                 Johnny T and Horgan, Adrian M and Hoschler, Katya and Hurwitz,
                 Steve and Ivanov, Denis V and Johnson, Maria Q and James,
                 Terena and Huw Jones, T A and Kang, Gyoung-Dong and Kerelska,
                 Tzvetana H and Kersey, Alan D and Khrebtukova, Irina and
                 Kindwall, Alex P and Kingsbury, Zoya and Kokko-Gonzales, Paula
                 I and Kumar, Anil and Laurent, Marc A and Lawley, Cynthia T
                 and Lee, Sarah E and Lee, Xavier and Liao, Arnold K and Loch,
                 Jennifer A and Lok, Mitch and Luo, Shujun and Mammen, Radhika
                 M and Martin, John W and McCauley, Patrick G and McNitt, Paul
                 and Mehta, Parul and Moon, Keith W and Mullens, Joe W and
                 Newington, Taksina and Ning, Zemin and Ling Ng, Bee and Novo,
                 Sonia M and O'Neill, Michael J and Osborne, Mark A and
                 Osnowski, Andrew and Ostadan, Omead and Paraschos, Lambros L
                 and Pickering, Lea and Pike, Andrew C and Pike, Alger C and
                 Chris Pinkard, D and Pliskin, Daniel P and Podhasky, Joe and
                 Quijano, Victor J and Raczy, Come and Rae, Vicki H and
                 Rawlings, Stephen R and Chiva Rodriguez, Ana and Roe, Phyllida
                 M and Rogers, John and Rogert Bacigalupo, Maria C and Romanov,
                 Nikolai and Romieu, Anthony and Roth, Rithy K and Rourke,
                 Natalie J and Ruediger, Silke T and Rusman, Eli and
                 Sanches-Kuiper, Raquel M and Schenker, Martin R and Seoane,
                 Josefina M and Shaw, Richard J and Shiver, Mitch K and Short,
                 Steven W and Sizto, Ning L and Sluis, Johannes P and Smith,
                 Melanie A and Ernest Sohna Sohna, Jean and Spence, Eric J and
                 Stevens, Kim and Sutton, Neil and Szajkowski, Lukasz and
                 Tregidgo, Carolyn L and Turcatti, Gerardo and Vandevondele,
                 Stephanie and Verhovsky, Yuli and Virk, Selene M and Wakelin,
                 Suzanne and Walcott, Gregory C and Wang, Jingwen and Worsley,
                 Graham J and Yan, Juying and Yau, Ling and Zuerlein, Mike and
                 Rogers, Jane and Mullikin, James C and Hurles, Matthew E and
                 McCooke, Nick J and West, John S and Oaks, Frank L and
                 Lundberg, Peter L and Klenerman, David and Durbin, Richard and
                 Smith, Anthony J},
  Abstract    = {DNA sequence information underpins genetic research, enabling
                 discoveries of important biological or medical benefit.
                 Sequencing projects have traditionally used long (400-800 base
                 pair) reads, but the existence of reference sequences for the
                 human and many other genomes makes it possible to develop new,
                 fast approaches to re-sequencing, whereby shorter reads are
                 compared to a reference to identify intraspecies genetic
                 variation. Here we report an approach that generates several
                 billion bases of accurate nucleotide sequence per experiment
                 at low cost. Single molecules of DNA are attached to a flat
                 surface, amplified in situ and used as templates for synthetic
                 sequencing with fluorescent reversible terminator
                 deoxyribonucleotides. Images of the surface are analysed to
                 generate high-quality sequence. We demonstrate application of
                 this approach to human genome sequencing on flow-sorted X
                 chromosomes and then scale the approach to determine the
                 genome sequence of a male Yoruba from Ibadan, Nigeria. We
                 build an accurate consensus sequence from >30x average depth
                 of paired 35-base reads. We characterize four million
                 single-nucleotide polymorphisms and four hundred thousand
                 structural variants, many of which were previously unknown.
                 Our approach is effective for accurate, rapid and economical
                 whole-genome re-sequencing and many other biomedical
                 applications.},
  Journal     = {Nature},
  Volume      =  {456},
  Number      =  {7218},
  Pages       = {53--59},
  Month       =  {11},
  Year        =  {2008},
  Language    = {en},
  Issn        = {0028-0836, 1476-4687},
  Pmid        = {18987734},
  Doi         = {10.1038/nature07517},
  Pmc         = {PMC2581791}
}

@article{pairedEndAdapters,
  Title       = {Next-generation sequencing platforms},
  Author      = {Mardis, Elaine R},
  Abstract    = {Automated DNA sequencing instruments embody an elegant
                 interplay among chemistry, engineering, software, and
                 molecular biology and have built upon Sanger's founding
                 discovery of dideoxynucleotide sequencing to perform
                 once-unfathomable tasks. Combined with innovative physical
                 mapping approaches that helped to establish long-range
                 relationships between cloned stretches of genomic DNA,
                 fluorescent DNA sequencers produced reference genome sequences
                 for model organisms and for the reference human genome. New
                 types of sequencing instruments that permit amazing
                 acceleration of data-collection rates for DNA sequencing have
                 been developed. The ability to generate genome-scale data sets
                 is now transforming the nature of biological inquiry. Here, I
                 provide an historical perspective of the field, focusing on
                 the fundamental developments that predated the advent of
                 next-generation sequencing instruments and providing
                 information about how these instruments work, their
                 application to biological research, and the newest types of
                 sequencers that can extract data from single DNA molecules.},
  Journal     = {Annual Review of Analytical Chemistry},
  Volume      =  {6},
  Pages       = {287--303},
  Year        =  {2013},
  Language    = {en},
  Issn        = {1936-1327, 1936-1335},
  Pmid        = {23560931},
  Doi         = {10.1146/annurev-anchem-062012-092628}
}

@article{fastqFormat,
  Title       = {The Sanger {FASTQ} file format for sequences with quality
                 scores, and the {Solexa/Illumina} {FASTQ} variants},
  Author      = {Cock, Peter J A and Fields, Christopher J and Goto, Naohisa
                 and Heuer, Michael L and Rice, Peter M},
  Abstract    = {FASTQ has emerged as a common file format for sharing
                 sequencing read data combining both the sequence and an
                 associated per base quality score, despite lacking any formal
                 definition to date, and existing in at least three
                 incompatible variants. This article defines the FASTQ format,
                 covering the original Sanger standard, the Solexa/Illumina
                 variants and conversion between them, based on publicly
                 available information such as the MAQ documentation and
                 conventions recently agreed by the Open Bioinformatics
                 Foundation projects Biopython, BioPerl, BioRuby, BioJava and
                 EMBOSS. Being an open access publication, it is hoped that
                 this description, with the example files provided as
                 Supplementary Data, will serve in future as a reference for
                 this important file format.},
  Journal     = {Nucleic Acids Research},
  Volume      =  {38},
  Number      =  {6},
  Pages       = {1767--1771},
  Month       =  {04},
  Year        =  {2010},
  Language    = {en},
  Issn        = {0305-1048, 1362-4962},
  Pmid        = {20015970},
  Doi         = {10.1093/nar/gkp1137},
  Pmc         = {PMC2847217}
}

@unpublished{rnaDirectSeq,
  Title    = {Highly parallel direct {RNA} sequencing on an array of nanopores},
  Author   = {Garalde, Daniel R and Snell, Elizabeth A and Jachimowicz, Daniel
              and Heron, Andrew J and Bruce, Mark and Lloyd, Joseph and
              Warland, Anthony and Pantic, Nadia and Admassu, Tigist and
              Ciccone, Jonah and Serra, Sabrina and Keenan, Jemma and Martin,
              Samuel and McNeill, Luke and Wallace, Jayne and Jayasinghe,
              Lakmal and Wright, Chris and Blasco, Javier and Sipos, Botond and
              Young, Stephen and Juul, Sissel and Clarke, James and Turner,
              Daniel J},
  Abstract = {Ribonucleic acid sequencing can allow us to monitor the RNAs
              present in a sample. This enables us to detect the presence and
              nucleotide sequence of viruses, or to build a picture of how
              active transcriptional processes are changing -- information that
              is useful for understanding the status and function of a sample.
              Nanopore-based sequencing technology is capable of electronically
              analysing a sample9s DNA directly, and in real-time. In this
              manuscript we demonstrate the ability of an array of nanopores to
              sequence RNA directly, and we apply it to a range of biological
              situations. Nanopore technology is the only available sequencing
              technology which can sequence RNA directly, rather than depending
              on reverse transcription and PCR. There are several potential
              advantages of this approach over other RNA-seq strategies,
              including the absence of amplification and reverse transcription
              biases, the ability to detect nucleotide analogues and the
              ability to generate full-length, strand-specific RNA sequences.
              This will improve the ease and speed of RNA analysis, while
              yielding richer biological information.},
  Journal  = {bioRxiv},
  Pages    = {068809},
  Month    = {08},
  Year     = {2016},
  Language = {en},
  Doi      = {10.1101/068809}
}

@article{popularIllumina,
  Title       = {A defining decade in {DNA} sequencing},
  Author      = {McPherson, John D},
  Journal     = {Nature Methods},
  Volume      =  {11},
  Number      =  {10},
  Pages       = {1003--1005},
  Month       =  {10},
  Year        =  {2014},
  Language    = {en},
  Issn        = {1548-7091, 1548-7105},
  Pmid        = {25264775},
  Doi         = {10.1038/nmeth.3106}
}

@article{rrnaStudy,
  Title       = {High resolution profiling of coral-associated bacterial
                 communities using full-length {16S} {rRNA} sequence data from
                 {PacBio} {SMRT} sequencing system},
  Author      = {Pootakham, Wirulda and Mhuantong, Wuttichai and Yoocha,
                 Thippawan and Putchim, Lalita and Sonthirod, Chutima and
                 Naktang, Chaiwat and Thongtham, Nalinee and Tangphatsornruang,
                 Sithichoke},
  Abstract    = {Coral reefs are a complex ecosystem consisting of coral
                 animals and a vast array of associated symbionts including the
                 dinoflagellate Symbiodinium, fungi, viruses and bacteria.
                 Several studies have highlighted the importance of
                 coral-associated bacteria and their fundamental roles in
                 fitness and survival of the host animal. The scleractinian
                 coral Porites lutea is one of the dominant reef-builders in
                 the Indo-West Pacific. Currently, very little is known about
                 the composition and structure of bacterial communities across
                 P. lutea reefs. The purpose of this study is twofold: to
                 demonstrate the advantages of using PacBio circular consensus
                 sequencing technology in microbial community studies and to
                 investigate the diversity and structure of P. lutea-associated
                 microbiome in the Indo-Pacific. This is the first metagenomic
                 study of marine environmental samples that utilises the PacBio
                 sequencing system to capture full-length 16S rRNA sequences.
                 We observed geographically distinct coral-associated microbial
                 profiles between samples from the Gulf of Thailand and Andaman
                 Sea. Despite the geographical and environmental impacts on the
                 coral-host interactions, we identified a conserved community
                 of bacteria that were present consistently across diverse reef
                 habitats. Finally, we demonstrated the superior performance of
                 full-length 16S rRNA sequences in resolving taxonomic
                 uncertainty of coral associates at the species level.},
  Journal     = {Scientific Reports},
  Volume      =  {7},
  Number      =  {1},
  Pages       = {2774},
  Month       =  {06},
  Year        =  {2017},
  Language    = {en},
  Issn        = {2045-2322},
  Pmid        = {28584301},
  Doi         = {10.1038/s41598-017-03139-4},
  Pmc         = {PMC5459821}
}

@article{phredScale,
  Title       = {A glance at quality score: implication for de novo
                 transcriptome reconstruction of Illumina reads},
  Author      = {Mbandi, Stanley Kimbung and Hesse, Uljana and Rees, D Jasper G
                 and Christoffels, Alan},
  Abstract    = {Downstream analyses of short-reads from next-generation
                 sequencing platforms are often preceded by a pre-processing
                 step that removes uncalled and wrongly called bases. Standard
                 approaches rely on their associated base quality scores to
                 retain the read or a portion of it when the score is above a
                 predefined threshold. It is difficult to differentiate
                 sequencing error from biological variation without a reference
                 using quality scores. The effects of quality score based
                 trimming have not been systematically studied in de novo
                 transcriptome assembly. Using RNA-Seq data produced from
                 Illumina, we teased out the effects of quality score based
                 filtering or trimming on de novo transcriptome reconstruction.
                 We showed that assemblies produced from reads subjected to
                 different quality score thresholds contain truncated and
                 missing transfrags when compared to those from untrimmed
                 reads. Our data supports the fact that de novo assembling of
                 untrimmed data is challenging for de Bruijn graph assemblers.
                 However, our results indicates that comparing the assemblies
                 from untrimmed and trimmed read subsets can suggest
                 appropriate filtering parameters and enable selection of the
                 optimum de novo transcriptome assembly in non-model organisms.},
  Journal     = {Frontiers in Genetics},
  Volume      =  {5},
  Pages       = {17},
  Month       =  {02},
  Year        =  {2014},
  Keywords    = {Oases; RNA-Seq; Trinity; quality score; transcriptome
                 reconstruction; truncated transfrags},
  Language    = {en},
  Issn        = {1664-8021},
  Pmid        = {24575122},
  Doi         = {10.3389/fgene.2014.00017},
  Pmc         = {PMC3921913}
}

@article{reviewRNAseqBestpractice,
  Title       = {A survey of best practices for {RNA-seq} data analysis},
  Author      = {Conesa, Ana and Madrigal, Pedro and Tarazona, Sonia and
                 Gomez-Cabrero, David and Cervera, Alejandra and McPherson,
                 Andrew and Szcześniak, Michał Wojciech and Gaffney, Daniel J
                 and Elo, Laura L and Zhang, Xuegong and Mortazavi, Ali},
  Abstract    = {RNA-sequencing (RNA-seq) has a wide variety of applications,
                 but no single analysis pipeline can be used in all cases. We
                 review all of the major steps in RNA-seq data analysis,
                 including experimental design, quality control, read
                 alignment, quantification of gene and transcript levels,
                 visualization, differential gene expression, alternative
                 splicing, functional analysis, gene fusion detection and eQTL
                 mapping. We highlight the challenges associated with each
                 step. We discuss the analysis of small RNAs and the
                 integration of RNA-seq with other functional genomics
                 techniques. Finally, we discuss the outlook for novel
                 technologies that are changing the state of the art in
                 transcriptomics.},
  Journal     = {Genome Biology},
  Volume      =  {17},
  Pages       = {13},
  Month       =  {01},
  Year        =  {2016},
  Language    = {en},
  Issn        = {1465-6906},
  Pmid        = {26813401},
  Doi         = {10.1186/s13059-016-0881-8},
  Pmc         = {PMC4728800}
}

@article{TrimRNAseq,
  Title       = {Evaluation of genomic high-throughput sequencing data
                 generated on Illumina {HiSeq} and genome analyzer systems},
  Author      = {Minoche, André E and Dohm, Juliane C and Himmelbauer, Heinz},
  Abstract    = {BACKGROUND: The generation and analysis of high-throughput
                 sequencing data are becoming a major component of many studies
                 in molecular biology and medical research. Illumina's Genome
                 Analyzer (GA) and HiSeq instruments are currently the most
                 widely used sequencing devices. Here, we comprehensively
                 evaluate properties of genomic HiSeq and GAIIx data derived
                 from two plant genomes and one virus, with read lengths of 95
                 to 150 bases. RESULTS: We provide quantifications and evidence
                 for GC bias, error rates, error sequence context, effects of
                 quality filtering, and the reliability of quality values. By
                 combining different filtering criteria we reduced error rates
                 7-fold at the expense of discarding 12.5\% of alignable bases.
                 While overall error rates are low in HiSeq data we observed
                 regions of accumulated wrong base calls. Only 3\% of all error
                 positions accounted for 24.7\% of all substitution errors.
                 Analyzing the forward and reverse strands separately revealed
                 error rates of up to 18.7\%. Insertions and deletions occurred
                 at very low rates on average but increased to up to 2\% in
                 homopolymers. A positive correlation between read coverage and
                 GC content was found depending on the GC content range.
                 CONCLUSIONS: The errors and biases we report have implications
                 for the use and the interpretation of Illumina sequencing
                 data. GAIIx and HiSeq data sets show slightly different error
                 profiles. Quality filtering is essential to minimize
                 downstream analysis artifacts. Supporting previous
                 recommendations, the strand-specificity provides a criterion
                 to distinguish sequencing errors from low abundance
                 polymorphisms.},
  Journal     = {Genome Biology},
  Volume      =  {12},
  Number      =  {11},
  Pages       = {R112},
  Month       =  {11},
  Year        =  {2011},
  Language    = {en},
  Issn        = {1465-6906},
  Pmid        = {22067484},
  Doi         = {10.1186/gb-2011-12-11-r112},
  Pmc         = {PMC3334598}
}

@article{dnaseqCorr,
  Title       = {Identifying and mitigating bias in next-generation sequencing
                 methods for chromatin biology},
  Author      = {Meyer, Clifford A and Liu, X Shirley},
  Abstract    = {Next-generation sequencing (NGS) technologies have been used
                 in diverse ways to investigate various aspects of chromatin
                 biology by identifying genomic loci that are bound by
                 transcription factors, occupied by nucleosomes or accessible
                 to nuclease cleavage, or loci that physically interact with
                 remote genomic loci. However, reaching sound biological
                 conclusions from such NGS enrichment profiles requires many
                 potential biases to be taken into account. In this Review, we
                 discuss common ways in which biases may be introduced into NGS
                 chromatin profiling data, approaches to diagnose these biases
                 and analytical techniques to mitigate their effect.},
  Journal     = {Nature Reviews Genetics},
  Volume      = {15},
  Number      = {11},
  Pages       = {709--721},
  Month       = {11},
  Year        = {2014},
  Language    = {en},
  Issn        = {1471-0056, 1471-0064},
  Pmid        = {25223782},
  Doi         = {10.1038/nrg3788},
  Pmc         = {PMC4473780}
}

@online{readMappingDef,
  Title        = {What is a read mapping?},
  Booktitle    = {Bits of {DNA}},
  Author       = {Pachter, Lior},
  Month        = {11},
  Year         = {2015},
  Url = {https://liorpachter.wordpress.com/2015/11/01/what-is-a-read-mapping/},
  Note         = {Accessed: 2017-6-27}
}

@phdthesis{MarPhD,
  Author       = {Mar Gonzàlez-Porta},
  Title        = {RNA sequencing for the study of splicing},
  School       = {University of Cambridge},
  Year         = {2014}
}

@phdthesis{AngelaPhD,
  Author       = {Ângela Teresa Filimon Gonçalves},
  Title        = {RNA sequencing for the study of gene expression regulation},
  School       = {University of Cambridge},
  Year         = {2012}
}

@article{denovoReview,
  Title       = {Next-generation transcriptome assembly},
  Author      = {Martin, Jeffrey A and Wang, Zhong},
  Abstract    = {Transcriptomics studies often rely on partial reference
                 transcriptomes that fail to capture the full catalogue of
                 transcripts and their variations. Recent advances in
                 sequencing technologies and assembly algorithms have
                 facilitated the reconstruction of the entire transcriptome by
                 deep RNA sequencing (RNA-seq), even without a reference
                 genome. However, transcriptome assembly from billions of
                 RNA-seq reads, which are often very short, poses a significant
                 informatics challenge. This Review summarizes the recent
                 developments in transcriptome assembly approaches -
                 reference-based, de novo and combined strategies - along with
                 some perspectives on transcriptome assembly in the near
                 future.},
  Journal     = {Nature Reviews Genetics},
  Volume      = {12},
  Number      = {10},
  Pages       = {671--682},
  Month       = {09},
  Year        = {2011},
  Language    = {en},
  Issn        = {1471-0056, 1471-0064},
  Pmid        = {21897427},
  Doi         = {10.1038/nrg3068}
}

@article{algorithmsDenovo,
  Title       = {Review of general algorithmic features for genome assemblers
                 for next generation sequencers},
  Author      = {Wajid, Bilal and Serpedin, Erchin},
  Abstract    = {In the realm of bioinformatics and computational biology, the
                 most rudimentary data upon which all the analysis is built is
                 the sequence data of genes, proteins and RNA. The sequence
                 data of the entire genome is the solution to the genome
                 assembly problem. The scope of this contribution is to provide
                 an overview on the art of problem-solving applied within the
                 domain of genome assembly in the next-generation sequencing
                 (NGS) platforms. This article discusses the major genome
                 assemblers that were proposed in the literature during the
                 past decade by outlining their basic working principles. It is
                 intended to act as a qualitative, not a quantitative, tutorial
                 to all working on genome assemblers pertaining to the next
                 generation of sequencers. We discuss the theoretical aspects
                 of various genome assemblers, identifying their working
                 schemes. We also discuss briefly the direction in which the
                 area is headed towards along with discussing core issues on
                 software simplicity.},
  Journal     = {Genomics, Proteomics \& Bioinformatics},
  Volume      = {10},
  Number      =  {2},
  Pages       = {58--73},
  Month       =  {04},
  Year        =  {2012},
  Language    = {en},
  Issn        = {1672-0229, 2210-3244},
  Pmid        = {22768980},
  Doi         = {10.1016/j.gpb.2012.05.006},
  Pmc         = {PMC5054208}
}

@article{deBruijn,
  Title       = {De novo assembly and analysis of {RNA-seq} data},
  Author      = {Robertson, Gordon and Schein, Jacqueline and Chiu, Readman and
                 Corbett, Richard and Field, Matthew and Jackman, Shaun D and
                 Mungall, Karen and Lee, Sam and Okada, Hisanaga Mark and Qian,
                 Jenny Q and Griffith, Malachi and Raymond, Anthony and
                 Thiessen, Nina and Cezard, Timothee and Butterfield, Yaron S
                 and Newsome, Richard and Chan, Simon K and She, Rong and
                 Varhol, Richard and Kamoh, Baljit and Prabhu, Anna-Liisa and
                 Tam, Angela and Zhao, Yongjun and Moore, Richard A and Hirst,
                 Martin and Marra, Marco A and Jones, Steven J M and Hoodless,
                 Pamela A and Birol, Inanc},
 Abstract    = {We describe Trans-ABySS, a de novo short-read transcriptome
                 assembly and analysis pipeline that addresses variation in
                 local read densities by assembling read substrings with
                 varying stringencies and then merging the resulting contigs
                 before analysis. Analyzing 7.4 gigabases of 50-base-pair
                 paired-end Illumina reads from an adult mouse liver poly(A)
                 RNA library, we identified known, new and alternative
                 structures in expressed transcripts, and achieved high
                 sensitivity and specificity relative to reference-based
                 assembly methods.},
  Journal     = {Nature Methods},
  Volume      = {7},
  Number      = {11},
  Pages       = {909--912},
  Month       = {11},
  Year        = {2010},
  Language    = {en},
  Issn        = {1548-7091, 1548-7105},
  Pmid        = {20935650},
  Doi         = {10.1038/nmeth.1517}
}

@article{Bowtie,
  Title       = {Ultrafast and memory-efficient alignment of short {DNA}
                 sequences to the human genome},
  Author      = {Langmead, Ben and Trapnell, Cole and Pop, Mihai and Salzberg,
                 Steven L},
  Abstract    = {Bowtie is an ultrafast, memory-efficient alignment program for
                 aligning short DNA sequence reads to large genomes. For the
                 human genome, Burrows-Wheeler indexing allows Bowtie to align
                 more than 25 million reads per CPU hour with a memory
                 footprint of approximately 1.3 gigabytes. Bowtie extends
                 previous Burrows-Wheeler techniques with a novel quality-aware
                 backtracking algorithm that permits mismatches. Multiple
                 processor cores can be used simultaneously to achieve even
                 greater alignment speeds. Bowtie is open source
                 (http://bowtie.cbcb.umd.edu).},
  Journal     = {Genome Biology},
  Volume      =  {10},
  Number      =  {3},
  Pages       = {R25},
  Month       =  {03},
  Year        =  {2009},
  Language    = {en},
  Issn        = {1465-6906},
  Pmid        = {19261174},
  Doi         = {10.1186/gb-2009-10-3-r25},
  Pmc         = {PMC2690996}
}

@article{SAMformat,
  Title       = {The Sequence {Alignment/Map} format and {SAMtools}},
  Author      = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim
                 and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis,
                 Goncalo and Durbin, Richard and {1000 Genome Project Data
                 Processing Subgroup}},
  Abstract    = {SUMMARY: The Sequence Alignment/Map (SAM) format is a generic
                 alignment format for storing read alignments against reference
                 sequences, supporting short and long reads (up to 128 Mbp)
                 produced by different sequencing platforms. It is flexible in
                 style, compact in size, efficient in random access and is the
                 format in which alignments from the 1000 Genomes Project are
                 released. SAMtools implements various utilities for
                 post-processing alignments in the SAM format, such as
                 indexing, variant caller and alignment viewer, and thus
                 provides universal tools for processing read alignments.
                 AVAILABILITY: http://samtools.sourceforge.net.},
  Journal     = {Bioinformatics},
  Volume      =  {25},
  Number      =  {16},
  Pages       = {2078--2079},
  Month       =  {08},
  Year        =  {2009},
  Language    = {en},
  Issn        = {1367-4803, 1367-4811},
  Pmid        = {19505943},
  Doi         = {10.1093/bioinformatics/btp352},
  Pmc         = {PMC2723002}
}

@article{htseq,
  Title       = {{HTSeq--a} Python framework to work with high-throughput
                 sequencing data},
  Author      = {Anders, Simon and Pyl, Paul Theodor and Huber, Wolfgang},
  Abstract    = {MOTIVATION: A large choice of tools exists for many standard
                 tasks in the analysis of high-throughput sequencing (HTS)
                 data. However, once a project deviates from standard
                 workflows, custom scripts are needed. RESULTS: We present
                 HTSeq, a Python library to facilitate the rapid development of
                 such scripts. HTSeq offers parsers for many common data
                 formats in HTS projects, as well as classes to represent data,
                 such as genomic coordinates, sequences, sequencing reads,
                 alignments, gene model information and variant calls, and
                 provides data structures that allow for querying via genomic
                 coordinates. We also present htseq-count, a tool developed
                 with HTSeq that preprocesses RNA-Seq data for differential
                 expression analysis by counting the overlap of reads with
                 genes. AVAILABILITY AND IMPLEMENTATION: HTSeq is released as
                 an open-source software under the GNU General Public Licence
                 and available from http://www-huber.embl.de/HTSeq or from the
                 Python Package Index at https://pypi.python.org/pypi/HTSeq.},
  Journal     = {Bioinformatics},
  Volume      = {31},
  Number      = {2},
  Pages       = {166--169},
  Month       = {01},
  Year        = {2015},
  Language    = {en},
  Issn        = {1367-4803, 1367-4811},
  Pmid        = {25260700},
  Doi         = {10.1093/bioinformatics/btu638},
  Pmc         = {PMC4287950}
}

@article{hisat,
  Title       = {{HISAT}: a fast spliced aligner with low memory requirements},
  Author      = {Kim, Daehwan and Langmead, Ben and Salzberg, Steven L},
  Abstract    = {HISAT (hierarchical indexing for spliced alignment of
                 transcripts) is a highly efficient system for aligning reads
                 from RNA sequencing experiments. HISAT uses an indexing scheme
                 based on the Burrows-Wheeler transform and the
                 Ferragina-Manzini (FM) index, employing two types of indexes
                 for alignment: a whole-genome FM index to anchor each
                 alignment and numerous local FM indexes for very rapid
                 extensions of these alignments. HISAT's hierarchical index for
                 the human genome contains 48,000 local FM indexes, each
                 representing a genomic region of ∼64,000 bp. Tests on real and
                 simulated data sets showed that HISAT is the fastest system
                 currently available, with equal or better accuracy than any
                 other method. Despite its large number of indexes, HISAT
                 requires only 4.3 gigabytes of memory. HISAT supports genomes
                 of any size, including those larger than 4 billion bases.},
  Journal     = {Nature Methods},
  Volume      = {12},
  Number      = {4},
  Pages       = {357--360},
  Month       = {04},
  Year        = {2015},
  Language    = {en},
  Issn        = {1548-7091, 1548-7105},
  Pmid        = {25751142},
  Doi         = {10.1038/nmeth.3317},
  Pmc         = {PMC4655817}
}

@article{STARpaper,
  Title       = {{STAR}: ultrafast universal {RNA-seq} aligner},
  Author      = {Dobin, Alexander and Davis, Carrie A and Schlesinger, Felix
                 and Drenkow, Jorg and Zaleski, Chris and Jha, Sonali and
                 Batut, Philippe and Chaisson, Mark and Gingeras, Thomas R},
  Abstract    = {MOTIVATION: Accurate alignment of high-throughput RNA-seq data
                 is a challenging and yet unsolved problem because of the
                 non-contiguous transcript structure, relatively short read
                 lengths and constantly increasing throughput of the sequencing
                 technologies. Currently available RNA-seq aligners suffer from
                 high mapping error rates, low mapping speed, read length
                 limitation and mapping biases. RESULTS: To align our large
                 (>80 billon reads) ENCODE Transcriptome RNA-seq dataset, we
                 developed the Spliced Transcripts Alignment to a Reference
                 (STAR) software based on a previously undescribed RNA-seq
                 alignment algorithm that uses sequential maximum mappable seed
                 search in uncompressed suffix arrays followed by seed
                 clustering and stitching procedure. STAR outperforms other
                 aligners by a factor of >50 in mapping speed, aligning to the
                 human genome 550 million 2 × 76 bp paired-end reads per hour
                 on a modest 12-core server, while at the same time improving
                 alignment sensitivity and precision. In addition to unbiased
                 de novo detection of canonical junctions, STAR can discover
                 non-canonical splices and chimeric (fusion) transcripts, and
                 is also capable of mapping full-length RNA sequences. Using
                 Roche 454 sequencing of reverse transcription polymerase chain
                 reaction amplicons, we experimentally validated 1960 novel
                 intergenic splice junctions with an 80-90\% success rate,
                 corroborating the high precision of the STAR mapping strategy.
                 AVAILABILITY AND IMPLEMENTATION: STAR is implemented as a
                 standalone C++ code. STAR is free open source software
                 distributed under GPLv3 license and can be downloaded from
                 http://code.google.com/p/rna-star/.},
  Journal     = {Bioinformatics},
  Volume      = {29},
  Number      = {1},
  Pages       = {15--21},
  Month       = {01},
  Year        = {2013},
  Language    = {en},
  Issn        = {1367-4803, 1367-4811},
  Pmid        = {23104886},
  Doi         = {10.1093/bioinformatics/bts635},
  Pmc         = {PMC3530905}
}

@article{tophatStarwhatever,
  Title       = {Benchmarking of {RNA-sequencing} analysis workflows using
                 whole-transcriptome {RT-qPCR} expression data},
  Author      = {Everaert, Celine and Luypaert, Manuel and Maag, Jesper L V and
                 Cheng, Quek Xiu and Dinger, Marcel E and Hellemans, Jan and
                 Mestdagh, Pieter},
  Abstract    = {RNA-sequencing has become the gold standard for
                 whole-transcriptome gene expression quantification. Multiple
                 algorithms have been developed to derive gene counts from
                 sequencing reads. While a number of benchmarking studies have
                 been conducted, the question remains how individual methods
                 perform at accurately quantifying gene expression levels from
                 RNA-sequencing reads. We performed an independent benchmarking
                 study using RNA-sequencing data from the well established
                 MAQCA and MAQCB reference samples. RNA-sequencing reads were
                 processed using five workflows (Tophat-HTSeq,
                 Tophat-Cufflinks, STAR-HTSeq, Kallisto and Salmon) and
                 resulting gene expression measurements were compared to
                 expression data generated by wet-lab validated qPCR assays for
                 all protein coding genes. All methods showed high gene
                 expression correlations with qPCR data. When comparing gene
                 expression fold changes between MAQCA and MAQCB samples, about
                 85\% of the genes showed consistent results between
                 RNA-sequencing and qPCR data. Of note, each method revealed a
                 small but specific gene set with inconsistent expression
                 measurements. A significant proportion of these
                 method-specific inconsistent genes were reproducibly
                 identified in independent datasets. These genes were typically
                 smaller, had fewer exons, and were lower expressed compared to
                 genes with consistent expression measurements. We propose that
                 careful validation is warranted when evaluating RNA-seq based
                 expression profiles for this specific gene set.},
  Journal     = {Scientific reports},
  Volume      = {7},
  Number      = {1},
  Pages       = {1559},
  Month       = {05},
  Year        = {2017},
  Language    = {en},
  Issn        = {2045-2322},
  Pmid        = {28484260},
  Doi         = {10.1038/s41598-017-01617-3},
  Pmc         = {PMC5431503}
}

@article{errorsRNAquant,
  Title       = {Errors in {RNA-Seq} quantification affect genes of relevance
                 to human disease},
  Author      = {Robert, Christelle and Watson, Mick},
  Abstract    = {BACKGROUND: RNA-Seq has emerged as the standard for measuring
                 gene expression and is an important technique often used in
                 studies of human disease. Gene expression quantification
                 involves comparison of the sequenced reads to a known genomic
                 or transcriptomic reference. The accuracy of that
                 quantification relies on there being enough unique information
                 in the reads to enable bioinformatics tools to accurately
                 assign the reads to the correct gene. RESULTS: We apply 12
                 common methods to estimate gene expression from RNA-Seq data
                 and show that there are hundreds of genes whose expression is
                 underestimated by one or more of those methods. Many of these
                 genes have been implicated in human disease, and we describe
                 their roles. We go on to propose a two-stage analysis of
                 RNA-Seq data in which multi-mapped or ambiguous reads can
                 instead be uniquely assigned to groups of genes. We apply this
                 method to a recently published mouse cancer study, and
                 demonstrate that we can extract relevant biological signal
                 from data that would otherwise have been discarded.
                 CONCLUSIONS: For hundreds of genes in the human genome,
                 RNA-Seq is unable to measure expression accurately. These
                 genes are enriched for gene families, and many of them have
                 been implicated in human disease. We show that it is possible
                 to use data that may otherwise have been discarded to measure
                 group-level expression, and that such data contains
                 biologically relevant information.},
  Journal     = {Genome Biology},
  Volume      = {16},
  Pages       = {177},
  Month       = {09},
  Year        = {2015},
  Language    = {en},
  Issn        = {1465-6906},
  Pmid        = {26335491},
  Doi         = {10.1186/s13059-015-0734-x},
  Pmc         = {PMC4558956}
}

@article{oneDominant,
  Title    = {Transcriptome analysis of human tissues and cell lines reveals
              one dominant transcript per gene},
  Author   = {Gonzàlez-Porta, Mar and Frankish, Adam and Rung, Johan and
              Harrow, Jennifer and Brazma, Alvis},
  Abstract = {BACKGROUND: RNA sequencing has opened new avenues for the study
              of transcriptome composition. Significant evidence has
              accumulated showing that the human transcriptome contains in
              excess of a hundred thousand different transcripts. However, it
              is still not clear to what extent this diversity prevails when
              considering the relative abundances of different transcripts from
              the same gene. RESULTS: Here we show that, in a given condition,
              most protein coding genes have one major transcript expressed at
              significantly higher level than others, that in human tissues the
              major transcripts contribute almost 85 percent to the total mRNA
              from protein coding loci, and that often the same major
              transcript is expressed in many tissues. We detect a high degree
              of overlap between the set of major transcripts and a recently
              published set of alternatively spliced transcripts that are
              predicted to be translated utilizing proteomic data. Thus, we
              hypothesize that although some minor transcripts may play a
              functional role, the major ones are likely to be the main
              contributors to the proteome. However, we still detect a
              non-negligible fraction of protein coding genes for which the
              major transcript does not code a protein. CONCLUSIONS: Overall,
              our findings suggest that the transcriptome from protein coding
              loci is dominated by one transcript per gene and that not all the
              transcripts that contribute to transcriptome diversity are
              equally likely to contribute to protein diversity. This
              observation can help to prioritize candidate targets in
              proteomics research and to predict the functional impact of the
              detected changes in variation studies.},
  Journal  = {Genome biology},
  Volume   =  {14},
  Number   =  {7},
  Pages    = {R70},
  Month    =  {07},
  Year     =  {2013},
  Language = {en},
  Issn     = {1465-6906},
  Pmid     = {23815980},
  Doi      = {10.1186/gb-2013-14-7-r70},
  Pmc      = {PMC4053754}
}

@article{OccamRazorAndBiology,
  Title       = {Systems biology: the elements and principles of life},
  Author      = {Westerhoff, Hans V and Winder, Catherine and Messiha, Hanan
                 and Simeonidis, Evangelos and Adamczyk, Malgorzata and Verma,
                 Malkhey and Bruggeman, Frank J and Dunn, Warwick},
  Abstract    = {Systems Biology has a mission that puts it at odds with
                 traditional paradigms of physics and molecular biology, such
                 as the simplicity requested by Occam's razor and minimum
                 energy/maximal efficiency. By referring to biochemical
                 experiments on control and regulation, and on flux balancing
                 in yeast, we show that these paradigms are inapt. Systems
                 Biology does not quite converge with biology either: Although
                 it certainly requires accurate 'stamp collecting', it
                 discovers quantitative laws. Systems Biology is a science of
                 its own, discovering own fundamental principles, some of which
                 we identify here.},
  Journal     = {FEBS letters},
  Volume      = {583},
  Number      = {24},
  Pages       = {3882--3890},
  Month       = {12},
  Year        = {2009},
  Language    = {en},
  Issn        = {0014-5793, 1873-3468},
  Pmid        = {19913018},
  Doi         = {10.1016/j.febslet.2009.11.018}
}

@article{CufflinksPaper2,
  Title       = {Identification of novel transcripts in annotated genomes using
                 {RNA-Seq}},
  Author      = {Roberts, Adam and Pimentel, Harold and Trapnell, Cole and
                 Pachter, Lior},
  Abstract    = {SUMMARY: We describe a new 'reference annotation based
                 transcript assembly' problem for RNA-Seq data that involves
                 assembling novel transcripts in the context of an existing
                 annotation. This problem arises in the analysis of expression
                 in model organisms, where it is desirable to leverage existing
                 annotations for discovering novel transcripts. We present an
                 algorithm for reference annotation-based transcript assembly
                 and show how it can be used to rapidly investigate novel
                 transcripts revealed by RNA-Seq in comparison with a reference
                 annotation. AVAILABILITY: The methods described in this
                 article are implemented in the Cufflinks suite of software for
                 RNA-Seq, freely available from
                 http://bio.math.berkeley.edu/cufflinks. The software is
                 released under the BOOST license. CONTACT:
                 cole@broadinstitute.org; lpachter@math.berkeley.edu
                 SUPPLEMENTARY INFORMATION: Supplementary data are available at
                 Bioinformatics online.},
  Journal     = {Bioinformatics},
  Volume      = {27},
  Number      = {17},
  Pages       = {2325--2329},
  Month       = {09},
  Year        = {2011},
  Language    = {en},
  Issn        = {1367-4803, 1367-4811},
  Pmid        = {21697122},
  Doi         = {10.1093/bioinformatics/btr355}
}

@misc{Turner2015,
  Title      = {{RNA-SEQ} quality control and analysis of {Differential} gene
                expression using the {TUXEDO} software suite},
  Author     = {Turner, Stephen D},
  Month      = {10},
  Year       = {2015},
  Conference = {CSHL DNA Learning Center RNA-seq for the Next Generation}
}

@article{EM-what,
  Title       = {What is the expectation maximization algorithm?},
  Author      = {Do, Chuong B and Batzoglou, Serafim},
  Journal     = {Nature Biotechnology},
  Volume      = {26},
  Number      = {8},
  Pages       = {897--899},
  Month       = {08},
  Year        = {2008},
  Language    = {en},
  Issn        = {1087-0156, 1546-1696},
  Pmid        = {18688245},
  Doi         = {10.1038/nbt1406}
}

@article{EM-algo-latest,
  Title     = {Maximum Likelihood from Incomplete Data via the {EM} Algorithm},
  Author    = {Dempster, A P and Laird, N M and Rubin, D B},
  Abstract  = {A broadly applicable algorithm for computing maximum likelihood
               estimates from incomplete data is presented at various levels of
               generality. Theory showing the monotone behaviour of the
               likelihood and convergence of the algorithm is derived. Many
               examples are sketched, including missing value situations,
               applications to grouped, censored or truncated data, finite
               mixture models, variance component estimation, hyperparameter
               estimation, iteratively reweighted least squares and factor
               analysis.},
  Journal   = {Journal of the Royal Statistical Society. Series B, Statistical
               methodology},
  Publisher = {Royal Statistical Society, Wiley},
  Volume    =  {39},
  Number    =  {1},
  Pages     = {1--38},
  Year      = {1977},
  Issn      = {1369-7412, 0035-9246}
}

@article{sampleConservationMatters,
  Title       = {A Comparison of {RNA-Seq} Results from Paired {Formalin-Fixed}
                 {Paraffin-Embedded} and {Fresh-Frozen} Glioblastoma Tissue
                 Samples},
  Author      = {Esteve-Codina, Anna and Arpi, Oriol and Martinez-García, Maria
                 and Pineda, Estela and Mallo, Mar and Gut, Marta and Carrato,
                 Cristina and Rovira, Anna and Lopez, Raquel and Tortosa,
                 Avelina and Dabad, Marc and Del Barco, Sonia and Heath, Simon
                 and Bagué, Silvia and Ribalta, Teresa and Alameda, Francesc
                 and de la Iglesia, Nuria and Balaña, Carmen and {GLIOCAT
                 Group}},
  Abstract    = {The molecular classification of glioblastoma (GBM) based on
                 gene expression might better explain outcome and response to
                 treatment than clinical factors. Whole transcriptome
                 sequencing using next-generation sequencing platforms is
                 rapidly becoming accepted as a tool for measuring gene
                 expression for both research and clinical use. Fresh frozen
                 (FF) tissue specimens of GBM are difficult to obtain since
                 tumor tissue obtained at surgery is often scarce and necrotic
                 and diagnosis is prioritized over freezing. After diagnosis,
                 leftover tissue is usually stored as formalin-fixed
                 paraffin-embedded (FFPE) tissue. However, RNA from FFPE
                 tissues is usually degraded, which could hamper gene
                 expression analysis. We compared RNA-Seq data obtained from
                 matched pairs of FF and FFPE GBM specimens. Only three FFPE
                 out of eleven FFPE-FF matched samples yielded informative
                 results. Several quality-control measurements showed that RNA
                 from FFPE samples was highly degraded but maintained
                 transcriptomic similarities to RNA from FF samples. Certain
                 issues regarding mutation analysis and subtype prediction were
                 detected. Nevertheless, our results suggest that RNA-Seq of
                 FFPE GBM specimens provides reliable gene expression data that
                 can be used in molecular studies of GBM if the RNA is
                 sufficiently preserved.},
  Journal     = {PloS ONE},
  Volume      = {12},
  Number      = {1},
  Pages       = {e0170632},
  Month       = {01},
  Year        = {2017},
  Language    = {en},
  Issn        = {1932-6203},
  Pmid        = {28122052},
  Doi         = {10.1371/journal.pone.0170632},
  Pmc         = {PMC5266269}
}

@article{replicates,
  Title    = {Points of significance: replication},
  Author   = {Blainey, Paul and Krzywinski, Martin and Altman, Naomi},
  Journal  = {Nature Methods},
  Volume   =  {11},
  Number   =  {9},
  Pages    = {879--880},
  Month    =  {09},
  Year     =  {2014},
  Language = {en},
  Issn     = {1548-7091, 1548-7105},
  Pmid     = {25317452},
  Doi      = {10.1038/nmeth.3091}
}

@article{normSigCancerHelp,
  Title       = {Transforming {RNA-Seq} data to improve the performance of
                 prognostic gene signatures},
  Author      = {Zwiener, Isabella and Frisch, Barbara and Binder, Harald},
  Abstract    = {Gene expression measurements have successfully been used for
                 building prognostic signatures, i.e for identifying a short
                 list of important genes that can predict patient outcome.
                 Mostly microarray measurements have been considered, and there
                 is little advice available for building multivariable risk
                 prediction models from RNA-Seq data. We specifically consider
                 penalized regression techniques, such as the lasso and
                 componentwise boosting, which can simultaneously consider all
                 measurements and provide both, multivariable regression models
                 for prediction and automated variable selection. However, they
                 might be affected by the typical skewness,
                 mean-variance-dependency or extreme values of RNA-Seq
                 covariates and therefore could benefit from transformations of
                 the latter. In an analytical part, we highlight preferential
                 selection of covariates with large variances, which is
                 problematic due to the mean-variance dependency of RNA-Seq
                 data. In a simulation study, we compare different
                 transformations of RNA-Seq data for potentially improving
                 detection of important genes. Specifically, we consider
                 standardization, the log transformation, a
                 variance-stabilizing transformation, the Box-Cox
                 transformation, and rank-based transformations. In addition,
                 the prediction performance for real data from patients with
                 kidney cancer and acute myeloid leukemia is considered. We
                 show that signature size, identification performance, and
                 prediction performance critically depend on the choice of a
                 suitable transformation. Rank-based transformations perform
                 well in all scenarios and can even outperform complex
                 variance-stabilizing approaches. Generally, the results
                 illustrate that the distribution and potential transformations
                 of RNA-Seq data need to be considered as a critical step when
                 building risk prediction models by penalized regression
                 techniques.},
  Journal     = {PLoS ONE},
  Volume      = {9},
  Number      = {1},
  Pages       = {e85150},
  Month       = {01},
  Year        = {2014},
  Language    = {en},
  Issn        = {1932-6203},
  Pmid        = {24416353},
  Doi         = {10.1371/journal.pone.0085150},
  Pmc         = {PMC3885686}
}

@article{NormImpact,
  Title       = {The Impact of Normalization Methods on {RNA-Seq} Data Analysis},
  Author      = {Zyprych-Walczak, J and Szabelska, A and Handschuh, L and
                 Górczak, K and Klamecka, K and Figlerowicz, M and Siatkowski,
                 I},
  Abstract    = {High-throughput sequencing technologies, such as the Illumina
                 Hi-seq, are powerful new tools for investigating a wide range
                 of biological and medical problems. Massive and complex data
                 sets produced by the sequencers create a need for development
                 of statistical and computational methods that can tackle the
                 analysis and management of data. The data normalization is one
                 of the most crucial steps of data processing and this process
                 must be carefully considered as it has a profound effect on
                 the results of the analysis. In this work, we focus on a
                 comprehensive comparison of five normalization methods related
                 to sequencing depth, widely used for transcriptome sequencing
                 (RNA-seq) data, and their impact on the results of gene
                 expression analysis. Based on this study, we suggest a
                 universal workflow that can be applied for the selection of
                 the optimal normalization procedure for any particular data
                 set. The described workflow includes calculation of the bias
                 and variance values for the control genes, sensitivity and
                 specificity of the methods, and classification errors as well
                 as generation of the diagnostic plots. Combining the above
                 information facilitates the selection of the most appropriate
                 normalization method for the studied data sets and determines
                 which methods can be used interchangeably.},
  Journal     = {BioMed research international},
  Volume      = {2015},
  Pages       = {621690},
  Month       = {06},
  Year        = {2015},
  Language    = {en},
  Issn        = {2314-6133, 2314-6141},
  Pmid        = {26176014},
  Doi         = {10.1155/2015/621690},
  Pmc         = {PMC4484837}
}

@article{ruvseqComQN,
  Title       = {How data analysis affects power, reproducibility and
                 biological insight of {RNA-seq} studies in complex datasets},
  Author      = {Peixoto, Lucia and Risso, Davide and Poplawski, Shane G and
                 Wimmer, Mathieu E and Speed, Terence P and Wood, Marcelo A and
                 Abel, Ted},
  Abstract    = {The sequencing of the full transcriptome (RNA-seq) has become
                 the preferred choice for the measurement of genome-wide gene
                 expression. Despite its widespread use, challenges remain in
                 RNA-seq data analysis. One often-overlooked aspect is
                 normalization. Despite the fact that a variety of factors or
                 'batch effects' can contribute unwanted variation to the data,
                 commonly used RNA-seq normalization methods only correct for
                 sequencing depth. The study of gene expression is particularly
                 problematic when it is influenced simultaneously by a variety
                 of biological factors in addition to the one of interest.
                 Using examples from experimental neuroscience, we show that
                 batch effects can dominate the signal of interest; and that
                 the choice of normalization method affects the power and
                 reproducibility of the results. While commonly used global
                 normalization methods are not able to adequately normalize the
                 data, more recently developed RNA-seq normalization can. We
                 focus on one particular method, RUVSeq and show that it is
                 able to increase power and biological insight of the results.
                 Finally, we provide a tutorial outlining the implementation of
                 RUVSeq normalization that is applicable to a broad range of
                 studies as well as meta-analysis of publicly available data.},
  Journal     = {Nucleic Acids Research},
  Volume      = {43},
  Number      = {16},
  Pages       = {7664--7674},
  Month       = {09},
  Year        = {2015},
  Language    = {en},
  Issn        = {0305-1048, 1362-4962},
  Pmid        = {26202970},
  Doi         = {10.1093/nar/gkv736},
  Pmc         = {PMC4652761}
}



@article{cqn,
  Title       = {Removing technical variability in {RNA-seq} data using
                 conditional quantile normalization},
  Author      = {Hansen, Kasper D and Irizarry, Rafael A and Wu, Zhijin},
  Abstract    = {The ability to measure gene expression on a genome-wide scale
                 is one of the most promising accomplishments in molecular
                 biology. Microarrays, the technology that first permitted
                 this, were riddled with problems due to unwanted sources of
                 variability. Many of these problems are now mitigated, after a
                 decade's worth of statistical methodology development. The
                 recently developed RNA sequencing (RNA-seq) technology has
                 generated much excitement in part due to claims of reduced
                 variability in comparison to microarrays. However, we show
                 that RNA-seq data demonstrate unwanted and obscuring
                 variability similar to what was first observed in microarrays.
                 In particular, we find guanine-cytosine content (GC-content)
                 has a strong sample-specific effect on gene expression
                 measurements that, if left uncorrected, leads to false
                 positives in downstream results. We also report on commonly
                 observed data distortions that demonstrate the need for data
                 normalization. Here, we describe a statistical methodology
                 that improves precision by 42\% without loss of accuracy. Our
                 resulting conditional quantile normalization algorithm
                 combines robust generalized regression to remove systematic
                 bias introduced by deterministic features such as GC-content
                 and quantile normalization to correct for global distortions.},
  Journal     = {Biostatistics},
  Volume      = {13},
  Number      =  {2},
  Pages       = {204--216},
  Month       = {04},
  Year        = {2012},
  Language    = {en},
  Issn        = {1465-4644, 1468-4357},
  Pmid        = {22285995},
  Doi         = {10.1093/biostatistics/kxr054},
  Pmc         = {PMC3297825}
}

@article{ruvseq,
  Title       = {Normalization of {RNA-seq} data using factor analysis of
                 control genes or samples},
  Author      = {Risso, Davide and Ngai, John and Speed, Terence P and Dudoit,
                 Sandrine},
  Abstract    = {Normalization of RNA-sequencing (RNA-seq) data has proven
                 essential to ensure accurate inference of expression levels.
                 Here, we show that usual normalization approaches mostly
                 account for sequencing depth and fail to correct for library
                 preparation and other more complex unwanted technical effects.
                 We evaluate the performance of the External RNA Control
                 Consortium (ERCC) spike-in controls and investigate the
                 possibility of using them directly for normalization. We show
                 that the spike-ins are not reliable enough to be used in
                 standard global-scaling or regression-based normalization
                 procedures. We propose a normalization strategy, called remove
                 unwanted variation (RUV), that adjusts for nuisance technical
                 effects by performing factor analysis on suitable sets of
                 control genes (e.g., ERCC spike-ins) or samples (e.g.,
                 replicate libraries). Our approach leads to more accurate
                 estimates of expression fold-changes and tests of differential
                 expression compared to state-of-the-art normalization methods.
                 In particular, RUV promises to be valuable for large
                 collaborative projects involving multiple laboratories,
                 technicians, and/or sequencing platforms.},
  Journal     = {Nature Biotechnology},
  Volume      = {32},
  Number      = {9},
  Pages       = {896--902},
  Month       = {09},
  Year        = {2014},
  Language    = {en},
  Issn        = {1087-0156, 1546-1696},
  Pmid        = {25150836},
  Doi         = {10.1038/nbt.2931},
  Pmc         = {PMC4404308}
}

@article{edgeR,
  Title       = {edgeR: a Bioconductor package for differential expression
                 analysis of digital gene expression data},
  Author      = {Robinson, Mark D and McCarthy, Davis J and Smyth, Gordon K},
  Abstract    = {SUMMARY: It is expected that emerging digital gene expression
                 (DGE) technologies will overtake microarray technologies in
                 the near future for many functional genomics applications. One
                 of the fundamental data analysis tasks, especially for gene
                 expression studies, involves determining whether there is
                 evidence that counts for a transcript or exon are
                 significantly different across experimental conditions. edgeR
                 is a Bioconductor software package for examining differential
                 expression of replicated count data. An overdispersed Poisson
                 model is used to account for both biological and technical
                 variability. Empirical Bayes methods are used to moderate the
                 degree of overdispersion across transcripts, improving the
                 reliability of inference. The methodology can be used even
                 with the most minimal levels of replication, provided at least
                 one phenotype or experimental condition is replicated. The
                 software may have other applications beyond sequencing data,
                 such as proteome peptide count data. AVAILABILITY: The package
                 is freely available under the LGPL licence from the
                 Bioconductor web site (http://bioconductor.org).},
  Journal     = {Bioinformatics},
  Volume      = {26},
  Number      = {1},
  Pages       = {139--140},
  Month       = {01},
  Year        = {2010},
  Language    = {en},
  Issn        = {1367-4803, 1367-4811},
  Pmid        = {19910308},
  Doi         = {10.1093/bioinformatics/btp616},
  Pmc         = {PMC2796818}
}

@article{DESeq2,
  Title    = {Moderated estimation of fold change and dispersion for {RNA-seq}
              data with {DESeq2}},
  Author   = {Love, Michael I and Huber, Wolfgang and Anders, Simon},
  Abstract = {In comparative high-throughput sequencing assays, a fundamental
              task is the analysis of count data, such as read counts per gene
              in RNA-seq, for evidence of systematic changes across
              experimental conditions. Small replicate numbers, discreteness,
              large dynamic range and the presence of outliers require a
              suitable statistical approach. We present DESeq2, a method for
              differential analysis of count data, using shrinkage estimation
              for dispersions and fold changes to improve stability and
              interpretability of estimates. This enables a more quantitative
              analysis focused on the strength rather than the mere presence of
              differential expression. The DESeq2 package is available at
              http://www.bioconductor.org/packages/release/bioc/html/DESeq2.html
              webcite.},
  Journal  = {Genome Biology},
  Volume   = {15},
  Number   = {12},
  Pages    = {550},
  Year     = {2014},
  Language = {en},
  Issn     = {1465-6906},
  Pmid     = {25516281},
  Doi      = {10.1186/s13059-014-0550-8},
  Pmc      = {PMC4302049}
}

@article{Aebersold2003,
  Title       = {Mass spectrometry-based proteomics},
  Author      = {Aebersold, Ruedi and Mann, Matthias},
  Abstract    = {Recent successes illustrate the role of mass
                 spectrometry-based proteomics as an indispensable tool for
                 molecular and cellular biology and for the emerging field of
                 systems biology. These include the study of protein-protein
                 interactions via affinity-based isolations on a small and
                 proteome-wide scale, the mapping of numerous organelles, the
                 concurrent description of the malaria parasite genome and
                 proteome, and the generation of quantitative protein profiles
                 from diverse species. The ability of mass spectrometry to
                 identify and, increasingly, to precisely quantify thousands of
                 proteins from complex samples can be expected to impact
                 broadly on biology and medicine.},
  Journal     = {Nature},
  Volume      = {422},
  Number      = {6928},
  Pages       = {198--207},
  Month       = {03},
  Year        = {2003},
  Language    = {en},
  Issn        = {0028-0836},
  Pmid        = {12634793},
  Doi         = {10.1038/nature01511}
}

@article{Cox2011,
  Title     = {Quantitative, {High-Resolution} Proteomics for {Data-Driven}
               Systems Biology},
  Author    = {Cox, Jürgen and Mann, Matthias},
  Abstract  = {Systems biology requires comprehensive data at all molecular
               levels. Mass spectrometry (MS)-based proteomics has emerged as a
               powerful and universal method for the global measurement of
               proteins. In the most widespread format, it uses liquid
               chromatography (LC) coupled to high-resolution tandem mass
               spectrometry (MS/MS) to identify and quantify peptides at a
               large scale. This peptide intensity information is the basic
               quantitative proteomic data type. It is used to quantify
               proteins between different proteome states, including the
               temporal variation of the proteome, to determine the complete
               primary structure of proteins including posttranslational
               modifications, to localize proteins to organelles, and to
               determine protein interactions. Here, we describe the principles
               of analysis and the areas of biology where proteomics can make
               unique contributions. The large-scale nature of proteomics data
               and its high accuracy pose special opportunities as well as
               challenges in systems biology that have been largely untapped so
               far.},
  Journal   = {Annual Review of Biochemistry},
  Publisher = {Annual Reviews},
  Volume    = {80},
  Number    = {1},
  Pages     = {273--299},
  Month     = {06},
  Year      = {2011},
  Issn      = {0066-4154},
  Doi       = {10.1146/annurev-biochem-061308-093216}
}

@phdthesis{Broshphd,
      Author       = {Markus Brosh},
      Title        = {Development of computational methods for analysing proteomic
      data for genome annotation},
      School       = {University of Cambridge},
      Year         = {2009}
}

@article{Hunt1992,
  Title       = {Characterization of peptides bound to the class {I} {MHC}
                 molecule {HLA-A2.1} by mass spectrometry},
  Author      = {Hunt, D F and Henderson, R A and Shabanowitz, J and Sakaguchi,
                 K and Michel, H and Sevilir, N and Cox, A L and Appella, E and
                 Engelhard, V H},
  Abstract    = {Antigens recognized by T cells are expressed as peptides bound
                 to major histocompatibility complex (MHC) molecules.
                 Microcapillary high-performance liquid
                 chromatography-electrospray ionization-tandem mass
                 spectrometry was used to fractionate and sequence subpicomolar
                 amounts of peptides isolated from the MHC molecule HLA-A2.1.
                 Of 200 different species quantitated, eight were sequenced and
                 four were found in cellular proteins. All were nine residues
                 long and shared a distinct structural motif. The sensitivity
                 and speed of this approach should enhance the analysis of
                 peptides from small quantities of virally infected and
                 transformed cells as well as those associated with autoimmune
                 disease states.},
  Journal     = {Science},
  Volume      = {255},
  Number      = {5049},
  Pages       = {1261--1263},
  Month       = {03},
  Year        = {1992},
  Language    = {en},
  Issn        = {0036-8075},
  Pmid        = {1546328}
}

@article{AebersoldMann2016,
  Title       = {Mass-spectrometric exploration of proteome structure and
                 function},
  Author      = {Aebersold, Ruedi and Mann, Matthias},
  Abstract    = {Numerous biological processes are concurrently and
                 coordinately active in every living cell. Each of them
                 encompasses synthetic, catalytic and regulatory functions that
                 are, almost always, carried out by proteins organized further
                 into higher-order structures and networks. For decades, the
                 structures and functions of selected proteins have been
                 studied using biochemical and biophysical methods. However,
                 the properties and behaviour of the proteome as an integrated
                 system have largely remained elusive. Powerful
                 mass-spectrometry-based technologies now provide unprecedented
                 insights into the composition, structure, function and control
                 of the proteome, shedding light on complex biological
                 processes and phenotypes.},
  Journal     = {Nature},
  Volume      = {537},
  Number      = {7620},
  Pages       = {347--355},
  Month       = {09},
  Year        = {2016},
  Language    = {en},
  Issn        = {0028-0836, 1476-4687},
  Pmid        = {27629641},
  Doi         = {10.1038/nature19949}
}

@article{Deutsch2015,
  Title       = {State of the Human Proteome in 2014/2015 As Viewed through
                 {PeptideAtlas}: Enhancing Accuracy and Coverage through the
                 {AtlasProphet}},
  Author      = {Deutsch, Eric W and Sun, Zhi and Campbell, David and
                 Kusebauch, Ulrike and Chu, Caroline S and Mendoza, Luis and
                 Shteynberg, David and Omenn, Gilbert S and Moritz, Robert L},
  Abstract    = {The Human PeptideAtlas is a compendium of the highest quality
                 peptide identifications from over 1000 shotgun mass
                 spectrometry proteomics experiments collected from many
                 different laboratories, all reanalyzed through a uniform
                 processing pipeline. The latest 2015-03 build contains
                 substantially more input data than past releases, is mapped to
                 a recent version of our merged reference proteome, and uses
                 improved informatics processing and the development of the
                 AtlasProphet to provide the highest quality results. Within
                 the set of ∼20,000 neXtProt primary entries, 14,070 (70\%) are
                 confidently detected in the latest build, 5\% are ambiguous,
                 9\% are redundant, leaving the total percentage of proteins
                 for which there are no mapping detections at just 16\% (3166),
                 all derived from over 133 million peptide-spectrum matches
                 identifying more than 1 million distinct peptides using
                 AtlasProphet to characterize and classify the protein matches.
                 Improved handling for detection and presentation of single
                 amino-acid variants (SAAVs) reveals the detection of 5326
                 uniquely mapping SAAVs across 2794 proteins. With such a large
                 amount of data, the control of false positives is a challenge.
                 We present the methodology and results for maintaining
                 rigorous quality along with a discussion of the implications
                 of the remaining sources of errors in the build.},
  Journal     = {Journal of Proteome Research},
  Volume      = {14},
  Number      = {9},
  Pages       = {3461--3473},
  Month       = {09},
  Year        = {2015},
  Keywords    = {Human Proteome Project; PeptideAtlas; observed proteome;
                 repositories; shotgun proteomics; tandem mass spectrometry},
  Language    = {en},
  Issn        = {1535-3893, 1535-3907},
  Pmid        = {26139527},
  Doi         = {10.1021/acs.jproteome.5b00500},
  Pmc         = {PMC4755269}
}

@article{Shi2016,
  Title       = {Advances in targeted proteomics and applications to biomedical
                 research},
  Author      = {Shi, Tujin and Song, Ehwang and Nie, Song and Rodland, Karin D
                 and Liu, Tao and Qian, Wei-Jun and Smith, Richard D},
  Abstract    = {Targeted proteomics technique has emerged as a powerful
                 protein quantification tool in systems biology, biomedical
                 research, and increasing for clinical applications. The most
                 widely used targeted proteomics approach, selected reaction
                 monitoring (SRM), also known as multiple reaction monitoring
                 (MRM), can be used for quantification of cellular signaling
                 networks and preclinical verification of candidate protein
                 biomarkers. As an extension to our previous review on advances
                 in SRM sensitivity (Shi et al., Proteomics, 12, 1074-1092,
                 2012) herein we review recent advances in the method and
                 technology for further enhancing SRM sensitivity (from 2012 to
                 present), and highlighting its broad biomedical applications
                 in human bodily fluids, tissue and cell lines. Furthermore, we
                 also review two recently introduced targeted proteomics
                 approaches, parallel reaction monitoring (PRM) and
                 data-independent acquisition (DIA) with targeted data
                 extraction on fast scanning high-resolution accurate-mass
                 (HR/AM) instruments. Such HR/AM targeted quantification with
                 monitoring all target product ions addresses SRM limitations
                 effectively in specificity and multiplexing; whereas when
                 compared to SRM, PRM and DIA are still in the infancy with a
                 limited number of applications. Thus, for HR/AM targeted
                 quantification we focus our discussion on method development,
                 data processing and analysis, and its advantages and
                 limitations in targeted proteomics. Finally, general
                 perspectives on the potential of achieving both high
                 sensitivity and high sample throughput for large-scale
                 quantification of hundreds of target proteins are discussed.},
  Journal     = {Proteomics},
  Volume      = {16},
  Number      = {15-16},
  Pages       = {2160--2182},
  Month       = {08},
  Year        = {2016},
  Keywords    = {Biomarker; DIA; PRISM; PRM; SRM; Signaling pathway; Technology},
  Language    = {en},
  Issn        = {1615-9853, 1615-9861},
  Pmid        = {27302376},
  Doi         = {10.1002/pmic.201500449},
  Pmc         = {PMC5051956}
}

@article{Chapman2014,
  Title       = {Multiplexed and data-independent tandem mass spectrometry for
                 global proteome profiling},
  Author      = {Chapman, John D and Goodlett, David R and Masselon, Christophe
                 D},
  Abstract    = {One of the most important early developments in the field of
                 proteomics was the advent of automated data acquisition
                 routines that allowed high-throughput unattended data
                 acquisition during HPLC introduction of peptide mixtures to a
                 tandem mass spectrometer. Prior to this, data acquisition was
                 orders of magnitude less efficient being based entirely on
                 lists of predetermined ions generated in a prior HPLC-MS
                 experiment. This process, known generically as data-dependent
                 analysis, empowered the development of shotgun proteomics
                 where hundreds to thousands of peptide sequences are matched
                 per experiment. In their most popular implementation, the most
                 abundant ionized species from every precursor ion scan at each
                 moment in chromatographic time are successively selected for
                 isolation, activation and tandem mass analysis. While
                 extremely powerful, this strategy has one primary limitation
                 in that detectable dynamic range is restricted (in a top-down
                 manner) to the peptides that ionize the best. To circumvent
                 the serial nature of the data-dependent process and increase
                 detectable dynamic range, the concepts of multiplexed and
                 data-independent acquisition (DIA) have emerged.
                 Multiplexed-data acquisition is based on more efficient
                 co-selection and co-dissociation of multiple precursor ions in
                 parallel, the data from which is subsequently de-convoluted to
                 provide polypeptide sequences for each individual precursor
                 ion. DIA has similar goals, but there is no real-time ion
                 selection based on prior precursor ion scans. Instead,
                 predefined m/z ranges are interrogated either by fragmenting
                 all ions entering the mass spectrometer at every single point
                 in chromatographic time; or by dividing the m/z range into
                 smaller m/z ranges for isolation and fragmentation. These
                 approaches aim to fully utilize the capabilities of mass
                 spectrometers to maximize tandem MS acquisition time and to
                 address the need to expand the detectable dynamic range, lower
                 the limit of detection, and improve the overall confidence of
                 peptide identifications and relative protein quantification
                 measurements. This review covers all aspects of multiplexed-
                 and data-independent tandem mass spectrometry in proteomics,
                 from experimental implementations to advances in software for
                 data interpretation.},
  Journal     = {Mass spectrometry reviews},
  Volume      = {33},
  Number      = {6},
  Pages       = {452--470},
  Month       = {11},
  Year        = {2014},
  Language    = {en},
  Issn        = {0277-7037, 1098-2787},
  Pmid        = {24281846},
  Doi         = {10.1002/mas.21400}
}

@article{Zhang2013,
  Title       = {Protein analysis by shotgun/bottom-up proteomics},
  Author      = {Zhang, Yaoyang and Fonslow, Bryan R and Shan, Bing and Baek,
                 Moon-Chang and Yates, 3rd, John R},
  Journal     = {Chemical reviews},
  Volume      = {113},
  Number      = {4},
  Pages       = {2343--2394},
  Month       = {04},
  Year        = {2013},
  Language    = {en},
  Issn        = {0009-2665, 1520-6890},
  Pmid        = {23438204},
  Doi         = {10.1021/cr3003533},
  Pmc         = {PMC3751594}
}

@article{Zhang2014,
  Title       = {High-throughput proteomics},
  Author      = {Zhang, Zhaorui and Wu, Si and Stenoien, David L and
                 Paša-Tolić, Ljiljana},
  Abstract    = {Mass spectrometry (MS)-based high-throughput proteomics is the
                 core technique for large-scale protein characterization. Due
                 to the extreme complexity of proteomes, sophisticated
                 separation techniques and advanced MS instrumentation have
                 been developed to extend coverage and enhance dynamic range
                 and sensitivity. In this review, we discuss the separation and
                 prefractionation techniques applied for large-scale analysis
                 in both bottom-up (i.e., peptide-level) and top-down (i.e.,
                 protein-level) proteomics. Different approaches for
                 quantifying peptides or intact proteins, including label-free
                 and stable-isotope-labeling strategies, are also discussed. In
                 addition, we present a brief overview of different types of
                 mass analyzers and fragmentation techniques as well as
                 selected emerging techniques.},
  Journal     = {Annual review of analytical chemistry},
  Volume      = {7},
  Pages       = {427--454},
  Year        = {2014},
  Keywords    = {ion-mobility spectrometry; liquid chromatography; mass
                 spectrometry; proteomics},
  Language    = {en},
  Issn        = {1936-1327, 1936-1335},
  Pmid        = {25014346},
  Doi         = {10.1146/annurev-anchem-071213-020216}
}

@article{LCMSflaws,
  Title       = {A systematic model of the {LC-MS} proteomics pipeline},
  Author      = {Sun, Youting and Braga-Neto, Ulisses and Dougherty, Edward R},
  Abstract    = {MOTIVATION: Mass spectrometry is a complex technique used for
                 large-scale protein profiling with clinical and pharmaceutical
                 applications. While individual components in the system have
                 been studied extensively, little work has been done to
                 integrate various modules and evaluate them from a systems
                 point of view. RESULTS: In this work, we investigate this
                 problem by putting together the different modules in a typical
                 proteomics work flow, in order to capture and analyze key
                 factors that impact the number of identified peptides and
                 quantified proteins, protein quantification error,
                 differential expression results, and classification
                 performance. The proposed proteomics pipeline model can be
                 used to optimize the work flow as well as to pinpoint critical
                 bottlenecks worth investing time and resources into for
                 improving performance. Using the model-based approach proposed
                 here, one can study systematically the critical problem of
                 proteomic biomarker discovery, by means of simulation using
                 ground-truthed synthetic MS data.},
  Journal     = {BMC Genomics},
  Volume      = {13 Suppl 6},
  Pages       = {S2},
  Month       = {10},
  Year        = {2012},
  Language    = {en},
  Issn        = {1471-2164},
  Pmid        = {23134670},
  Doi         = {10.1186/1471-2164-13-S6-S2},
  Pmc         = {PMC3481448}
}

@article{LCMSconsider,
  Title       = {Options and considerations when selecting a quantitative
                 proteomics strategy},
  Author      = {Domon, Bruno and Aebersold, Ruedi},
  Abstract    = {The vast majority of proteomic studies to date have relied on
                 mass spectrometric techniques to identify, and in some cases
                 quantify, peptides that have been generated by proteolysis.
                 Current approaches differ in the types of instrument used,
                 their performance profiles, the manner in which they interface
                 with biological research strategies, and their reliance on and
                 use of prior information. Here, we consider the three main
                 mass spectrometry (MS)-based proteomic approaches used today:
                 shotgun (or discovery), directed and targeted strategies. We
                 discuss the principles of each technique, their strengths and
                 weaknesses and the dependence of their performance profiles on
                 the composition of the biological sample. Our goal is to
                 provide a rational framework for selecting strategies
                 optimally suited to address the specific research issue under
                 consideration.},
  Journal     = {Nature Biotechnology},
  Volume      = {28},
  Number      = {7},
  Pages       = {710--721},
  Month       = {07},
  Year        = {2010},
  Language    = {en},
  Issn        = {1087-0156, 1546-1696},
  Pmid        = {20622845},
  Doi         = {10.1038/nbt.1661}
}

@article{Liu2009,
  Title       = {Relationship between sample loading amount and peptide
                 identification and its effects on quantitative proteomics},
  Author      = {Liu, Kehui and Zhang, Jiyang and Wang, Jinglan and Zhao, Liyan
                 and Peng, Xu and Jia, Wei and Ying, Wantao and Zhu, Yunping
                 and Xie, Hongwei and He, Fuchu and Qian, Xiaohong},
  Abstract    = {The relationship between sample loading amount and peptide
                 identification is crucial for the optimization of proteomics
                 experiments, but few studies have addressed this matter.
                 Herein, we present a systematic study using a replicate run
                 strategy to probe the inherent influence of both peptide
                 physicochemical properties and matrix effects on the
                 relationship between peptide identification and sample loading
                 amounts, as well as its applications in protein
                 quantification. Ten replicate runs for a series of laddered
                 loading amounts (ranging between 0.01 approximately 10 microg)
                 of total digested proteins from Saccharomyces cerevisiae were
                 performed with nanoscale liquid chromatography coupled with
                 linear ion trap/Fourier transform ion cyclotron resonance
                 (nanoLC-LTQ-FT) to obtain a nearly saturated peptide
                 identification. This permitted us to differentiate the linear
                 correlativity of peptide identification by the commonly used
                 peptide quantitative index, the area of constructed ion
                 chromatograms (XIC) (SA, from MS and tandem MS data) in the
                 given experiments. The absolute loading amount of a given
                 complex sample affected the final qualitative identification
                 result; thus, optimization of the sample loading amount before
                 every proteomics study was essential. Peptide physicochemical
                 properties had little effect on the linear correlativity
                 between SA-based peptide quantification and loading amount.
                 The matrix effects, rather than the static physicochemical
                 properties of individual peptides, affect peptide
                 measurability. We also quantified the target protein by
                 selecting peptides with good parallel linear correlativity
                 based upon SA as signature peptides and revised the data by
                 multiplying by the reciprocal of the slope coefficient. We
                 found that this optimized the linear protein abundance
                 relativity at every amount range and thus extended the linear
                 dynamic range of label-free quantification. This empirical
                 rule for linear peptide selection (ERLPS) can be adopted to
                 correct comparison results in proteolytic peptide-based
                 quantitative proteomics, such as accurate mass tag (AMT) and
                 targeted quantitative proteomics, as well as in tag-labeled
                 comparative proteomics.},
  Journal     = {Analytical Chemistry},
  Volume      = {81},
  Number      = {4},
  Pages       = {1307--1314},
  Month       = {02},
  Year        = {2009},
  Language    = {en},
  Issn        = {0003-2700, 1520-6882},
  Pmid        = {19146458},
  Doi         = {10.1021/ac801466k}
}

@article{Cappadona2012,
  Title       = {Current challenges in software solutions for mass
                 spectrometry-based quantitative proteomics},
  Author      = {Cappadona, Salvatore and Baker, Peter R and Cutillas, Pedro R
                 and Heck, Albert J R and van Breukelen, Bas},
  Abstract    = {Mass spectrometry-based proteomics has evolved as a
                 high-throughput research field over the past decade.
                 Significant advances in instrumentation, and the ability to
                 produce huge volumes of data, have emphasized the need for
                 adequate data analysis tools, which are nowadays often
                 considered the main bottleneck for proteomics development.
                 This review highlights important issues that directly impact
                 the effectiveness of proteomic quantitation and educates
                 software developers and end-users on available computational
                 solutions to correct for the occurrence of these factors.
                 Potential sources of errors specific for stable isotope-based
                 methods or label-free approaches are explicitly outlined. The
                 overall aim focuses on a generic proteomic workflow.},
  Journal     = {Amino Acids},
  Volume      = {43},
  Number      = {3},
  Pages       = {1087--1108},
  Month       = {09},
  Year        = {2012},
  Language    = {en},
  Issn        = {0939-4451, 1438-2199},
  Pmid        = {22821268},
  Doi         = {10.1007/s00726-012-1289-8},
  Pmc         = {PMC3418498}
}

@article{Bruce2013,
  Title       = {Proteomics and the analysis of proteomic data: 2013 overview
                 of current protein-profiling technologies},
  Author      = {Bruce, Can and Stone, Kathryn and Gulcicek, Erol and Williams,
                 Kenneth},
  Abstract    = {Mass spectrometry has become a major tool in the study of
                 proteomes. The analysis of proteolytic peptides and their
                 fragment ions by this technique enables the identification and
                 quantitation of the precursor proteins in a mixture. However,
                 deducing chemical structures and then protein sequences from
                 mass-to-charge ratios is a challenging computational task.
                 Software tools incorporating powerful algorithms and
                 statistical methods improved our ability to process the large
                 quantities of proteomics data. Repositories of spectral data
                 make both data analysis and experimental design more
                 efficient. New approaches in quantitative and statistical
                 proteomics make possible a greater coverage of the proteome,
                 the identification of more post-translational modifications,
                 and a greater sensitivity in the quantitation of targeted
                 proteins.},
  Journal     = {Current Protocols in Bioinformatics},
  Volume      = {S41},
  Number      = {13.21},
  Pages       = {1--17},
  Month       = {03},
  Year        = {2013},
  Language    = {en},
  Issn        = {1934-3396, 1934-340X},
  Pmid        = {23504934},
  Doi         = {10.1002/0471250953.bi1321s41},
  Pmc         = {PMC3688054}
}

@article{Feist2015,
  Title       = {Proteomic challenges: sample preparation techniques for
                 microgram-quantity protein analysis from biological samples},
  Author      = {Feist, Peter and Hummon, Amanda B},
  Abstract    = {Proteins regulate many cellular functions and analyzing the
                 presence and abundance of proteins in biological samples are
                 central focuses in proteomics. The discovery and validation of
                 biomarkers, pathways, and drug targets for various diseases
                 can be accomplished using mass spectrometry-based proteomics.
                 However, with mass-limited samples like tumor biopsies, it can
                 be challenging to obtain sufficient amounts of proteins to
                 generate high-quality mass spectrometric data. Techniques
                 developed for macroscale quantities recover sufficient amounts
                 of protein from milligram quantities of starting material, but
                 sample losses become crippling with these techniques when only
                 microgram amounts of material are available. To combat this
                 challenge, proteomicists have developed micro-scale techniques
                 that are compatible with decreased sample size (100 μg or
                 lower) and still enable excellent proteome coverage.
                 Extraction, contaminant removal, protein quantitation, and
                 sample handling techniques for the microgram protein range are
                 reviewed here, with an emphasis on liquid chromatography and
                 bottom-up mass spectrometry-compatible techniques. Also, a
                 range of biological specimens, including mammalian tissues and
                 model cell culture systems, are discussed.},
  Journal     = {International Journal of Molecular Sciences},
  Volume      = {16},
  Number      = {2},
  Pages       = {3537--3563},
  Month       = {2},
  Year        = {2015},
  Language    = {en},
  Issn        = {1422-0067},
  Pmid        = {25664860},
  Doi         = {10.3390/ijms16023537},
  Pmc         = {PMC4346912}
}

@article{Gutstein2008,
  Title       = {Microproteomics: analysis of protein diversity in small
                 samples},
  Author      = {Gutstein, Howard B and Morris, Jeffrey S and Annangudi, Suresh
                 P and Sweedler, Jonathan V},
  Abstract    = {Proteomics, the large-scale study of protein expression in
                 organisms, offers the potential to evaluate global changes in
                 protein expression and their post-translational modifications
                 that take place in response to normal or pathological stimuli.
                 One challenge has been the requirement for substantial amounts
                 of tissue in order to perform comprehensive proteomic
                 characterization. In heterogeneous tissues, such as brain,
                 this has limited the application of proteomic methodologies.
                 Efforts to adapt standard methods of tissue sampling, protein
                 extraction, arraying, and identification are reviewed, with an
                 emphasis on those appropriate to smaller samples ranging in
                 size from several microliters down to single cells. The
                 effects of miniaturization on these analyses are highlighted
                 using neuroscience-related examples, as are statistical issues
                 unique to the high-dimensional datasets generated by proteomic
                 experiments.},
  Journal     = {Mass Spectrometry Reviews},
  Volume      = {27},
  Number      = {4},
  Pages       = {316--330},
  Month       = {07},
  Year        = {2008},
  Language    = {en},
  Issn        = {0277-7037},
  Pmid        = {18271009},
  Doi         = {10.1002/mas.20161},
  Pmc         = {PMC2743962}
}

@article{Bodzon-Kulakowska2007,
  Title       = {Methods for samples preparation in proteomic research},
  Author      = {Bodzon-Kulakowska, Anna and Bierczynska-Krzysik, Anna and
                 Dylag, Tomasz and Drabik, Anna and Suder, Piotr and Noga,
                 Marek and Jarzebinska, Justyna and Silberring, Jerzy},
  Abstract    = {Sample preparation is one of the most crucial processes in
                 proteomics research. The results of the experiment depend on
                 the condition of the starting material. Therefore, the proper
                 experimental model and careful sample preparation is vital to
                 obtain significant and trustworthy results, particularly in
                 comparative proteomics, where we are usually looking for minor
                 differences between experimental-, and control samples. In
                 this review we discuss problems associated with general
                 strategies of samples preparation, and experimental demands
                 for these processes.},
  Journal     = {Journal of Chromatography. B, Analytical Technologies in the
                 Biomedical and Life Sciences},
  Volume      = {849},
  Number      = {1-2},
  Pages       = {1--31},
  Month       = {04},
  Year        = {2007},
  Language    = {en},
  Issn        = {1570-0232},
  Pmid        = {17113834},
  Doi         = {10.1016/j.jchromb.2006.10.040}
}

@article{Visser2005,
  Title       = {Sample preparation for peptides and proteins in biological
                 matrices prior to liquid chromatography and capillary zone
                 electrophoresis},
  Author      = {Visser, N F C and Lingeman, H and Irth, H},
  Abstract    = {The determination of peptides and proteins in a biological
                 matrix normally includes a sample-preparation step to obtain a
                 sample that can be injected into a separation system in such a
                 way that peptides and proteins of interest can be determined
                 qualitatively and/or quantitatively. This can be a rather
                 challenging, labourious and/or time-consuming process. The
                 extract obtained after sample preparation is further separated
                 using a compatible separation system. Liquid chromatography
                 (LC) is the generally applied technique for this purpose, but
                 capillary zone electrophoresis (CZE) is an alternative,
                 providing fast, versatile and efficient separations. In this
                 review, the recent developments in the combination of
                 sample-preparation procedures with LC and CZE, for the
                 determination of peptides and proteins, will be discussed.
                 Emphasis will be on purification from and determination in
                 complex biological matrices (plasma, cell lysates, etc.) of
                 these compounds and little attention will be paid to the
                 proteomics area. Additional focus will be put on
                 sample-preparation conditions, which can be 'hard' or 'soft',
                 and on selectivity issues. Selectivity issues will be
                 addressed in combination with the used separation technique
                 and a comparison between LC and CZE will be made.},
  Journal     = {Analytical and Bioanalytical Chemistry},
  Volume      = {382},
  Number      = {3},
  Pages       = {535--558},
  Month       = {06},
  Year        = {2005},
  Language    = {en},
  Issn        = {1618-2642},
  Pmid        = {15834556},
  Doi         = {10.1007/s00216-005-3120-9}
}

@article{Hilbrig2003,
  Title       = {Protein purification by affinity precipitation},
  Author      = {Hilbrig, Frank and Freitag, Ruth},
  Abstract    = {Developing the most efficient strategy for the purification of
                 a (recombinant) protein especially at large scale remains a
                 challenge. A typical problem of the downstream process of
                 mammalian cell products is, for instance, the early capture of
                 the highly diluted product from the complex process stream.
                 Affinity precipitation has been suggested in this context. The
                 technique is known for over 20 years, but has recently
                 received more attention due to the development of new
                 materials for its implementation, but also because it seems
                 ideally suited to specific product capture at large scale. The
                 present review gives a comprehensive overview over this
                 technique. Besides an introduction to the basic principle and
                 a brief summary of the historical development, the main focus
                 is on the current state-of-art of the technique, the available
                 materials, important recent applications, as well as process
                 design strategies and operating procedures. Special
                 consideration is given to affinity precipitation for product
                 recovery at large scale.},
  Journal     = {Journal of Chromatography. B, Analytical Technologies in the
                 Biomedical and Life Sciences},
  Volume      = {790},
  Number      = {1-2},
  Pages       = {79--90},
  Month       = {06},
  Year        = {2003},
  Language    = {en},
  Issn        = {1570-0232},
  Pmid        = {12767322},
  Doi         = {10.1016/S1570-0232(03)00081-3}
}

@article{Steiner2014,
  Title       = {Applications of mass spectrometry for quantitative protein
                 analysis in formalin-fixed paraffin-embedded tissues},
  Author      = {Steiner, Carine and Ducret, Axel and Tille, Jean-Christophe
                 and Thomas, Marlene and McKee, Thomas A and Rubbia-Brandt,
                 Laura and Scherl, Alexander and Lescuyer, Pierre and Cutler,
                 Paul},
  Abstract    = {Proteomic analysis of tissues has advanced in recent years as
                 instruments and methodologies have evolved. The ability to
                 retrieve peptides from formalin-fixed paraffin-embedded
                 tissues followed by shotgun or targeted proteomic analysis is
                 offering new opportunities in biomedical research. In
                 particular, access to large collections of clinically
                 annotated samples should enable the detailed analysis of
                 pathologically relevant tissues in a manner previously
                 considered unfeasible. In this paper, we review the current
                 status of proteomic analysis of formalin-fixed
                 paraffin-embedded tissues with a particular focus on targeted
                 approaches and the potential for this technique to be used in
                 clinical research and clinical diagnosis. We also discuss the
                 limitations and perspectives of the technique, particularly
                 with regard to application in clinical diagnosis and drug
                 discovery.},
  Journal     = {Proteomics},
  Volume      = {14},
  Number      = {4-5},
  Pages       = {441--451},
  Month       = {03},
  Year        = {2014},
  Keywords    = {Biomarkers; Biomedicine; Formalin-fixed paraffin-embedded
                 tissue; Oncology; SRM; Shotgun proteomics},
  Language    = {en},
  Issn        = {1615-9853, 1615-9861},
  Pmid        = {24339433},
  Doi         = {10.1002/pmic.201300311},
  Pmc         = {PMC4265304}
}

@article{MichaelMentenDepletion,
  Title       = {Digestion and depletion of abundant proteins improves
                 proteomic coverage},
  Author      = {Fonslow, Bryan R and Stein, Benjamin D and Webb, Kristofor J
                 and Xu, Tao and Choi, Jeong and Park, Sung Kyu and Yates, 3rd,
                 John R},
  Abstract    = {Two major challenges in proteomics are the large number of
                 proteins and their broad dynamic range in the cell. We
                 exploited the abundance-dependent Michaelis-Menten kinetics of
                 trypsin digestion to selectively digest and deplete abundant
                 proteins with a method we call DigDeAPr. We validated the
                 depletion mechanism with known yeast protein abundances, and
                 we observed greater than threefold improvement in
                 low-abundance human-protein identification and quantitation
                 metrics. This methodology should be broadly applicable to many
                 organisms, proteases and proteomic pipelines.},
  Journal     = {Nature Methods},
  Volume      = {10},
  Number      = {1},
  Pages       = {54--56},
  Month       = {01},
  Year        = {2013},
  Language    = {en},
  Issn        = {1548-7091, 1548-7105},
  Pmid        = {23160281},
  Doi         = {10.1038/nmeth.2250},
  Pmc         = {PMC3531578}
}

@article{Vitek2009,
  Title       = {Getting started in computational mass spectrometry-based
                 proteomics},
  Author      = {Vitek, Olga},
  Journal     = {PLoS computational biology},
  Volume      = {5},
  Number      = {5},
  Pages       = {e1000366},
  Month       = {06},
  Year        = {2009},
  Language    = {en},
  Issn        = {1553-734X, 1553-7358},
  Pmid        = {19492072},
  Doi         = {10.1371/journal.pcbi.1000366},
  Pmc         = {PMC2668757}
}

@article{Thomson1913,
  Title     = {Rays of Positive Electricity},
  Author    = {Thomson, Joseph John},
  Journal   = {Proceedings of the Royal Society of London A: Mathematical,
               Physical and Engineering Sciences},
  Publisher = {The Royal Society},
  Volume    = {89},
  Number    = {607},
  Pages     = {1--20},
  Month     = {08},
  Year      = {1913},
  Language  = {en},
  Issn      = {1364-5021, 1471-2946},
  Doi       = {10.1098/rspa.1913.0057}
}

@article{Aston1919,
  Title     = {A positive ray spectrograph},
  Author    = {Aston, Francis William},
  Journal   = {Philosophical Magazine},
  Publisher = {Taylor \& Francis},
  Volume    = {38},
  Number    = {228},
  Pages     = {707--714},
  Month     = {12},
  Year      = {1919},
  Issn      = {1478-6435, 1941-5982},
  Doi       = {10.1080/14786441208636004}
}

@article{Gundry2009,
  Title       = {Preparation of proteins and peptides for mass spectrometry
                 analysis in a bottom-up proteomics workflow},
  Author      = {Gundry, Rebekah L and White, Melanie Y and Murray, Christopher
                 I and Kane, Lesley A and Fu, Qin and Stanley, Brian A and Van
                 Eyk, Jennifer E},
  Abstract    = {This unit outlines the steps required to prepare a sample for
                 MS analysis following protein separation or enrichment by gel
                 electrophoresis, liquid chromatography, and affinity capture
                 within the context of a bottom-up proteomics workflow in which
                 the protein is first broken up into peptides, either by
                 chemical or enzymatic digestion, prior to MS analysis. Also
                 included are protocols for enrichment at the peptide level,
                 including phosphopeptide enrichment and reversed-phase
                 chromatography for sample purification immediately prior to MS
                 analysis. Finally, there is a discussion regarding the types
                 of MS technologies commonly used to analyze proteomics
                 samples, as well as important parameters that should be
                 considered when analyzing the MS data to ensure stringent and
                 robust protein identifications and characterization.},
  Journal     = {Current Protocols in Molecular Biology},
  Volume      = {Ch10},
  Number      = {10.25},
  Pages       = {1--29},
  Month       = {10},
  Year        = {2009},
  Language    = {en},
  Issn        = {1934-3639, 1934-3647},
  Pmid        = {19816929},
  Doi         = {10.1002/0471142727.mb1025s88},
  Pmc         = {PMC2905857}
}

@incollection{Chen2016,
  Title     = {Mass {Spectrometry-Based} Protein Quantification},
  Booktitle = {Modern Proteomics – Sample Preparation, Analysis and Practical
               Applications},
  Author    = {Chen, Yun and Wang, Fuqiang and Xu, Feifei and Yang, Ting},
  Abstract  = {Quantification of individual proteins and even entire proteomes
               is an important theme in proteomics research. Quantitative
               proteomics is an approach to obtain quantitative information
               about proteins in a sample. Compared to qualitative or
               semi-quantitative proteomics, this approach can provide more
               insight into the effects of a specific stimulus, such as a
               change in the expression level of a protein and its
               posttranslational modifications, or to a panel of proposed
               biomarkers in a given disease state. Proteomics methodologies,
               along with a variety of bioinformatics approaches, are a major
               tool in quantitative proteomics. As the theory and technological
               aspects underlying the proteomics methodologies will be
               extensively described in Chap. 20, and protein identification as
               a prerequisite of quantification has been discussed in Chap. 17,
               we will focus on the quantitative proteomics bioinformatics
               algorithms and software tools in this chapter. Our goal is to
               provide researchers and newcomers a rational framework to select
               suitable bioinformatics tools for data analysis, interpretation,
               and integration in protein quantification. Before doing so, a
               brief overview of quantitative proteomics is provided.},
  Publisher = {Springer, Cham},
  Pages     = {255--279},
  Series    = {Advances in Experimental Medicine and Biology},
  Year      = {2016},
  Language  = {en},
  Isbn      = {9783319414461},
  Isbn-e    = {9783319414485},
  Doi       = {10.1007/978-3-319-41448-5\_15}
}

@article{Manza2005,
  Title       = {Sample preparation and digestion for proteomic analyses using
                 spin filters},
  Author      = {Manza, Linda L and Stamer, Sheryl L and Ham, Amy-Joan L and
                 Codreanu, Simona G and Liebler, Daniel C},
  Abstract    = {We describe the use of commercially available
                 microcentrifugation devices (spin filters) for cleanup and
                 digestion of protein samples for mass spectrometry analyses.
                 The protein sample is added to the upper chamber of a spin
                 filter with a > or = 3000 molecular weight cutoff membrane and
                 then washed prior to resuspension in ammonium bicarbonate. The
                 protein is then reduced, alkylated, and digested with trypsin
                 in the upper chamber and the peptides are recovered by
                 centrifugation through the membrane. The method provides
                 digestion efficiencies comparable to standard in-solution
                 digests, avoids lengthy dialysis steps, and allows rapid
                 cleanup of samples containing salts, some detergents, and
                 acidic or basic buffers.},
  Journal     = {Proteomics},
  Volume      = {5},
  Number      = {7},
  Pages       = {1742--1745},
  Month       = {05},
  Year        = {2005},
  Language    = {en},
  Issn        = {1615-9853},
  Pmid        = {15761957},
  Doi         = {10.1002/pmic.200401063}
}

@article{Wisniewski2009,
  Title       = {Universal sample preparation method for proteome analysis},
  Author      = {Wiśniewski, Jacek R and Zougman, Alexandre and Nagaraj,
                 Nagarjuna and Mann, Matthias},
  Abstract    = {We describe a method, filter-aided sample preparation (FASP),
                 which combines the advantages of in-gel and in-solution
                 digestion for mass spectrometry-based proteomics. We
                 completely solubilized the proteome in sodium dodecyl sulfate,
                 which we then exchanged by urea on a standard filtration
                 device. Peptides eluted after digestion on the filter were
                 pure, allowing single-run analyses of organelles and an
                 unprecedented depth of proteome coverage.},
  Journal     = {Nature Methods},
  Volume      = {6},
  Number      = {5},
  Pages       = {359--362},
  Month       = {05},
  Year        = {2009},
  Language    = {en},
  Issn        = {1548-7091, 1548-7105},
  Pmid        = {19377485},
  Doi         = {10.1038/nmeth.1322}
}

@article{Shevchenko2006,
  Title       = {In-gel digestion for mass spectrometric characterization of
                 proteins and proteomes},
  Author      = {Shevchenko, Andrej and Tomas, Henrik and Havlis, Jan and
                 Olsen, Jesper V and Mann, Matthias},
  Abstract    = {In-gel digestion of proteins isolated by gel electrophoresis
                 is a cornerstone of mass spectrometry (MS)-driven proteomics.
                 The 10-year-old recipe by Shevchenko et al. has been optimized
                 to increase the speed and sensitivity of analysis. The
                 protocol is for the in-gel digestion of both silver and
                 Coomassie-stained protein spots or bands and can be followed
                 by MALDI-MS or LC-MS/MS analysis to identify proteins at
                 sensitivities better than a few femtomoles of protein starting
                 material.},
  Journal     = {Nature Protocols},
  Volume      = {1},
  Number      = {6},
  Pages       = {2856--2860},
  Year        = {2006},
  Language    = {en},
  Issn        = {1754-2189, 1750-2799},
  Pmid        = {17406544},
  Doi         = {10.1038/nprot.2006.468}
}

@article{Pappin1993,
  Title       = {Rapid identification of proteins by peptide-mass
                 fingerprinting},
  Author      = {Pappin, D J and Hojrup, P and Bleasby, A J},
  Abstract    = {BACKGROUND: Developments in 'soft' ionisation techniques have
                 revolutionized mass-spectro-metric approaches for the analysis
                 of protein structure. For more than a decade, such techniques
                 have been used, in conjuction with digestion b specific
                 proteases, to produce accurate peptide molecular weight
                 'fingerprints' of proteins. These fingerprints have commonly
                 been used to screen known proteins, in order to detect errors
                 of translation, to characterize post-translational
                 modifications and to assign diulphide bonds. However, the
                 extent to which peptide-mass information can be used alone to
                 identify unknown sample proteins, independent of other
                 analytical methods such as protein sequence analysis, has
                 remained largely unexplored. RESULTS: We report here on the
                 development of the molecular weight search (MOWSE)
                 peptide-mass database at the SERC Daresbury Laboratory.
                 Practical experience has shown that sample proteins can be
                 uniquely identified from a few as three or four experimentally
                 determined peptide masses when these are screened against a
                 fragment database that is derived from over 50 000 proteins.
                 Experimental errors of a few Daltons are tolerated by the
                 scoring algorithms, thus permitting the use of inexpensive
                 time-of-flight mass spectrometers. As with other types of
                 physical data, such as amino-acid composition or linear
                 sequence, peptide masses provide a set of determinants that
                 are sufficiently discriminating to identify or match unknown
                 sample proteins. CONCLUSION: Peptide-mass fingerprints can
                 prove as discriminating as linear peptide sequences, but can
                 be obtained in a fraction of the time using less protein. In
                 many cases, this allows for a rapid identification of a sample
                 protein before committing it to protein sequence analysis.
                 Fragment masses also provide information, at the protein
                 level, that is complementary to the information provided by
                 large-scale DNA sequencing or mapping projects.},
  Journal     = {Current Biology},
  Volume      = {3},
  Number      = {6},
  Pages       = {327--332},
  Month       = {06},
  Year        = {1993},
  Language    = {en},
  Issn        = {0960-9822},
  Pmid        = {15335725}
}

@article{Luge2016,
  Title       = {Generating {Sample-Specific} Databases for Mass
                 {Spectrometry-Based} Proteomic Analysis by Using {RNA}
                 Sequencing},
  Author      = {Luge, Toni and Sauer, Sascha},
  Abstract    = {Mass spectrometry-based methods allow for the direct,
                 comprehensive analysis of expressed proteins and their
                 quantification among different conditions. However, in general
                 identification of proteins by assigning experimental mass
                 spectra to peptide sequences of proteins relies on matching
                 mass spectra to theoretical spectra derived from genomic
                 databases of organisms. This conventional approach limits the
                 applicability of proteomic methodologies to species for which
                 a genome reference sequence is available. Recently,
                 RNA-sequencing (RNA-Seq) became a valuable tool to overcome
                 this limitation by de novo construction of databases for
                 organisms for which no DNA sequence is available, or by
                 refining existing genomic databases with transcriptomic data.
                 Here we present a generic pipeline to make use of
                 transcriptomic data for proteomics experiments. We show in
                 particular how to efficiently fuel proteomic analysis
                 workflows with sample-specific RNA-sequencing databases. This
                 approach is useful for the proteomic analysis of so far
                 unsequenced organisms, complex microbial
                 metatranscriptomes/metaproteomes (for example in the human
                 body), and for refining current proteomics data analysis that
                 solely relies on the genomic sequence and predicted gene
                 expression but not on validated gene products. Finally, the
                 approach used in the here presented protocol can help to
                 improve the data quality of conventional proteomics
                 experiments that can be influenced by genetic variation or
                 splicing events.},
  Journal     = {Methods in Molecular Biology},
  Volume      = {1394},
  Pages       = {219--232},
  Year        = {2016},
  Keywords    = {Gene expression; Mass spectrometry; Metaproteomics;
                 Proteogenomics; Proteomics informed by transcriptomics},
  Language    = {en},
  Issn        = {1064-3745, 1940-6029},
  Pmid        = {26700052},
  Doi         = {10.1007/978-1-4939-3341-9\_16}
}

@incollection{Haag2016,
  Title     = {Mass Analyzers and Mass Spectrometers},
  Booktitle = {Modern Proteomics – Sample Preparation, Analysis and Practical
               Applications},
  Author    = {Haag, Anthony M},
  Abstract  = {Mass spectrometers are comprised of three main components: an
               ion source, a mass analyzer, and a detector. Ionization of the
               analyte occurs in the ion source and the resulting ions are
               counted at the detector. However, it is the mass analyzer that
               is responsible for determing the mass-to-charge ratio (m/z) of
               the ions (Jennings KR, Dolnikowski GG, Method Enzymol 193:37–61,
               1990). Therefore, it is primarily the analyzer that allows the
               mass spectrometer to serve its primary goal – determining the
               mass of the analytes being measured. This becomes important in
               the field of molecular biology, where biomolecules may be of low
               molecular weight or often take on multiple charges (z) after
               ionization (Fenn JB, Mann M, Meng CK, Wong SF, Whitehouse CM,
               Science 246:64–71, 1989). For this reason, the choice of
               analyzer is dependant on the properties of the analyte after
               ionization and the requirements of the experiment being
               performed.},
  Publisher = {Springer, Cham},
  Pages     = {157--169},
  Series    = {Advances in Experimental Medicine and Biology},
  Year      = {2016},
  Language  = {en},
  Isbn      = {9783319414461},
  Isbn-e    = {9783319414485},
  Doi       = {10.1007/978-3-319-41448-5\_7}
}

@article{Makarov2000,
  Title     = {Electrostatic Axially Harmonic Orbital Trapping: A
               {High-Performance} Technique of Mass Analysis},
  Author    = {Makarov, Alexander},
  Abstract  = {This work describes a new type of mass analyzer which employs
               trapping in an electrostatic field. The potential distribution
               of the field can be represented as a combination of quadrupole
               and logarithmic potentials. In the absence of any magnetic or rf
               fields, ion stability is achieved only due to ions orbiting
               around an axial electrode. Orbiting ions also perform harmonic
               oscillations along the electrode with frequency proportional to
               (m/z)-1/2. These oscillations are detected using image current
               detection and are transformed into mass spectra using fast FT,
               similarly to FT ICR. Practical aspects of the trap design are
               presented. High-mass resolution up to 150 000 for ions produced
               by laser ablation has been demonstrated, along with high-energy
               acceptance and wide mass range.},
  Journal   = {Analytical Chemistry},
  Publisher = {American Chemical Society},
  Volume    = {72},
  Number    = {6},
  Pages     = {1156--1162},
  Month     = {03},
  Year      = {2000},
  Issn      = {0003-2700},
  Doi       = {10.1021/ac991131p}
}

@article{Walther2010,
  Title     = {Mass spectrometry–based proteomics in cell biology},
  Author    = {Walther, Tobias C and Mann, Matthias},
  Abstract  = {The global analysis of protein composition, modifications, and
               dynamics are important goals in cell biology. Mass spectrometry
               (MS)–based proteomics has matured into an attractive technology
               for this purpose. Particularly, high resolution MS methods have
               been extremely successful for quantitative analysis of cellular
               and organellar proteomes. Rapid advances in all areas of the
               proteomic workflow, including sample preparation, MS, and
               computational analysis, should make the technology more easily
               available to a broad community and turn it into a staple
               methodology for cell biologists.},
  Journal   = {The Journal of Cell Biology},
  Publisher = {Rockefeller University Press},
  Volume    = {190},
  Number    = {4},
  Pages     = {491--500},
  Month     = {08},
  Year      = {2010},
  Language  = {en},
  Issn      = {0021-9525, 1540-8140},
  Pmid      = {20733050},
  Doi       = {10.1083/jcb.201004052}
}

@article{Scigelova2011,
  Title       = {Fourier transform mass spectrometry},
  Author      = {Scigelova, Michaela and Hornshaw, Martin and Giannakopulos,
                 Anastassios and Makarov, Alexander},
  Abstract    = {This article provides an introduction to Fourier
                 transform-based mass spectrometry. The key performance
                 characteristics of Fourier transform-based mass spectrometry,
                 mass accuracy and resolution, are presented in the view of how
                 they impact the interpretation of measurements in proteomic
                 applications. The theory and principles of operation of two
                 types of mass analyzer, Fourier transform ion cyclotron
                 resonance and Orbitrap, are described. Major benefits as well
                 as limitations of Fourier transform-based mass spectrometry
                 technology are discussed in the context of practical sample
                 analysis, and illustrated with examples included as figures in
                 this text and in the accompanying slide set. Comparisons
                 highlighting the performance differences between the two mass
                 analyzers are made where deemed useful in assisting the user
                 with choosing the most appropriate technology for an
                 application. Recent developments of these high-performing mass
                 spectrometers are mentioned to provide a future outlook.},
  Journal     = {Molecular \& Cellular Proteomics},
  Volume      = {10},
  Number      = {7},
  Pages       = {M111.009431},
  Month       = {07},
  Year        = {2011},
  Language    = {en},
  Issn        = {1535-9476, 1535-9484},
  Pmid        = {21742802},
  Doi         = {10.1074/mcp.M111.009431},
  Pmc         = {PMC3134075}
}

@article{Hu2005,
  Title       = {The Orbitrap: a new mass spectrometer},
  Author      = {Hu, Qizhi and Noll, Robert J and Li, Hongyan and Makarov,
                 Alexander and Hardman, Mark and Graham Cooks, R},
  Abstract    = {Research areas such as proteomics and metabolomics are driving
                 the demand for mass spectrometers that have high performance
                 but modest power requirements, size, and cost. This paper
                 describes such an instrument, the Orbitrap, based on a new
                 type of mass analyzer invented by Makarov. The Orbitrap
                 operates by radially trapping ions about a central spindle
                 electrode. An outer barrel-like electrode is coaxial with the
                 inner spindlelike electrode and mass/charge values are
                 measured from the frequency of harmonic ion oscillations,
                 along the axis of the electric field, undergone by the
                 orbitally trapped ions. This axial frequency is independent of
                 the energy and spatial spread of the ions. Ion frequencies are
                 measured non-destructively by acquisition of time-domain image
                 current transients, with subsequent fast Fourier transforms
                 (FFTs) being used to obtain the mass spectra. In addition to
                 describing the Orbitrap mass analyzer, this paper also
                 describes a complete Orbitrap-based mass spectrometer,
                 equipped with an electrospray ionization source (ESI). Ions
                 are transferred from the ESI source through three stages of
                 differential pumping using RF guide quadrupoles. The third
                 quadrupole, pressurized to less than 10(-3) Torr with
                 collision gas, acts as an ion accumulator; ion/neutral
                 collisions slow the ions and cause them to pool in an axial
                 potential well at the end of the quadrupole. Ion bunches are
                 injected from this pool into the Orbitrap analyzer for mass
                 analysis. The ion injection process is described in a
                 simplified way, including a description of electrodynamic
                 squeezing, field compensation for the effects of the ion
                 injection slit, and criteria for orbital stability. Features
                 of the Orbitrap at its present stage of development include
                 high mass resolution (up to 150,000), large space charge
                 capacity, high mass accuracy (2-5 ppm), a mass/charge range of
                 at least 6000, and dynamic range greater than 10(3).
                 Applications based on electrospray ionization are described,
                 including characterization of transition-metal complexes,
                 oligosaccharides, peptides, and proteins. Use is also made of
                 the high-resolution capabilities of the Orbitrap to confirm
                 the presence of metaclusters of serine octamers in ESI mass
                 spectra and to perform H/D exchange experiments on these ions
                 in the storage quadrupole.},
  Journal     = {Journal of Mass Spectrometry},
  Volume      = {40},
  Number      = {4},
  Pages       = {430--443},
  Month       = {04},
  Year        = {2005},
  Language    = {en},
  Issn        = {1076-5174},
  Pmid        = {15838939},
  Doi         = {10.1002/jms.856}
}

@article{Syka2004,
  Title       = {Peptide and protein sequence analysis by electron transfer
                 dissociation mass spectrometry},
  Author      = {Syka, John E P and Coon, Joshua J and Schroeder, Melanie J and
                 Shabanowitz, Jeffrey and Hunt, Donald F},
  Abstract    = {Peptide sequence analysis using a combination of gas-phase
                 ion/ion chemistry and tandem mass spectrometry (MS/MS) is
                 demonstrated. Singly charged anthracene anions transfer an
                 electron to multiply protonated peptides in a radio frequency
                 quadrupole linear ion trap (QLT) and induce fragmentation of
                 the peptide backbone along pathways that are analogous to
                 those observed in electron capture dissociation. Modifications
                 to the QLT that enable this ion/ion chemistry are presented,
                 and automated acquisition of high-quality, single-scan
                 electron transfer dissociation MS/MS spectra of
                 phosphopeptides separated by nanoflow HPLC is described.},
  Journal     = {Proceedings of the National Academy of Sciences of the United
                 States of America},
  Volume      =  {101},
  Number      =  {26},
  Pages       = {9528--9533},
  Month       = {06},
  Year        = {2004},
  Language    = {en},
  Issn        = {0027-8424},
  Pmid        = {15210983},
  Doi         = {10.1073/pnas.0402700101},
  Pmc         = {PMC470779}
}

@article{Madalinski2008,
  Title       = {Direct introduction of biological samples into a
                 {LTQ-Orbitrap} hybrid mass spectrometer as a tool for fast
                 metabolome analysis},
  Author      = {Madalinski, Geoffrey and Godat, Emmanuel and Alves, Sandra and
                 Lesage, Denis and Genin, Eric and Levi, Philippe and Labarre,
                 Jean and Tabet, Jean-Claude and Ezan, Eric and Junot,
                 Christophe},
  Abstract    = {We report the direct introduction of biological samples into a
                 high-resolution mass spectrometer, the LTQ-Orbitrap, as a fast
                 tool for metabolomic studies. A proof of concept study was
                 performed on yeast cell extracts that were introduced into the
                 mass spectrometer by using flow injection analysis, with an
                 acquisition time of 3 min. Typical mass spectra contained a
                 few thousand m/z signals, 400 of which were found to be
                 analytically relevant (i.e., their intensity was 3-fold higher
                 than that of the background noise and they occurred in at
                 least 60\% of the acquisition profiles under identical
                 experimental conditions). The method was validated by studies
                 of the matrix effect, linearity, and intra-assay precision.
                 Accurate mass measurements in the Orbitrap discriminated
                 between isobaric ions and also indicated the elemental
                 composition of the ions of interest with mass errors below 5
                 ppm, for identification purposes. The proposed structures were
                 then assessed by MSn experiments via the linear ion trap,
                 together with accurate mass determination of the product ions
                 in the Orbitrap analyzer. When applied to the study of cadmium
                 toxicity, the method was as effective as that initially
                 developed by using LC/ESI-MS/MS for a targeted approach. The
                 same metabolic fingerprints were also subjected to
                 multivariate statistical analyses. The results highlighted a
                 reorganization of amino acid metabolism under cadmium
                 conditions in order to increase the biosynthesis of
                 glutathione.},
  Journal     = {Analytical Chemistry},
  Volume      = {80},
  Number      = {9},
  Pages       = {3291--3303},
  Month       = {05},
  Year        = {2008},
  Language    = {en},
  Issn        = {0003-2700,1520-6882},
  Pmid        = {18351782},
  Doi         = {10.1021/ac7024915}
}

@article{perseus2016,
  Title       = {The Perseus computational platform for comprehensive analysis
                 of (prote)omics data},
  Author      = {Tyanova, Stefka and Temu, Tikira and Sinitcyn, Pavel and
                 Carlson, Arthur and Hein, Marco Y and Geiger, Tamar and Mann,
                 Matthias and Cox, Jürgen},
  Abstract    = {A main bottleneck in proteomics is the downstream biological
                 analysis of highly multivariate quantitative protein abundance
                 data generated using mass-spectrometry-based analysis. We
                 developed the Perseus software platform
                 (http://www.perseus-framework.org) to support biological and
                 biomedical researchers in interpreting protein quantification,
                 interaction and post-translational modification data. Perseus
                 contains a comprehensive portfolio of statistical tools for
                 high-dimensional omics data analysis covering normalization,
                 pattern recognition, time-series analysis, cross-omics
                 comparisons and multiple-hypothesis testing. A machine
                 learning module supports the classification and validation of
                 patient groups for diagnosis and prognosis, and it also
                 detects predictive protein signatures. Central to Perseus is a
                 user-friendly, interactive workflow environment that provides
                 complete documentation of computational methods used in a
                 publication. All activities in Perseus are realized as
                 plugins, and users can extend the software by programming
                 their own, which can be shared through a plugin store. We
                 anticipate that Perseus's arsenal of algorithms and its
                 intuitive usability will empower interdisciplinary analysis of
                 complex large data sets.},
  Journal     = {Nature Methods},
  Volume      = {13},
  Number      = {9},
  Pages       = {731--740},
  Month       = {09},
  Year        = {2016},
  Language    = {en},
  Issn        = {1548-7091, 1548-7105},
  Pmid        = {27348712},
  Doi         = {10.1038/nmeth.3901}
}

@article{Nilsson2010,
  Title       = {Mass spectrometry in high-throughput proteomics: ready for the
                 big time},
  Author      = {Nilsson, Tommy and Mann, Matthias and Aebersold, Ruedi and
                 Yates, 3rd, John R and Bairoch, Amos and Bergeron, John J M},
  Abstract    = {Mass spectrometry has evolved and matured to a level where it
                 is able to assess the complexity of the human proteome. We
                 discuss some of the expected challenges ahead and promising
                 strategies for success.},
  Journal     = {Nature Methods},
  Volume      = {7},
  Number      = {9},
  Pages       = {681--685},
  Month       = {09},
  Year        = {2010},
  Language    = {en},
  Issn        = {1548-7091, 1548-7105},
  Pmid        = {20805795},
  Doi         = {10.1038/nmeth0910-681}
}

@incollection{Bauer2011,
  Title     = {Evaluation of {Peak-Picking} Algorithms for Protein Mass
               Spectrometry},
  Booktitle = {Data Mining in Proteomics: From Standards to Applications},
  Author    = {Bauer, Chris and Cramer, Rainer and Schuchhardt, Johannes},
  Editor    = {Hamacher, Michael and Eisenacher, Martin and Stephan, Christian},
  Abstract  = {Peak picking is an early key step in MS data analysis. We
               compare three commonly used approaches to peak picking and
               discuss their merits by means of statistical analysis. Methods
               investigated encompass signal-to-noise ratio, continuous wavelet
               transform, and a correlation-based approach using a Gaussian
               template.},
  Publisher = {Humana Press},
  Pages     = {341--352},
  Year      = {2011},
  Address   = {Totowa, NJ},
  Isbn      = {9781607619871},
  Doi       = {10.1007/978-1-60761-987-1\_22}
}

@article{Nitpick,
  Title       = {{NITPICK}: peak identification for mass spectrometry data},
  Author      = {Renard, Bernhard Y and Kirchner, Marc and Steen, Hanno and
                 Steen, Judith A J and Hamprecht, Fred A},
  Abstract    = {BACKGROUND: The reliable extraction of features from mass
                 spectra is a fundamental step in the automated analysis of
                 proteomic mass spectrometry (MS) experiments. RESULTS: This
                 contribution proposes a sparse template regression approach to
                 peak picking called NITPICK. NITPICK is a Non-greedy,
                 Iterative Template-based peak PICKer that deconvolves complex
                 overlapping isotope distributions in multicomponent mass
                 spectra. NITPICK is based on fractional averaging, a novel
                 extension to Senko's well-known averaging model, and on a
                 modified version of sparse, non-negative least angle
                 regression, for which a suitable, statistically motivated
                 early stopping criterion has been derived. The strength of
                 NITPICK is the deconvolution of overlapping mixture mass
                 spectra. CONCLUSION: Extensive comparative evaluation has been
                 carried out and results are provided for simulated and
                 real-world data sets. NITPICK outperforms pepex, to date the
                 only alternate, publicly available, non-greedy feature
                 extraction routine. NITPICK is available as software package
                 for the R programming language and can be downloaded from
                 (http://hci.iwr.uni-heidelberg.de/mip/proteomics/).},
  Journal     = {BMC Bioinformatics},
  Volume      = {9},
  Pages       = {355},
  Month       = {08},
  Year        = {2008},
  Language    = {en},
  Issn        = {1471-2105},
  Pmid        = {18755032},
  Doi         = {10.1186/1471-2105-9-355},
  Pmc         = {PMC2655099}
}

@incollection{Codrea2016,
  Title     = {Platforms and Pipelines for Proteomics Data Analysis and
               Management},
  Booktitle = {Modern Proteomics – Sample Preparation, Analysis and Practical
               Applications},
  Author    = {Codrea, Marius Cosmin and Nahnsen, Sven},
  Abstract  = {Since mass spectrometry was introduced as the core technology
               for large-scale analysis of the proteome, the speed of data
               acquisition, dynamic ranges of measurements, and data quality
               are continuously improving. These improvements are triggered by
               regular launches of new methodologies and instruments.},
  Publisher = {Springer, Cham},
  Pages     = {203--215},
  Series    = {Advances in Experimental Medicine and Biology},
  Year      = {2016},
  Language  = {en},
  Isbn      = {9783319414461},
  Isbn-e    = {9783319414485},
  Doi       = {10.1007/978-3-319-41448-5\_9}
}

@article{maxquant2016,
  Title       = {The {MaxQuant} computational platform for mass
                 spectrometry-based shotgun proteomics},
  Author      = {Tyanova, Stefka and Temu, Tikira and Cox, Juergen},
  Abstract    = {MaxQuant is one of the most frequently used platforms for
                 mass-spectrometry (MS)-based proteomics data analysis. Since
                 its first release in 2008, it has grown substantially in
                 functionality and can be used in conjunction with more MS
                 platforms. Here we present an updated protocol covering the
                 most important basic computational workflows, including those
                 designed for quantitative label-free proteomics, MS1-level
                 labeling and isobaric labeling techniques. This protocol
                 presents a complete description of the parameters used in
                 MaxQuant, as well as of the configuration options of its
                 integrated search engine, Andromeda. This protocol update
                 describes an adaptation of an existing protocol that
                 substantially modifies the technique. Important concepts of
                 shotgun proteomics and their implementation in MaxQuant are
                 briefly reviewed, including different quantification
                 strategies and the control of false-discovery rates (FDRs), as
                 well as the analysis of post-translational modifications
                 (PTMs). The MaxQuant output tables, which contain information
                 about quantification of proteins and PTMs, are explained in
                 detail. Furthermore, we provide a short version of the
                 workflow that is applicable to data sets with simple and
                 standard experimental designs. The MaxQuant algorithms are
                 efficiently parallelized on multiple processors and scale well
                 from desktop computers to servers with many cores. The
                 software is written in C\# and is freely available at
                 http://www.maxquant.org.},
  Journal     = {Nature Protocols},
  Volume      = {11},
  Number      = {12},
  Pages       = {2301--2319},
  Month       = {12},
  Year        = {2016},
  Language    = {en},
  Issn        = {1754-2189, 1750-2799},
  Pmid        = {27809316},
  Doi         = {10.1038/nprot.2016.136}
}

@article{Eng2011,
  Title       = {A face in the crowd: recognizing peptides through database
                 search},
  Author      = {Eng, Jimmy K and Searle, Brian C and Clauser, Karl R and Tabb,
                 David L},
  Abstract    = {Peptide identification via tandem mass spectrometry sequence
                 database searching is a key method in the array of tools
                 available to the proteomics researcher. The ability to rapidly
                 and sensitively acquire tandem mass spectrometry data and
                 perform peptide and protein identifications has become a
                 commonly used proteomics analysis technique because of
                 advances in both instrumentation and software. Although many
                 different tandem mass spectrometry database search tools are
                 currently available from both academic and commercial sources,
                 these algorithms share similar core elements while maintaining
                 distinctive features. This review revisits the mechanism of
                 sequence database searching and discusses how various
                 parameter settings impact the underlying search.},
  Journal     = {Molecular \& Cellular Proteomics},
  Volume      = {10},
  Number      = {11},
  Pages       = {R111.009522},
  Month       = {11},
  Year        = {2011},
  Language    = {en},
  Issn        = {1535-9476, 1535-9484},
  Pmid        = {21876205},
  Doi         = {10.1074/mcp.R111.009522},
  Pmc         = {PMC3226415}
}

@article{Griss2016,
  Title       = {Spectral library searching in proteomics},
  Author      = {Griss, Johannes},
  Abstract    = {Spectral library searching has become a mature method to
                 identify tandem mass spectra in proteomics data analysis. This
                 review provides a comprehensive overview of available spectral
                 library search engines and highlights their distinct features.
                 Additionally, resources providing spectral libraries are
                 summarized and tools presented that extend experimental
                 spectral libraries by simulating spectra. Finally, spectrum
                 clustering algorithms are discussed that utilize the same
                 spectrum-to-spectrum matching algorithms as spectral library
                 search engines and allow novel methods to analyse proteomics
                 data.},
  Journal     = {Proteomics},
  Volume      = {16},
  Number      = {5},
  Pages       = {729--740},
  Month       = {03},
  Year        = {2016},
  Keywords    = {Bioinformatics; Spectral libraries; Spectral library
                 searching; Spectrum clustering},
  Language    = {en},
  Issn        = {1615-9853, 1615-9861},
  Pmid        = {26616598},
  Doi         = {10.1002/pmic.201500296}
}

@article{Shteynberg2013,
  Title       = {Combining results of multiple search engines in proteomics},
  Author      = {Shteynberg, David and Nesvizhskii, Alexey I and Moritz, Robert
                 L and Deutsch, Eric W},
  Abstract    = {A crucial component of the analysis of shotgun proteomics
                 datasets is the search engine, an algorithm that attempts to
                 identify the peptide sequence from the parent molecular ion
                 that produced each fragment ion spectrum in the dataset. There
                 are many different search engines, both commercial and open
                 source, each employing a somewhat different technique for
                 spectrum identification. The set of high-scoring
                 peptide-spectrum matches for a defined set of input spectra
                 differs markedly among the various search engine results;
                 individual engines each provide unique correct identifications
                 among a core set of correlative identifications. This has led
                 to the approach of combining the results from multiple search
                 engines to achieve improved analysis of each dataset. Here we
                 review the techniques and available software for combining the
                 results of multiple search engines and briefly compare the
                 relative performance of these techniques.},
  Journal     = {Molecular \& Cellular Proteomics},
  Volume      = {12},
  Number      = {9},
  Pages       = {2383--2393},
  Month       = {09},
  Year        = {2013},
  Language    = {en},
  Issn        = {1535-9476, 1535-9484},
  Pmid        = {23720762},
  Doi         = {10.1074/mcp.R113.027797},
  Pmc         = {PMC3769318}
}

@article{proteowizard2012,
  Title    = {A cross-platform toolkit for mass spectrometry and proteomics},
  Author   = {Chambers, Matthew C and Maclean, Brendan and Burke, Robert and
              Amodei, Dario and Ruderman, Daniel L and Neumann, Steffen and
              Gatto, Laurent and Fischer, Bernd and Pratt, Brian and Egertson,
              Jarrett and Hoff, Katherine and Kessner, Darren and Tasman,
              Natalie and Shulman, Nicholas and Frewen, Barbara and Baker,
              Tahmina A and Brusniak, Mi-Youn and Paulse, Christopher and
              Creasy, David and Flashner, Lisa and Kani, Kian and Moulding,
              Chris and Seymour, Sean L and Nuwaysir, Lydia M and Lefebvre,
              Brent and Kuhlmann, Frank and Roark, Joe and Rainer, Paape and
              Detlev, Suckau and Hemenway, Tina and Huhmer, Andreas and
              Langridge, James and Connolly, Brian and Chadick, Trey and Holly,
              Krisztina and Eckels, Josh and Deutsch, Eric W and Moritz, Robert
              L and Katz, Jonathan E and Agus, David B and MacCoss, Michael and
              Tabb, David L and Mallick, Parag},
  Journal  = {Nature Biotechnology},
  Volume   = {30},
  Number   = {10},
  Pages    = {918--920},
  Month    = {11},
  Year     = {2012},
  Language = {en},
  Issn     = {1087-0156, 1546-1696},
  Pmid     = {23051804},
  Doi      = {10.1038/nbt.2377},
  Pmc      = {PMC3471674}
}

@article{Deutsch2010,
  Title       = {Mass spectrometer output file format {mzML}},
  Author      = {Deutsch, Eric W},
  Abstract    = {Mass spectrometry is an important technique for analyzing
                 proteins and other biomolecular compounds in biological
                 samples. Each of the vendors of these mass spectrometers uses
                 a different proprietary binary output file format, which has
                 hindered data sharing and the development of open source
                 software for downstream analysis. The solution has been to
                 develop, with the full participation of academic researchers
                 as well as software and hardware vendors, an open XML-based
                 format for encoding mass spectrometer output files, and then
                 to write software to use this format for archiving, sharing,
                 and processing. This chapter presents the various components
                 and information available for this format, mzML. In addition
                 to the XML schema that defines the file structure, a
                 controlled vocabulary provides clear terms and definitions for
                 the spectral metadata, and a semantic validation rules mapping
                 file allows the mzML semantic validator to insure that an mzML
                 document complies with one of several levels of requirements.
                 Complete documentation and example files insure that the
                 format may be uniformly implemented. At the time of release,
                 there already existed several implementations of the format
                 and vendors have committed to supporting the format in their
                 products.},
  Journal     = {Methods in Molecular Biology},
  Volume      = {604},
  Pages       = {319--331},
  Year        = {2010},
  Language    = {en},
  Issn        = {1064-3745, 1940-6029},
  Pmid        = {20013381},
  Doi         = {10.1007/978-1-60761-444-9\_22},
  Pmc         = {PMC3073315}
}

@article{mzML,
  Title    = {{mzML} — A Community Standard for Mass Spectrometry Data},
  Author   = {Martens, Lennart and Chambers, Matthew and Sturm, Marc and
              Kessner, Darren and Levander, Fredrik and Shofstahl, Jim and
              Tang, Wilfred H and Römpp, Andreas and Neumann, Steffen and
              Pizarro, Angel D and Montecchi-Palazzi, Luisa and Tasman, Natalie
              and Coleman, Mike and Reisinger, Florian and Souda, Puneet and
              Hermjakob, Henning and Binz, Pierre-Alain and Deutsch, Eric W},
  Abstract = {Mass spectrometry is a fundamental tool for discovery and
              analysis in the life sciences. With the rapid advances in mass
              spectrometry technology and methods, it has become imperative to
              provide a standard output format for mass spectrometry data that
              will facilitate data sharing and analysis. Initially, the efforts
              to develop a standard format for mass spectrometry data resulted
              in multiple formats, each designed with a different underlying
              philosophy. To resolve the issues associated with having multiple
              formats, vendors, researchers, and software developers convened
              under the banner of the HUPO PSI to develop a single standard.
              The new data format incorporated many of the desirable technical
              attributes from the previous data formats, while adding a number
              of improvements, including features such as a controlled
              vocabulary with validation tools to ensure consistent usage of
              the format, improved support for selected reaction monitoring
              data, and immediately available implementations to facilitate
              rapid adoption by the community. The resulting standard data
              format, mzML, is a well tested open-source format for mass
              spectrometer output files that can be readily utilized by the
              community and easily adapted for incremental advances in mass
              spectrometry technology.},
  Journal  = {Molecular \& Cellular Proteomics},
  Volume   =  {10},
  Number   =  {1},
  Month    =  {01},
  Year     =  {2011},
  Issn     = {1535-9476},
  Doi      = {10.1074/mcp.R110.000133}
}

@article{Nahnsen2013,
  Title       = {Tools for label-free peptide quantification},
  Author      = {Nahnsen, Sven and Bielow, Chris and Reinert, Knut and
                 Kohlbacher, Oliver},
  Abstract    = {The increasing scale and complexity of quantitative proteomics
                 studies complicate subsequent analysis of the acquired data.
                 Untargeted label-free quantification, based either on feature
                 intensities or on spectral counting, is a method that scales
                 particularly well with respect to the number of samples. It is
                 thus an excellent alternative to labeling techniques. In order
                 to profit from this scalability, however, data analysis has to
                 cope with large amounts of data, process them automatically,
                 and do a thorough statistical analysis in order to achieve
                 reliable results. We review the state of the art with respect
                 to computational tools for label-free quantification in
                 untargeted proteomics. The two fundamental approaches are
                 feature-based quantification, relying on the summed-up mass
                 spectrometric intensity of peptides, and spectral counting,
                 which relies on the number of MS/MS spectra acquired for a
                 certain protein. We review the current algorithmic approaches
                 underlying some widely used software packages and briefly
                 discuss the statistical strategies for analyzing the data.},
  Journal     = {Molecular \& Cellular Proteomics},
  Volume      = {12},
  Number      = {3},
  Pages       = {549--556},
  Month       = {03},
  Year        = {2013},
  Language    = {en},
  Issn        = {1535-9476, 1535-9484},
  Pmid        = {23250051},
  Doi         = {10.1074/mcp.R112.025163},
  Pmc         = {PMC3591650}
}

@article {Wright-2016,
  Title = {Improving GENCODE reference gene annotation using a high-stringency
          proteogenomics workflow},
  Abstract={Complete annotation of the human genome is indispensable for
          medical research. The GENCODE consortium strives to provide this,
          augmenting computational and experimental evidence with manual annotation.
          The rapidly developing field of proteogenomics provides evidence for the
          translation of genes into proteins and can be used to discover and refine
          gene models. However, for both the proteomics and annotation groups,
          there is a lack of guidelines for integrating this data. Here we report
          a stringent workflow for the interpretation of proteogenomic data that
          could be used by the annotation community to interpret novel proteogenomic
          evidence. Based on reprocessing of three large-scale publicly available
          human data sets, we show that a conservative approach, using stringent
          filtering is required to generate valid identifications. Evidence has
          been found supporting 16 novel protein-coding genes being added to GENCODE.
          Despite this many peptide identifications in pseudogenes cannot be
          annotated due to the absence of orthogonal supporting evidence.},
  Author = {Wright, James C and Mudge, Jonathan and Weisser, Hendrik and
          Barzine, Mitra P and Gonzalez, Jose M and Brazma, Alvis and
          Choudhary, Jyoti S and Harrow, Jennifer},
  DOI = {10.1038/ncomms11778},
  Volume = {7},
  Month = {06},
  Year = {2016},
  Journal = {Nature Communications},
  ISSN = {2041-1723},
  Pages = {11778},
  URL = {http://dx.doi.org/10.1038/ncomms11778},
  PMID = {27250503}
}

@article{Weisser2016-pipeline,
  Title       = {Flexible Data Analysis Pipeline for {High-Confidence}
                 Proteogenomics},
  Author      = {Weisser, Hendrik and Wright, James C and Mudge, Jonathan M and
                 Gutenbrunner, Petra and Choudhary, Jyoti S},
  Abstract    = {Proteogenomics leverages information derived from proteomic
                 data to improve genome annotations. Of particular interest are
                 ``novel'' peptides that provide direct evidence of protein
                 expression for genomic regions not previously annotated as
                 protein-coding. We present a modular, automated data analysis
                 pipeline aimed at detecting such ``novel'' peptides in
                 proteomic data sets. This pipeline implements criteria
                 developed by proteomics and genome annotation experts for
                 high-stringency peptide identification and filtering. Our
                 pipeline is based on the OpenMS computational framework; it
                 incorporates multiple database search engines for peptide
                 identification and applies a machine-learning approach
                 (Percolator) to post-process search results. We describe
                 several new and improved software tools that we developed to
                 facilitate proteogenomic analyses that enhance the wealth of
                 tools provided by OpenMS. We demonstrate the application of
                 our pipeline to a human testis tissue data set previously
                 acquired for the Chromosome-Centric Human Proteome Project,
                 which led to the addition of five new gene annotations on the
                 human reference genome.},
  Journal     = {Journal of Proteome Research},
  Volume      = {15},
  Number      = {12},
  Pages       = {4686--4695},
  Month       = {12},
  Year        = {2016},
  Keywords    = {bioinformatics; genome annotation; mass spectrometry;
                 proteogenomics; testis; workflow},
  Language    = {en},
  Issn        = {1535-3893, 1535-3907},
  Pmid        = {27786492},
  Doi         = {10.1021/acs.jproteome.6b00765}
}

@article{UniProt2017,
  Title    = {{UniProt}: the universal protein knowledgebase},
  Author   = {{The UniProt Consortium}},
  Abstract = {The UniProt knowledgebase is a large resource of protein
              sequences and associated detailed annotation. The database
              contains over 60 million sequences, of which over half a million
              sequences have been curated by experts who critically review
              experimental and predicted data for each protein. The remainder
              are automatically annotated based on rule systems that rely on
              the expert curated knowledge. Since our last update in 2014, we
              have more than doubled the number of reference proteomes to 5631,
              giving a greater coverage of taxonomic diversity. We implemented
              a pipeline to remove redundant highly similar proteomes that were
              causing excessive redundancy in UniProt. The initial run of this
              pipeline reduced the number of sequences in UniProt by 47
              million. For our users interested in the accessory proteomes, we
              have made available sets of pan proteome sequences that cover the
              diversity of sequences for each species that is found in its
              strains and sub-strains. To help interpretation of genomic
              variants, we provide tracks of detailed protein information for
              the major genome browsers. We provide a SPARQL endpoint that
              allows complex queries of the more than 22 billion triples of
              data in UniProt (http://sparql.uniprot.org/). UniProt resources
              can be accessed via the website at http://www.uniprot.org/.},
  Journal  = {Nucleic Acids Research},
  Volume   = {45},
  Number   = {D1},
  Pages    = {D158--D169},
  Month    = {01},
  Year     = {2017},
  Language = {en},
  Issn     = {0305-1048, 1362-4962},
  Pmid     = {27899622},
  Doi      = {10.1093/nar/gkw1099},
  Pmc      = {PMC5210571}
}

@article{Stanke2004,
  Title       = {{AUGUSTUS}: a web server for gene finding in eukaryotes},
  Author      = {Stanke, Mario and Steinkamp, Rasmus and Waack, Stephan and
                 Morgenstern, Burkhard},
  Abstract    = {We present a www server for AUGUSTUS, a novel software program
                 for ab initio gene prediction in eukaryotic genomic sequences.
                 Our method is based on a generalized Hidden Markov Model with
                 a new method for modeling the intron length distribution. This
                 method allows approximation of the true intron length
                 distribution more accurately than do existing programs. For
                 genomic sequence data from human and Drosophila melanogaster,
                 the accuracy of AUGUSTUS is superior to existing gene-finding
                 approaches. The advantage of our program becomes apparent
                 especially for larger input sequences containing more than one
                 gene. The server is available at http://augustus.gobics.de.},
  Journal     = {Nucleic Acids Research},
  Volume      = {32},
  Number      = {Web Server issue},
  Pages       = {W309--12},
  Month       = {07},
  Year        = {2004},
  Language    = {en},
  Issn        = {0305-1048, 1362-4962},
  Pmid        = {15215400},
  Doi         = {10.1093/nar/gkh379},
  Pmc         = {PMC441517}
}

@article{pseudogenesOrg,
  Title       = {Pseudogene.org: a comprehensive database and comparison
                 platform for pseudogene annotation},
  Author      = {Karro, John E and Yan, Yangpan and Zheng, Deyou and Zhang,
                 Zhaolei and Carriero, Nicholas and Cayting, Philip and
                 Harrrison, Paul and Gerstein, Mark},
  Abstract    = {The Pseudogene.org knowledgebase serves as a comprehensive
                 repository for pseudogene annotation. The definition of a
                 pseudogene varies within the literature, resulting in
                 significantly different approaches to the problem of
                 identification. Consequently, it is difficult to maintain a
                 consistent collection of pseudogenes in detail necessary for
                 their effective use. Our database is designed to address this
                 issue. It integrates a variety of heterogeneous resources and
                 supports a subset structure that highlights specific groups of
                 pseudogenes that are of interest to the research community.
                 Tools are provided for the comparison of sets and the creation
                 of layered set unions, enabling researchers to derive a
                 current 'consensus' set of pseudogenes. Additional features
                 include versatile search, the capacity for robust interaction
                 with other databases, the ability to reconstruct older
                 versions of the database (accounting for changing genome
                 builds) and an underlying object-oriented interface designed
                 for researchers with a minimal knowledge of programming. At
                 the present time, the database contains more than 100,000
                 pseudogenes spanning 64 prokaryote and 11 eukaryote genomes,
                 including a collection of human annotations compiled from 16
                 sources.},
  Journal     = {Nucleic Acids Research},
  Volume      = {35},
  Number      = {Database issue},
  Pages       = {D55--60},
  Month       = {01},
  Year        = {2007},
  Language    = {en},
  Issn        = {0305-1048, 1362-4962},
  Pmid        = {17099229},
  Doi         = {10.1093/nar/gkl851},
  Pmc         = {PMC1669708}
}

@article{scripture,
  Title       = {Ab initio reconstruction of cell type-specific transcriptomes
                 in mouse reveals the conserved multi-exonic structure of
                 {lincRNAs}},
  Author      = {Guttman, Mitchell and Garber, Manuel and Levin, Joshua Z and
                 Donaghey, Julie and Robinson, James and Adiconis, Xian and
                 Fan, Lin and Koziol, Magdalena J and Gnirke, Andreas and
                 Nusbaum, Chad and Rinn, John L and Lander, Eric S and Regev,
                 Aviv},
  Abstract    = {Massively parallel cDNA sequencing (RNA-Seq) provides an
                 unbiased way to study a transcriptome, including both coding
                 and noncoding genes. Until now, most RNA-Seq studies have
                 depended crucially on existing annotations and thus focused on
                 expression levels and variation in known transcripts. Here, we
                 present Scripture, a method to reconstruct the transcriptome
                 of a mammalian cell using only RNA-Seq reads and the genome
                 sequence. We applied it to mouse embryonic stem cells,
                 neuronal precursor cells and lung fibroblasts to accurately
                 reconstruct the full-length gene structures for most known
                 expressed genes. We identified substantial variation in
                 protein coding genes, including thousands of novel 5' start
                 sites, 3' ends and internal coding exons. We then determined
                 the gene structures of more than a thousand large intergenic
                 noncoding RNA (lincRNA) and antisense loci. Our results open
                 the way to direct experimental manipulation of thousands of
                 noncoding RNAs and demonstrate the power of ab initio
                 reconstruction to render a comprehensive picture of mammalian
                 transcriptomes.},
  Journal     = {Nature Biotechnology},
  Volume      = {28},
  Number      = {5},
  Pages       = {503--510},
  Month       = {05},
  Year        = {2010},
  Language    = {en},
  Issn        = {1087-0156, 1546-1696},
  Pmid        = {20436462},
  Doi         = {10.1038/nbt.1633},
  Pmc         = {PMC2868100}
}


@article{Arike2012,
  Title       = {Comparison and applications of label-free absolute proteome
                 quantification methods on Escherichia coli},
  Author      = {Arike, L and Valgepea, K and Peil, L and Nahku, R and
                 Adamberg, K and Vilu, R},
  Abstract    = {Three different label-free proteome quantification
                 methods--APEX, emPAI and iBAQ--were evaluated to measure
                 proteome-wide protein concentrations in the cell. All the
                 methods were applied to a sample from Escherichia coli
                 chemostat culture. A Pearson squared correlation of
                 approximately 0.6 among the three quantification methods was
                 demonstrated. Importantly, the sum of quantified proteins by
                 iBAQ and emPAI corresponded with the Lowry total protein
                 quantification, demonstrating applicability of label-free
                 methods for an accurate calculation of protein concentrations
                 at the proteome level. The iBAQ method showed the best
                 correlation between biological replicates, a normal
                 distribution among all protein abundances, and the lowest
                 variation among ribosomal protein abundances, which are
                 expected to have equal amounts. Absolute quantitative proteome
                 data enabled us to evaluate metabolic cost for protein
                 synthesis and apparent catalytic activities of enzymes by
                 integration with flux analysis. All the methods demonstrated
                 similar ATP costs for protein synthesis for different cellular
                 processes and that costs for expressing biomass synthesis
                 related proteins were higher than those for energy generation.
                 Importantly, catalytic activities of energy metabolism enzymes
                 were an order or two higher than those of monomer synthesis.
                 Interestingly, a staircase-like protein expression was
                 demonstrated for most of the transcription units.},
  Journal     = {Journal of Proteomics},
  Volume      = {75},
  Number      = {17},
  Pages       = {5437--5448},
  Month       = {09},
  Year        = {2012},
  Language    = {en},
  Issn        = {1874-3919, 1876-7737},
  Pmid        = {22771841},
  Doi         = {10.1016/j.jprot.2012.06.020}
}



@article{apex-tool,
  Title       = {The {APEX} Quantitative Proteomics Tool: generating protein
                 quantitation estimates from {LC-MS/MS} proteomics results},
  Author      = {Braisted, John C and Kuntumalla, Srilatha and Vogel, Christine
                 and Marcotte, Edward M and Rodrigues, Alan R and Wang, Rong
                 and Huang, Shih-Ting and Ferlanti, Erik S and Saeed, Alexander
                 I and Fleischmann, Robert D and Peterson, Scott N and Pieper,
                 Rembert},
  Abstract    = {BACKGROUND: Mass spectrometry (MS) based label-free protein
                 quantitation has mainly focused on analysis of ion peak
                 heights and peptide spectral counts. Most analyses of tandem
                 mass spectrometry (MS/MS) data begin with an enzymatic
                 digestion of a complex protein mixture to generate smaller
                 peptides that can be separated and identified by an MS/MS
                 instrument. Peptide spectral counting techniques attempt to
                 quantify protein abundance by counting the number of detected
                 tryptic peptides and their corresponding MS spectra. However,
                 spectral counting is confounded by the fact that peptide
                 physicochemical properties severely affect MS detection
                 resulting in each peptide having a different detection
                 probability. Lu et al. (2007) described a modified spectral
                 counting technique, Absolute Protein Expression (APEX), which
                 improves on basic spectral counting methods by including a
                 correction factor for each protein (called Oi value) that
                 accounts for variable peptide detection by MS techniques. The
                 technique uses machine learning classification to derive
                 peptide detection probabilities that are used to predict the
                 number of tryptic peptides expected to be detected for one
                 molecule of a particular protein (Oi). This predicted spectral
                 count is compared to the protein's observed MS total spectral
                 count during APEX computation of protein abundances. RESULTS:
                 The APEX Quantitative Proteomics Tool, introduced here, is a
                 free open source Java application that supports the APEX
                 protein quantitation technique. The APEX tool uses data from
                 standard tandem mass spectrometry proteomics experiments and
                 provides computational support for APEX protein abundance
                 quantitation through a set of graphical user interfaces that
                 partition th parameter controls for the various processing
                 tasks. The tool also provides a Z-score analysis for
                 identification of significant differential protein expression,
                 a utility to assess APEX classifier performance via cross
                 validation, and a utility to merge multiple APEX results into
                 a standardized format in preparation for further statistical
                 analysis. CONCLUSION: The APEX Quantitative Proteomics Tool
                 provides a simple means to quickly derive hundreds to
                 thousands of protein abundance values from standard liquid
                 chromatography-tandem mass spectrometry proteomics datasets.
                 The APEX tool provides a straightforward intuitive interface
                 design overlaying a highly customizable computational workflow
                 to produce protein abundance values from LC-MS/MS datasets.},
  Journal     = {BMC Bioinformatics},
  Volume      = {9},
  Pages       = {529},
  Month       = {12},
  Year        = {2008},
  Language    = {en},
  Issn        = {1471-2105},
  Pmid        = {19068132},
  Doi         = {10.1186/1471-2105-9-529},
  Pmc         = {PMC2639435}
}

@article{emPAI-tool,
  Title       = {Exponentially modified protein abundance index ({emPAI}) for
                 estimation of absolute protein amount in proteomics by the
                 number of sequenced peptides per protein},
  Author      = {Ishihama, Yasushi and Oda, Yoshiya and Tabata, Tsuyoshi and
                 Sato, Toshitaka and Nagasu, Takeshi and Rappsilber, Juri and
                 Mann, Matthias},
  Abstract    = {To estimate absolute protein contents in complex mixtures, we
                 previously defined a protein abundance index (PAI) as the
                 number of observed peptides divided by the number of
                 observable peptides per protein (Rappsilber, J., Ryder, U.,
                 Lamond, A. I., and Mann, M. (2002) Large-scale proteomic
                 analysis of the human spliceosome. Genome. Res. 12,
                 1231-1245). Here we report that PAI values obtained at
                 different concentrations of serum albumin show a linear
                 relationship with the logarithm of protein concentration in
                 LC-MS/MS experiments. This was also the case for 46 proteins
                 in a mouse whole cell lysate. For absolute quantitation, PAI
                 was converted to exponentially modified PAI (emPAI), equal to
                 10PAI minus one, which is proportional to protein content in a
                 protein mixture. For the 46 proteins in the whole lysate, the
                 deviation percentages of the emPAI-based abundances from the
                 actual values were within 63\% on average, similar or better
                 than determination of abundance by protein staining. emPAI was
                 applied to comprehensive protein expression analysis and to a
                 comparison study between gene and protein expression in a
                 human cancer cell line, HCT116. The values of emPAI are easily
                 calculated and add important quantitation information to
                 proteomic experiments; therefore we suggest that they should
                 be reported in large scale proteomic identification projects.},
  Journal     = {Molecular \& Cellular Proteomics},
  Volume      =  4,
  Number      =  9,
  Pages       = {1265--1272},
  Month       = {09},
  Year        =  2005,
  Language    = {en},
  Issn        = {1535-9476},
  Pmid        = {15958392},
  Doi         = {10.1074/mcp.M500061-MCP200}
}


@article{TOP3isbetter,
  Title       = {Critical assessment of proteome-wide label-free absolute
                 abundance estimation strategies},
  Author      = {Ahrné, Erik and Molzahn, Lars and Glatter, Timo and Schmidt,
                 Alexander},
  Affiliation = {Proteomics Core Facility, Biozentrum, University of Basel,
                 Basel, Switzerland.},
  Abstract    = {There is a great interest in reliable ways to obtain absolute
                 protein abundances at a proteome-wide scale. To this end,
                 label-free LC-MS/MS quantification methods have been proposed
                 where all identified proteins are assigned an estimated
                 abundance. Several variants of this quantification approach
                 have been presented, based on either the number of spectral
                 counts per protein or MS1 peak intensities. Equipped with
                 several datasets representing real biological environments,
                 containing a high number of accurately quantified reference
                 proteins, we evaluate five popular low-cost and easily
                 implemented quantification methods (Absolute Protein
                 Expression, Exponentially Modified Protein Abundance Index,
                 Intensity-Based Absolute Quantification Index, Top3, and
                 MeanInt). Our results demonstrate considerably improved
                 abundance estimates upon implementing accurately quantified
                 reference proteins; that is, using spiked in stable isotope
                 labeled standard peptides or a standard protein mix, to
                 generate a properly calibrated quantification model. We show
                 that only the Top3 method is directly proportional to protein
                 abundance over the full quantification range and is the
                 preferred method in the absence of reference protein
                 measurements. Additionally, we demonstrate that spectral count
                 based quantification methods are associated with higher errors
                 than MS1 peak intensity based methods. Furthermore, we
                 investigate the impact of miscleaved, modified, and shared
                 peptides as well as protein size and the number of employed
                 reference proteins on quantification accuracy.},
  Journal     = {Proteomics},
  Volume      = {13},
  Number      = {17},
  Pages       = {2567--2578},
  Month       = {09},
  Year        = 2013,
  Keywords    = {APEX; Absolute protein quantification; Bioinformatics; MS;
                 Top3; emPAI; iBAQ},
  Language    = {en},
  Issn        = {1615-9853, 1615-9861},
  Pmid        = {23794183},
  Doi         = {10.1002/pmic.201300135}
}


@article{Silva-Top3,
  Title       = {Absolute quantification of proteins by {LCMSE}: a virtue of
                 parallel {MS} acquisition},
  Author      = {Silva, Jeffrey C and Gorenstein, Marc V and Li, Guo-Zhong and
                 Vissers, Johannes P C and Geromanos, Scott J},
  Affiliation = {Waters Corporation, Milford, Massachusetts 01757-3696, USA.
                 jeff\_silva@waters.com},
  Abstract    = {Relative quantification methods have dominated the
                 quantitative proteomics field. There is a need, however, to
                 conduct absolute quantification studies to accurately model
                 and understand the complex molecular biology that results in
                 proteome variability among biological samples. A new method of
                 absolute quantification of proteins is described. This method
                 is based on the discovery of an unexpected relationship
                 between MS signal response and protein concentration: the
                 average MS signal response for the three most intense tryptic
                 peptides per mole of protein is constant within a coefficient
                 of variation of less than +/-10\%. Given an internal standard,
                 this relationship is used to calculate a universal signal
                 response factor. The universal signal response factor
                 (counts/mol) was shown to be the same for all proteins tested
                 in this study. A controlled set of six exogenous proteins of
                 varying concentrations was studied in the absence and presence
                 of human serum. The absolute quantity of the standard proteins
                 was determined with a relative error of less than +/-15\%. The
                 average MS signal responses of the three most intense peptides
                 from each protein were plotted against their calculated
                 protein concentrations, and this plot resulted in a linear
                 relationship with an R(2) value of 0.9939. The analyses were
                 applied to determine the absolute concentration of 11 common
                 serum proteins, and these concentrations were then compared
                 with known values available in the literature. Additionally
                 within an unfractionated Escherichia coli lysate, a subset of
                 identified proteins known to exist as functional complexes was
                 studied. The calculated absolute quantities were used to
                 accurately determine their stoichiometry.},
  Journal     = {Molecular \& Cellular Proteomics},
  Volume      = {5},
  Number      = {1},
  Pages       = {144--156},
  Month       =  {01},
  Year        = {2006},
  Language    = {en},
  Issn        = {1535-9476},
  Pmid        = {16219938},
  Doi         = {10.1074/mcp.M500230-MCP200}
}

@article{ProteomeWizard,
  Title       = {Employing {ProteoWizard} to Convert Raw Mass Spectrometry Data},
  Author      = {Holman, Jerry D and Tabb, David L and Mallick, Parag},
  Abstract    = {After raw data have been captured by mass spectrometers in
                 biological LC-MS/MS experiments, they must be converted from
                 vendor-specific binary files to open-format files for
                 manipulation by most software. This protocol details the use
                 of ProteoWizard software for this conversion, taking format
                 features, coding options, and vendor particularities into
                 account. This protocol will aid researchers in preparing their
                 data for analysis by database search engines and other
                 bioinformatics tools.},
  Journal     = {Current Protocols in Bioinformatics},
  Volume      = {46},
  Number      = {13.24},
  Pages       = {1--9},
  Month       = {06},
  Year        = {2014},
  Keywords    = {LC-MS/MS; database search; mzML; proteomics; raw files},
  Language    = {en},
  Issn        = {1934-3396, 1934-340X},
  Pmid        = {24939128},
  Doi         = {10.1002/0471250953.bi1324s46},
  Pmc         = {PMC4113728}
}

@article{Topp,
  Title       = {{TOPP--the} {OpenMS} proteomics pipeline},
  Author      = {Kohlbacher, Oliver and Reinert, Knut and Gröpl, Clemens and
                 Lange, Eva and Pfeifer, Nico and Schulz-Trieglaff, Ole and
                 Sturm, Marc},
  Abstract    = {MOTIVATION: Experimental techniques in proteomics have seen
                 rapid development over the last few years. Volume and
                 complexity of the data have both been growing at a similar
                 rate. Accordingly, data management and analysis are one of the
                 major challenges in proteomics. Flexible algorithms are
                 required to handle changing experimental setups and to assist
                 in developing and validating new methods. In order to
                 facilitate these studies, it would be desirable to have a
                 flexible 'toolbox' of versatile and user-friendly applications
                 allowing for rapid construction of computational workflows in
                 proteomics. RESULTS: We describe a set of tools for proteomics
                 data analysis-TOPP, The OpenMS Proteomics Pipeline. TOPP
                 provides a set of computational tools which can be easily
                 combined into analysis pipelines even by non-experts and can
                 be used in proteomics workflows. These applications range from
                 useful utilities (file format conversion, peak picking) over
                 wrapper applications for known applications (e.g. Mascot) to
                 completely new algorithmic techniques for data reduction and
                 data analysis. We anticipate that TOPP will greatly facilitate
                 rapid prototyping of proteomics data evaluation pipelines. As
                 such, we describe the basic concepts and the current abilities
                 of TOPP and illustrate these concepts in the context of two
                 example applications: the identification of peptides from a
                 raw dataset through database search and the complex analysis
                 of a standard addition experiment for the absolute
                 quantitation of biomarkers. The latter example demonstrates
                 TOPP's ability to construct flexible analysis pipelines in
                 support of complex experimental setups. AVAILABILITY: The TOPP
                 components are available as open-source software under the
                 lesser GNU public license (LGPL). Source code is available
                 from the project website at www.OpenMS.de},
  Journal     = {Bioinformatics},
  Volume      = {23},
  Number      = {2},
  pages       = {e191--7},
  month       = {01},
  year        = {2007},
  language    = {en},
  issn        = {1367-4803, 1367-4811},
  pmid        = {17237091},
  doi         = {10.1093/bioinformatics/btl299}
}

@article{openMS2016,
  Title       = {{OpenMS}: a flexible open-source software platform for mass
                 spectrometry data analysis},
  Author      = {Röst, Hannes L and Sachsenberg, Timo and Aiche, Stephan and
                 Bielow, Chris and Weisser, Hendrik and Aicheler, Fabian and
                 Andreotti, Sandro and Ehrlich, Hans-Christian and
                 Gutenbrunner, Petra and Kenar, Erhan and Liang, Xiao and
                 Nahnsen, Sven and Nilse, Lars and Pfeuffer, Julianus and
                 Rosenberger, George and Rurik, Marc and Schmitt, Uwe and Veit,
                 Johannes and Walzer, Mathias and Wojnar, David and Wolski,
                 Witold E and Schilling, Oliver and Choudhary, Jyoti S and
                 Malmström, Lars and Aebersold, Ruedi and Reinert, Knut and
                 Kohlbacher, Oliver},
  Abstract    = {High-resolution mass spectrometry (MS) has become an important
                 tool in the life sciences, contributing to the diagnosis and
                 understanding of human diseases, elucidating biomolecular
                 structural information and characterizing cellular signaling
                 networks. However, the rapid growth in the volume and
                 complexity of MS data makes transparent, accurate and
                 reproducible analysis difficult. We present OpenMS 2.0
                 (http://www.openms.de), a robust, open-source, cross-platform
                 software specifically designed for the flexible and
                 reproducible analysis of high-throughput MS data. The
                 extensible OpenMS software implements common mass
                 spectrometric data processing tasks through a well-defined
                 application programming interface in C++ and Python and
                 through standardized open data formats. OpenMS additionally
                 provides a set of 185 tools and ready-made workflows for
                 common mass spectrometric data processing tasks, which enable
                 users to perform complex quantitative mass spectrometric
                 analyses with ease.},
  Journal     = {Nature Methods},
  Volume      = {13},
  Number      = {9},
  Pages       = {741--748},
  Month       = {08},
  Year        = {2016},
  Language    = {en},
  Issn        = {1548-7091, 1548-7105},
  pmid        = {27575624},
  Doi         = {10.1038/nmeth.3959}
}


@article{Kim2014-nj,
  Title       = {{MS-GF+} makes progress towards a universal database search
                 tool for proteomics},
  Author      = {Kim, Sangtae and Pevzner, Pavel A},
  Abstract    = {Mass spectrometry (MS) instruments and experimental protocols
                 are rapidly advancing, but the software tools to analyse
                 tandem mass spectra are lagging behind. We present a database
                 search tool MS-GF+ that is sensitive (it identifies more
                 peptides than most other database search tools) and universal
                 (it works well for diverse types of spectra, different
                 configurations of MS instruments and different experimental
                 protocols). We benchmark MS-GF+ using diverse spectral data
                 sets: (i) spectra of varying fragmentation methods; (ii)
                 spectra of multiple enzyme digests; (iii) spectra of
                 phosphorylated peptides; and (iv) spectra of peptides with
                 unusual fragmentation propensities produced by a novel
                 alpha-lytic protease. For all these data sets, MS-GF+
                 significantly increases the number of identified peptides
                 compared with commonly used methods for peptide
                 identifications. We emphasize that although MS-GF+ is not
                 specifically designed for any particular experimental set-up,
                 it improves on the performance of tools specifically designed
                 for these applications (for example, specialized tools for
                 phosphoproteomics).},
  Journal     = {Nature Communications},
  Volume      = {5},
  Pages       = {5277},
  Month       = {10},
  Year        = {2014},
  Language    = {en},
  Issn        = {2041-1723},
  Pmid        = {25358478},
  Doi         = {10.1038/ncomms6277},
  Pmc         = {PMC5036525}
}


@article{Brosch2009-xq,
  Title       = {Accurate and sensitive peptide identification with Mascot
                 Percolator},
  Author      = {Brosch, Markus and Yu, Lu and Hubbard, Tim and Choudhary,
                 Jyoti},
  Abstract    = {Sound scoring methods for sequence database search algorithms
                 such as Mascot and Sequest are essential for sensitive and
                 accurate peptide and protein identifications from proteomic
                 tandem mass spectrometry data. In this paper, we present a
                 software package that interfaces Mascot with Percolator, a
                 well performing machine learning method for rescoring database
                 search results, and demonstrate it to be amenable for both low
                 and high accuracy mass spectrometry data, outperforming all
                 available Mascot scoring schemes as well as providing reliable
                 significance measures. Mascot Percolator can be readily used
                 as a stand alone tool or integrated into existing data
                 analysis pipelines.},
  Journal     = {Journal of Proteome Research},
  Volume      = {8},
  Number      = {6},
  Pages       = {3176--3181},
  Month       = {06},
  Year        = {2009},
  Language    = {en},
  Issn        = {1535-3893},
  Pmid        = {19338334},
  Doi         = {10.1021/pr800982s},
  Pmc         = {PMC2734080}
}



@article{Wright2012-od,
  Title       = {Enhanced peptide identification by electron transfer
                 dissociation using an improved Mascot Percolator},
  Author      = {Wright, James C and Collins, Mark O and Yu, Lu and Käll, Lukas
                 and Brosch, Markus and Choudhary, Jyoti S},
  Abstract    = {Peptide identification using tandem mass spectrometry is a
                 core technology in proteomics. Latest generations of mass
                 spectrometry instruments enable the use of electron transfer
                 dissociation (ETD) to complement collision induced
                 dissociation (CID) for peptide fragmentation. However, a
                 critical limitation to the use of ETD has been optimal
                 database search software. Percolator is a post-search
                 algorithm, which uses semi-supervised machine learning to
                 improve the rate of peptide spectrum identifications (PSMs)
                 together with providing reliable significance measures. We
                 have previously interfaced the Mascot search engine with
                 Percolator and demonstrated sensitivity and specificity
                 benefits with CID data. Here, we report recent developments in
                 the Mascot Percolator V2.0 software including an improved
                 feature calculator and support for a wider range of ion
                 series. The updated software is applied to the analysis of
                 several CID and ETD fragmented peptide data sets. This version
                 of Mascot Percolator increases the number of CID PSMs by up to
                 80\% and ETD PSMs by up to 60\% at a 0.01 q-value (1\% false
                 discovery rate) threshold over a standard Mascot search,
                 notably recovering PSMs from high charge state precursor ions.
                 The greatly increased number of PSMs and peptide coverage
                 afforded by Mascot Percolator has enabled a fuller assessment
                 of CID/ETD complementarity to be performed. Using a data set
                 of CID and ETcaD spectral pairs, we find that at a 1\% false
                 discovery rate, the overlap in peptide identifications by CID
                 and ETD is 83\%, which is significantly higher than that
                 obtained using either stand-alone Mascot (69\%) or OMSSA
                 (39\%). We conclude that Mascot Percolator is a highly
                 sensitive and accurate post-search algorithm for peptide
                 identification and allows direct comparison of peptide
                 identifications using multiple alternative fragmentation
                 techniques.},
  Journal     = {Molecular \& Cellular Proteomics},
  Volume      = {11},
  Number      = {8},
  Pages       = {478--491},
  Month       = {08},
  Year        = {2012},
  Language    = {en},
  Issn        = {1535-9476, 1535-9484},
  Pmid        = {22493177},
  Doi         = {10.1074/mcp.O111.014522},
  Pmc         = {PMC3412976}
}

@article{Granholm2014-cw,
  Title       = {Fast and accurate database searches with {MS-GF+Percolator}},
  Author      = {Granholm, Viktor and Kim, Sangtae and Navarro, José C F and
                 Sjölund, Erik and Smith, Richard D and Käll, Lukas},
  Abstract    = {One can interpret fragmentation spectra stemming from peptides
                 in mass-spectrometry-based proteomics experiments using
                 so-called database search engines. Frequently, one also runs
                 post-processors such as Percolator to assess the confidence,
                 infer unique peptides, and increase the number of
                 identifications. A recent search engine, MS-GF+, has shown
                 promising results, due to a new and efficient scoring
                 algorithm. However, MS-GF+ provides few statistical estimates
                 about the peptide-spectrum matches, hence limiting the
                 biological interpretation. Here, we enabled Percolator
                 processing for MS-GF+ output and observed an increased number
                 of identified peptides for a wide variety of data sets. In
                 addition, Percolator directly reports p values and false
                 discovery rate estimates, such as q values and posterior error
                 probabilities, for peptide-spectrum matches, peptides, and
                 proteins, functions that are useful for the whole proteomics
                 community.},
  Journal     = {Journal of Proteome Research},
  Volume      = {13},
  Number      = {2},
  Pages       = {890--897},
  Month       = {02},
  Year        = {2014},
  Language    = {en},
  Issn        = {1535-3893, 1535-3907},
  Pmid        = {24344789},
  Doi         = {10.1021/pr400937n},
  Pmc         = {PMC3975676}
}

@article{Eng1994-eq,
  Title       = {An approach to correlate tandem mass spectral data of peptides
                 with amino acid sequences in a protein database},
  Author      = {Eng, J K and McCormack, A L and Yates, J R},
  Abstract    = {A method to correlate the uninterpreted tandem mass spectra of
                 peptides produced under low energy (10-50 eV) collision
                 conditions with amino acid sequences in the Genpept database
                 has been developed. In this method the protein database is
                 searched to identify linear amino acid sequences within a mass
                 tolerance of ±1 u of the precursor ion molecular weight A
                 cross-correlation function is then used to provide a
                 measurement of similarity between the mass-to-charge ratios
                 for the fragment ions predicted from amino acid sequences
                 obtained from the database and the fragment ions observed in
                 the tandem mass spectrum. In general, a difference greater
                 than 0.1 between the normalized cross-correlation functions of
                 the first- and second-ranked search results indicates a
                 successful match between sequence and spectrum. Searches of
                 species-specific protein databases with tandem mass spectra
                 acquired from peptides obtained from the enzymatically
                 digested total proteins of E. coli and S. cerevisiae cells
                 allowed matching of the spectra to amino acid sequences within
                 proteins of these organisms. The approach described in this
                 manuscript provides a convenient method to interpret tandem
                 mass spectra with known sequences in a protein database.},
  Journal     = {Journal of the American Society for Mass Spectrometry},
  Volume      = {5},
  Number      = {11},
  Pages       = {976--989},
  Month       = {11},
  Year        = {1994},
  Language    = {en},
  Issn        = {1044-0305},
  Pmid        = {24226387},
  Doi         = {10.1016/1044-0305(94)80016-2}
}

@article{Spivak2009-zd,
  Title       = {Improvements to the percolator algorithm for Peptide
                 identification from shotgun proteomics data sets},
  Author      = {Spivak, Marina and Weston, Jason and Bottou, Léon and Käll,
                 Lukas and Noble, William Stafford},
  Abstract    = {Shotgun proteomics coupled with database search software
                 allows the identification of a large number of peptides in a
                 single experiment. However, some existing search algorithms,
                 such as SEQUEST, use score functions that are designed
                 primarily to identify the best peptide for a given spectrum.
                 Consequently, when comparing identifications across spectra,
                 the SEQUEST score function Xcorr fails to discriminate
                 accurately between correct and incorrect peptide
                 identifications. Several machine learning methods have been
                 proposed to address the resulting classification task of
                 distinguishing between correct and incorrect peptide-spectrum
                 matches (PSMs). A recent example is Percolator, which uses
                 semisupervised learning and a decoy database search strategy
                 to learn to distinguish between correct and incorrect PSMs
                 identified by a database search algorithm. The current work
                 describes three improvements to Percolator. (1) Percolator's
                 heuristic optimization is replaced with a clear objective
                 function, with intuitive reasons behind its choice. (2)
                 Tractable nonlinear models are used instead of linear models,
                 leading to improved accuracy over the original Percolator. (3)
                 A method, Q-ranker, for directly optimizing the number of
                 identified spectra at a specified q value is proposed, which
                 achieves further gains.},
  Journal     = {Journal of Proteome Research},
  Volume      = {8},
  Number      = {7},
  Pages       = {3737--3745},
  Month       = {07},
  Year        = {2009},
  Language    = {en},
  Issn        = {1535-3893},
  Pmid        = {19385687},
  Doi         = {10.1021/pr801109k},
  Pmc         = {PMC2710313}
}

@article{Jaskowiak2014,
  Title    = {On the selection of appropriate distances for gene expression
              data clustering},
  Author   = {Jaskowiak, Pablo A and Campello, Ricardo J G B and Costa, Ivan G},
  Abstract = {BACKGROUND: Clustering is crucial for gene expression data
              analysis. As an unsupervised exploratory procedure its results
              can help researchers to gain insights and formulate new
              hypothesis about biological data from microarrays. Given
              different settings of microarray experiments, clustering proves
              itself as a versatile exploratory tool. It can help to unveil new
              cancer subtypes or to identify groups of genes that respond
              similarly to a specific experimental condition. In order to
              obtain useful clustering results, however, different parameters
              of the clustering procedure must be properly tuned. Besides the
              selection of the clustering method itself, determining which
              distance is going to be employed between data objects is probably
              one of the most difficult decisions. RESULTS AND CONCLUSIONS: We
              analyze how different distances and clustering methods interact
              regarding their ability to cluster gene expression, i.e.,
              microarray data. We study 15 distances along with four common
              clustering methods from the literature on a total of 52 gene
              expression microarray datasets. Distances are evaluated on a
              number of different scenarios including clustering of cancer
              tissues and genes from short time-series expression data, the two
              main clustering applications in gene expression. Our results
              support that the selection of an appropriate distance depends on
              the scenario in hand. Moreover, in each scenario, given the very
              same clustering method, significant differences in quality may
              arise from the selection of distinct distance measures. In fact,
              the selection of an appropriate distance measure can make the
              difference between meaningful and poor clustering outcomes, even
              for a suitable clustering method.},
  Journal  = {BMC Bioinformatics},
  Volume   = {15 Suppl. 2},
  Pages    = {S2},
  Month    = {01},
  Year     = {2014},
  Language = {en},
  Issn     = {1471-2105},
  Pmid     = {24564555},
  Doi      = {10.1186/1471-2105-15-S2-S2},
  Pmc      = {PMC4072854}
}

@article{Ward1963,
  Title     = {Hierarchical Grouping to Optimize an Objective Function},
  Author    = {Ward, Joe H},
  Abstract  = {A procedure for forming hierarchical groups of mutually
               exclusive subsets, each of which has members that are maximally
               similar with respect to specified characteristics, is suggested
               for use in large-scale ($n > 100$) studies when a precise
               optimal solution for a specified number of groups is not
               practical. Given n sets, this procedure permits their reduction
               to n - 1 mutually exclusive sets by considering the union of all
               possible n(n - 1)/2 pairs and selecting a union having a maximal
               value for the functional relation, or objective function, that
               reflects the criterion chosen by the investigator. By repeating
               this process until only one group remains, the complete
               hierarchical structure and a quantitative estimate of the loss
               associated with each stage in the grouping can be obtained. A
               general flowchart helpful in computer programming and a
               numerical example are included.},
  Journal   = {Journal of the American Statistical Association},
  Volume    = {58},
  Number    = {301},
  Pages     = {236--244},
  Year      = {1963},
  Issn      = {0162-1459},
  Doi       = {10.2307/2282967}
}

@article{Ilicic2016,
  Title       = {Classification of low quality cells from single-cell {RNA-seq}
                 data},
  Author      = {Ilicic, Tomislav and Kim, Jong Kyoung and Kolodziejczyk,
                 Aleksandra A and Bagger, Frederik Otzen and McCarthy, Davis
                 James and Marioni, John C and Teichmann, Sarah A},
  Abstract    = {Single-cell RNA sequencing (scRNA-seq) has broad applications
                 across biomedical research. One of the key challenges is to
                 ensure that only single, live cells are included in downstream
                 analysis, as the inclusion of compromised cells inevitably
                 affects data interpretation. Here, we present a generic
                 approach for processing scRNA-seq data and detecting low
                 quality cells, using a curated set of over 20 biological and
                 technical features. Our approach improves classification
                 accuracy by over 30 \% compared to traditional methods when
                 tested on over 5,000 cells, including CD4+ T cells, bone
                 marrow dendritic cells, and mouse embryonic stem cells.},
  Journal     = {Genome Biology},
  Volume      = {17},
  Pages       = {29},
  Month       = {02},
  Year        = {2016},
  Language    = {en},
  Issn        = {1465-6906},
  Pmid        = {26887813},
  Doi         = {10.1186/s13059-016-0888-1},
  Pmc         = {PMC4758103}
}

@incollection{Dasu2003-bg,
  Title     = {Data quality},
  Booktitle = {Exploratory Data Mining and Data Cleaning},
  Author    = {Dasu, Tamraparni and Johnson, Theodore},
  Publisher = {Wiley},
  Series    = {Wiley Series in Probability and Statistics},
  Month     = {05},
  Year      = {2003},
  Address   = {Hoboken, NJ},
  Doi       = {10.1002/0471448354}
}

@article{Kratz2014,
  Title       = {The devil in the details of {RNA-seq}},
  Author      = {Kratz, Anton and Carninci, Piero},
  Journal     = {Nature Biotechnology},
  Volume      = {32},
  Number      = {9},
  Pages       = {882--884},
  Month       = {09},
  Year        = {2014},
  Language    = {en},
  Issn        = {1087-0156, 1546-1696},
  Pmid        = {25203036},
  Doi         = {10.1038/nbt.3015}
}


@article{Freeman2012,
  Title       = {A gene expression atlas of the domestic pig},
  Author      = {Freeman, Tom C and Ivens, Alasdair and Baillie, J Kenneth and
                 Beraldi, Dario and Barnett, Mark W and Dorward, David and
                 Downing, Alison and Fairbairn, Lynsey and Kapetanovic, Ronan
                 and Raza, Sobia and Tomoiu, Andru and Alberio, Ramiro and Wu,
                 Chunlei and Su, Andrew I and Summers, Kim M and Tuggle,
                 Christopher K and Archibald, Alan L and Hume, David A},
  Abstract    = {BACKGROUND: This work describes the first genome-wide analysis
                 of the transcriptional landscape of the pig. A new porcine
                 Affymetrix expression array was designed in order to provide
                 comprehensive coverage of the known pig transcriptome. The new
                 array was used to generate a genome-wide expression atlas of
                 pig tissues derived from 62 tissue/cell types. These data were
                 subjected to network correlation analysis and clustering.
                 RESULTS: The analysis presented here provides a detailed
                 functional clustering of the pig transcriptome where
                 transcripts are grouped according to their expression pattern,
                 so one can infer the function of an uncharacterized gene from
                 the company it keeps and the locations in which it is
                 expressed. We describe the overall transcriptional signatures
                 present in the tissue atlas, where possible assigning those
                 signatures to specific cell populations or pathways. In
                 particular, we discuss the expression signatures associated
                 with the gastrointestinal tract, an organ that was sampled at
                 15 sites along its length and whose biology in the pig is
                 similar to human. We identify sets of genes that define
                 specialized cellular compartments and region-specific
                 digestive functions. Finally, we performed a network analysis
                 of the transcription factors expressed in the gastrointestinal
                 tract and demonstrate how they sub-divide into functional
                 groups that may control cellular gastrointestinal development.
                 CONCLUSIONS: As an important livestock animal with a
                 physiology that is more similar than mouse to man, we provide
                 a major new resource for understanding gene expression with
                 respect to the known physiology of mammalian tissues and
                 cells. The data and analyses are available on the websites
                 http://biogps.org and http://www.macrophages.com/pig-atlas.},
  Journal     = {BMC Biology},
  Volume      = {10},
  Pages       = {90},
  Month       = {11},
  Year        = {2012},
  Language    = {en},
  Issn        = {1741-7007},
  Pmid        = {23153189},
  Doi         = {10.1186/1741-7007-10-90},
  Pmc         = {PMC3814290}
}


@article{Jimenez-Lozano2012,
  Title       = {Integrating human and murine anatomical gene expression data
                 for improved comparisons},
  Author      = {Jiménez-Lozano, Natalia and Segura, Joan and Macías, José
                 Ramón and Vega, Juanjo and Carazo, José María},
  Abstract    = {MOTIVATION: Information concerning the gene expression pattern
                 in four dimensions (species, genes, anatomy and developmental
                 stage) is crucial for unraveling the roles of genes through
                 time. There are a variety of anatomical gene expression
                 databases, but extracting information from them can be
                 hampered by their diversity and heterogeneity. RESULTS: aGEM
                 3.1 (anatomic Gene Expression Mapping) addresses the issues of
                 diversity and heterogeneity of anatomical gene expression
                 databases by integrating six mouse gene expression resources
                 (EMAGE, GXD, GENSAT, Allen Brain Atlas data base, EUREXPRESS
                 and BioGPS) and three human gene expression databases (HUDSEN,
                 Human Protein Atlas and BioGPS). Furthermore, aGEM 3.1
                 provides new cross analysis tools to bridge these resources.
                 AVAILABILITY AND IMPLEMENTATION: aGEM 3.1 can be queried using
                 gene and anatomical structure. Output information is presented
                 in a friendly format, allowing the user to display expression
                 maps and correlation matrices for a gene or structure during
                 development. An in-depth study of a specific developmental
                 stage is also possible using heatmaps that relate gene
                 expression with anatomical components. http://agem.cnb.csic.es
                 CONTACT: natalia@cnb.csic.es SUPPLEMENTARY INFORMATION:
                 Supplementary data are available at Bioinformatics online.},
  Journal     = {Bioinformatics},
  Volume      = {28},
  Number      = {3},
  Pages       = {397--402},
  Month       = {02},
  Year        = {2012},
  Language    = {en},
  Issn        = {1367-4803, 1367-4811},
  Pmid        = {22106336},
  Doi         = {10.1093/bioinformatics/btr639}
}


@article{Clark2017-mw,
  Title       = {A high resolution atlas of gene expression in the domestic
                 sheep (Ovis aries)},
  Author      = {Clark, Emily L and Bush, Stephen J and McCulloch, Mary E B and
                 Farquhar, Iseabail L and Young, Rachel and Lefevre, Lucas and
                 Pridans, Clare and Tsang, Hiu and Wu, Chunlei and Afrasiabi,
                 Cyrus and Watson, Mick and Whitelaw, C Bruce and Freeman, Tom
                 C and Summers, Kim M and Archibald, Alan L and Hume, David A},
  Abstract    = {Sheep are a key source of meat, milk and fibre for the global
                 livestock sector, and an important biomedical model. Global
                 analysis of gene expression across multiple tissues has aided
                 genome annotation and supported functional annotation of
                 mammalian genes. We present a large-scale RNA-Seq dataset
                 representing all the major organ systems from adult sheep and
                 from several juvenile, neonatal and prenatal developmental
                 time points. The Ovis aries reference genome (Oar v3.1)
                 includes 27,504 genes (20,921 protein coding), of which 25,350
                 (19,921 protein coding) had detectable expression in at least
                 one tissue in the sheep gene expression atlas dataset.
                 Network-based cluster analysis of this dataset grouped genes
                 according to their expression pattern. The principle of 'guilt
                 by association' was used to infer the function of
                 uncharacterised genes from their co-expression with genes of
                 known function. We describe the overall transcriptional
                 signatures present in the sheep gene expression atlas and
                 assign those signatures, where possible, to specific cell
                 populations or pathways. The findings are related to innate
                 immunity by focusing on clusters with an immune signature, and
                 to the advantages of cross-breeding by examining the patterns
                 of genes exhibiting the greatest expression differences
                 between purebred and crossbred animals. This high-resolution
                 gene expression atlas for sheep is, to our knowledge, the
                 largest transcriptomic dataset from any livestock species to
                 date. It provides a resource to improve the annotation of the
                 current reference genome for sheep, presenting a model
                 transcriptome for ruminants and insight into gene, cell and
                 tissue function at multiple developmental stages.},
  Journal     = {PLoS Genetics},
  Volume      = {13},
  Number      = {9},
  Pages       = {e1006997},
  Month       = {09},
  Year        = {2017},
  Language    = {en},
  Issn        = {1553-7390, 1553-7404},
  Pmid        = {28915238},
  Doi         = {10.1371/journal.pgen.1006997}
}


@article{Ringwald2012,
  Title       = {{BioGPS} and {GXD}: mouse gene expression data-the benefits
                 and challenges of data integration},
  Author      = {Ringwald, Martin and Wu, Chunlei and Su, Andrew I},
  Abstract    = {Mouse gene expression data are complex and voluminous. To
                 maximize the utility of these data, they must be made readily
                 accessible through databases, and those resources need to
                 place the expression data in the larger biological context.
                 Here we describe two community resources that approach these
                 problems in different but complementary ways: BioGPS and the
                 Mouse Gene Expression Database (GXD). BioGPS connects its
                 large and homogeneous microarray gene expression reference
                 data sets via plugins with a heterogeneous collection of
                 external gene centric resources, thus casting a wide but loose
                 net. GXD acquires different types of expression data from many
                 sources and integrates these data tightly with other types of
                 data in the Mouse Genome Informatics (MGI) resource, with a
                 strong emphasis on consistency checks and manual curation. We
                 describe and contrast the ``loose'' and ``tight'' data
                 integration strategies employed by BioGPS and GXD,
                 respectively, and discuss the challenges and benefits of data
                 integration. BioGPS is freely available at http://biogps.org .
                 GXD is freely available through the MGI web site (
                 www.informatics.jax.org ) or directly at
                 www.informatics.jax.org/expression.shtml .},
  Journal     = {Mammalian Genome},
  Volume      = {23},
  Number      = {9-10},
  Pages       = {550--558},
  Month       = {10},
  Year        = {2012},
  Language    = {en},
  Issn        = {0938-8990, 1432-1777},
  Pmid        = {22847375},
  Doi         = {10.1007/s00335-012-9408-0},
  Pmc         = {PMC3469763}
}


@article{Lu2017-df,
  Title       = {A gene expression atlas of adult Schistosoma mansoni and their
                 gonads},
  Author      = {Lu, Zhigang and Sessler, Florian and Holroyd, Nancy and
                 Hahnel, Steffen and Quack, Thomas and Berriman, Matthew and
                 Grevelding, Christoph G},
  Abstract    = {RNA-Seq has proven excellence in providing information about
                 the regulation and transcript levels of genes. We used this
                 method for profiling genes in the flatworm Schistosoma
                 mansoni. This parasite causes schistosomiasis, an infectious
                 disease of global importance for human and animals. The
                 pathology of schistosomiasis is associated with the eggs,
                 which are synthesized as a final consequence of male and
                 female adults pairing. The male induces processes in the
                 female that lead to the full development of its gonads as a
                 prerequisite for egg production. Unpaired females remain
                 sexually immature. Based on an organ-isolation method we
                 obtained gonad tissue for RNA extraction from paired and
                 unpaired schistosomes, with whole adults included as controls.
                 From a total of 23 samples, we used high-throughput cDNA
                 sequencing (RNA-Seq) on the Illumina platform to profile gene
                 expression between genders and tissues, with and without
                 pairing influence. The data obtained provide a wealth of
                 information on the reproduction biology of schistosomes and a
                 rich resource for exploitation through basic and applied
                 research activities.},
  Journal     = {Scientific Data},
  Volume      = {4},
  Pages       = {170118},
  Month       = {08},
  Year        = {2017},
  Language    = {en},
  Issn        = {2052-4463},
  Pmid        = {28829433},
  Doi         = {10.1038/sdata.2017.118},
  Pmc         = {PMC5566097}
}


@article{Pazhamala2017-ig,
  Title       = {Gene expression atlas of pigeonpea and its application to gain
                 insights into genes associated with pollen fertility
                 implicated in seed formation},
  Author      = {Pazhamala, Lekha T and Purohit, Shilp and Saxena, Rachit K and
                 Garg, Vanika and Krishnamurthy, L and Verdier, Jerome and
                 Varshney, Rajeev K},
  Abstract    = {Pigeonpea (Cajanus cajan) is an important grain legume of the
                 semi-arid tropics, mainly used for its protein rich seeds. To
                 link the genome sequence information with agronomic traits
                 resulting from specific developmental processes, a Cajanus
                 cajan gene expression atlas (CcGEA) was developed using the
                 Asha genotype. Thirty tissues/organs representing
                 developmental stages from germination to senescence were used
                 to generate 590.84 million paired-end RNA-Seq data. The CcGEA
                 revealed a compendium of 28 793 genes with differential,
                 specific, spatio-temporal and constitutive expression during
                 various stages of development in different tissues. As an
                 example to demonstrate the application of the CcGEA, a network
                 of 28 flower-related genes analysed for cis-regulatory
                 elements and splicing variants has been identified. In
                 addition, expression analysis of these candidate genes in male
                 sterile and male fertile genotypes suggested their critical
                 role in normal pollen development leading to seed formation.
                 Gene network analysis also identified two regulatory genes, a
                 pollen-specific SF3 and a sucrose-proton symporter, that could
                 have implications for improvement of agronomic traits such as
                 seed production and yield. In conclusion, the CcGEA provides a
                 valuable resource for pigeonpea to identify candidate genes
                 involved in specific developmental processes and to understand
                 the well-orchestrated growth and developmental process in this
                 resilient crop.},
  Journal     = {Journal of Experimental Botany},
  Volume      = {68},
  Number      = {8},
  Pages       = {2037--2054},
  Month       = {04},
  Year        = {2017},
  Keywords    = {Cajanus cajan; CcGEA; gene clustering; gene expression atlas;
                 gene networking; legume genomics; male sterile genotype;
                 pigeonpea; pollen-specific SF3; sucrose–proton symporter.},
  Language    = {en},
  Issn        = {0022-0957, 1460-2431},
  Pmid        = {28338822},
  Doi         = {10.1093/jxb/erx010},
  Pmc         = {PMC5429002}
}



@article{Stelpflug2016-sm,
  Title    = {An Expanded Maize Gene Expression Atlas based on {RNA} Sequencing
              and its Use to Explore Root Development},
  Author   = {Stelpflug, Scott C and Sekhon, Rajandeep S and Vaillancourt,
              Brieanne and Hirsch, Candice N and Buell, C Robin and de Leon,
              Natalia and Kaeppler, Shawn M},
  Abstract = {Comprehensive and systematic transcriptome profiling provides
              valuable insight into biological and developmental processes that
              occur throughout the life cycle of a plant. We have enhanced our
              previously published microarray-based gene atlas of maize ( L.)
              inbred B73 to now include 79 distinct replicated samples that
              have been interrogated using RNA sequencing (RNA-seq). The
              current version of the atlas includes 50 original array-based
              gene atlas samples, a time-course of 12 stalk and leaf samples
              postflowering, and an additional set of 17 samples from the maize
              seedling and adult root system. The entire dataset contains 4.6
              billion mapped reads, with an average of 20.5 million mapped
              reads per biological replicate, allowing for detection of genes
              with lower transcript abundance. As the new root samples
              represent key additions to the previously examined tissues, we
              highlight insights into the root transcriptome, which is
              represented by 28,894 (73.2\%) annotated genes in maize.
              Additionally, we observed remarkable expression differences
              across both the longitudinal (four zones) and radial gradients
              (cortical parenchyma and stele) of the primary root supported by
              fourfold differential expression of 9353 and 4728 genes,
              respectively. Among the latter were 1110 genes that encode
              transcription factors, some of which are orthologs of previously
              characterized transcription factors known to regulate root
              development in (L.) Heynh., while most are novel, and represent
              attractive targets for reverse genetics approaches to determine
              their roles in this important organ. This comprehensive
              transcriptome dataset is a powerful tool toward understanding
              maize development, physiology, and phenotypic diversity.},
  Journal  = {The Plant Genome},
  Volume   = {9},
  Number   = {1},
  Month    = {03},
  Year     = {2016},
  Language = {en},
  Issn     = {1940-3372},
  Pmid     = {27898762},
  Doi      = {10.3835/plantgenome2015.04.0025}
}


@article{Yao2016-se,
  Title       = {The Vigna unguiculata Gene Expression Atlas ({VuGEA}) from de
                 novo assembly and quantification of {RNA-seq} data provides
                 insights into seed maturation mechanisms},
  Author      = {Yao, Shaolun and Jiang, Chuan and Huang, Ziyue and
                 Torres-Jerez, Ivone and Chang, Junil and Zhang, Heng and
                 Udvardi, Michael and Liu, Renyi and Verdier, Jerome},
  Abstract    = {Legume research and cultivar development are important for
                 sustainable food production, especially of high-protein seed.
                 Thanks to the development of deep-sequencing technologies,
                 crop species have been taken to the front line, even without
                 completion of their genome sequences. Black-eyed pea (Vigna
                 unguiculata) is a legume species widely grown in semi-arid
                 regions, which has high potential to provide stable seed
                 protein production in a broad range of environments, including
                 drought conditions. The black-eyed pea reference genotype has
                 been used to generate a gene expression atlas of the major
                 plant tissues (i.e. leaf, root, stem, flower, pod and seed),
                 with a developmental time series for pods and seeds. From
                 these various organs, 27 cDNA libraries were generated and
                 sequenced, resulting in more than one billion reads. Following
                 filtering, these reads were de novo assembled into 36 529
                 transcript sequences that were annotated and quantified across
                 the different tissues. A set of 24 866 unique transcript
                 sequences, called Unigenes, was identified. All the
                 information related to transcript identification, annotation
                 and quantification were stored into a gene expression atlas
                 webserver (http://vugea.noble.org), providing a user-friendly
                 interface and necessary tools to analyse transcript expression
                 in black-eyed pea organs and to compare data with other legume
                 species. Using this gene expression atlas, we inferred details
                 of molecular processes that are active during seed
                 development, and identified key putative regulators of seed
                 maturation. Additionally, we found evidence for conservation
                 of regulatory mechanisms involving miRNA in plant tissues
                 subjected to drought and seeds undergoing desiccation.},
  Journal     = {The Plant Journal},
  Volume      = {88},
  Number      = {2},
  Pages       = {318--327},
  Month       = {10},
  Year        = {2016},
  Keywords    = {Vigna unguiculata; cowpea; de novo assembly; drought; gene
                 atlas; seed; transcriptome},
  Language    = {en},
  Issn        = {0960-7412, 1365-313X},
  Pmid        = {27448251},
  Doi         = {10.1111/tpj.13279}
}

@article{Gerrard2016-zu,
  Title       = {An integrative transcriptomic atlas of organogenesis in human
                 embryos},
  Author      = {Gerrard, Dave T and Berry, Andrew A and Jennings, Rachel E and
                 Piper Hanley, Karen and Bobola, Nicoletta and Hanley, Neil A},
  Abstract    = {Human organogenesis is when severe developmental abnormalities
                 commonly originate. However, understanding this critical
                 embryonic phase has relied upon inference from patient
                 phenotypes and assumptions from in vitro stem cell models and
                 non-human vertebrates. We report an integrated transcriptomic
                 atlas of human organogenesis. By lineage-guided principal
                 components analysis, we uncover novel relatedness of
                 particular developmental genes across different organs and
                 tissues and identified unique transcriptional codes which
                 correctly predicted the cause of many congenital disorders. By
                 inference, our model pinpoints co-enriched genes as new causes
                 of developmental disorders such as cleft palate and congenital
                 heart disease. The data revealed more than 6000 novel
                 transcripts, over 90\% of which fulfil criteria as long
                 non-coding RNAs correlated with the protein-coding genome over
                 megabase distances. Taken together, we have uncovered cryptic
                 transcriptional programs used by the human embryo and
                 established a new resource for the molecular understanding of
                 human organogenesis and its associated disorders.},
  Journal     = {eLife},
  Volume      = {5},
  Month       = {08},
  Year        = {2016},
  Keywords    = {developmental biology; embryo; human; human biology; medicine;
                 organogenesis; rna-seq; stem cells; transcriptome},
  Language    = {en},
  Issn        = {2050-084X},
  Pmid        = {27557446},
  Doi         = {10.7554/eLife.15657},
  Pmc         = {PMC4996651}
}


@article{MAQC_Consortium2006-hs,
  Title       = {The {MicroArray} Quality Control ({MAQC}) project shows inter-
                 and intraplatform reproducibility of gene expression
                 measurements},
  Author      = {{MAQC Consortium} and Shi, Leming and Reid, Laura H and Jones,
                 Wendell D and Shippy, Richard and Warrington, Janet A and
                 Baker, Shawn C and Collins, Patrick J and de Longueville,
                 Francoise and Kawasaki, Ernest S and Lee, Kathleen Y and Luo,
                 Yuling and Sun, Yongming Andrew and Willey, James C and
                 Setterquist, Robert A and Fischer, Gavin M and Tong, Weida and
                 Dragan, Yvonne P and Dix, David J and Frueh, Felix W and
                 Goodsaid, Frederico M and Herman, Damir and Jensen, Roderick V
                 and Johnson, Charles D and Lobenhofer, Edward K and Puri, Raj
                 K and Schrf, Uwe and Thierry-Mieg, Jean and Wang, Charles and
                 Wilson, Mike and Wolber, Paul K and Zhang, Lu and Amur, Shashi
                 and Bao, Wenjun and Barbacioru, Catalin C and Lucas, Anne
                 Bergstrom and Bertholet, Vincent and Boysen, Cecilie and
                 Bromley, Bud and Brown, Donna and Brunner, Alan and Canales,
                 Roger and Cao, Xiaoxi Megan and Cebula, Thomas A and Chen,
                 James J and Cheng, Jing and Chu, Tzu-Ming and Chudin, Eugene
                 and Corson, John and Corton, J Christopher and Croner, Lisa J
                 and Davies, Christopher and Davison, Timothy S and Delenstarr,
                 Glenda and Deng, Xutao and Dorris, David and Eklund, Aron C
                 and Fan, Xiao-Hui and Fang, Hong and Fulmer-Smentek, Stephanie
                 and Fuscoe, James C and Gallagher, Kathryn and Ge, Weigong and
                 Guo, Lei and Guo, Xu and Hager, Janet and Haje, Paul K and
                 Han, Jing and Han, Tao and Harbottle, Heather C and Harris,
                 Stephen C and Hatchwell, Eli and Hauser, Craig A and Hester,
                 Susan and Hong, Huixiao and Hurban, Patrick and Jackson, Scott
                 A and Ji, Hanlee and Knight, Charles R and Kuo, Winston P and
                 LeClerc, J Eugene and Levy, Shawn and Li, Quan-Zhen and Liu,
                 Chunmei and Liu, Ying and Lombardi, Michael J and Ma, Yunqing
                 and Magnuson, Scott R and Maqsodi, Botoul and McDaniel, Tim
                 and Mei, Nan and Myklebost, Ola and Ning, Baitang and
                 Novoradovskaya, Natalia and Orr, Michael S and Osborn, Terry W
                 and Papallo, Adam and Patterson, Tucker A and Perkins, Roger G
                 and Peters, Elizabeth H and Peterson, Ron and Philips, Kenneth
                 L and Pine, P Scott and Pusztai, Lajos and Qian, Feng and Ren,
                 Hongzu and Rosen, Mitch and Rosenzweig, Barry A and Samaha,
                 Raymond R and Schena, Mark and Schroth, Gary P and Shchegrova,
                 Svetlana and Smith, Dave D and Staedtler, Frank and Su,
                 Zhenqiang and Sun, Hongmei and Szallasi, Zoltan and Tezak,
                 Zivana and Thierry-Mieg, Danielle and Thompson, Karol L and
                 Tikhonova, Irina and Turpaz, Yaron and Vallanat, Beena and
                 Van, Christophe and Walker, Stephen J and Wang, Sue Jane and
                 Wang, Yonghong and Wolfinger, Russ and Wong, Alex and Wu, Jie
                 and Xiao, Chunlin and Xie, Qian and Xu, Jun and Yang, Wen and
                 Zhang, Liang and Zhong, Sheng and Zong, Yaping and Slikker,
                 Jr, William},
  Abstract    = {Over the last decade, the introduction of microarray
                 technology has had a profound impact on gene expression
                 research. The publication of studies with dissimilar or
                 altogether contradictory results, obtained using different
                 microarray platforms to analyze identical RNA samples, has
                 raised concerns about the reliability of this technology. The
                 MicroArray Quality Control (MAQC) project was initiated to
                 address these concerns, as well as other performance and data
                 analysis issues. Expression data on four titration pools from
                 two distinct reference RNA samples were generated at multiple
                 test sites using a variety of microarray-based and alternative
                 technology platforms. Here we describe the experimental design
                 and probe mapping efforts behind the MAQC project. We show
                 intraplatform consistency across test sites as well as a high
                 level of interplatform concordance in terms of genes
                 identified as differentially expressed. This study provides a
                 resource that represents an important first step toward
                 establishing a framework for the use of microarrays in
                 clinical and regulatory settings.},
  Journal     = {Nature biotechnology},
  Volume      = {24},
  Number      = {9},
  Pages       = {1151--1161},
  Month       = {09},
  Year        = {2006},
  Language    = {en},
  Issn        = {1087-0156},
  Pmid        = {16964229},
  Doi         = {10.1038/nbt1239},
  Pmc         = {PMC3272078}
}


@article{Santos2015-rj,
  Title       = {Comprehensive comparison of large-scale tissue expression
                 datasets},
  Author      = {Santos, Alberto and Tsafou, Kalliopi and Stolte, Christian and
                 Pletscher-Frankild, Sune and O'Donoghue, Seán I and Jensen,
                 Lars Juhl},
  Abstract    = {For tissues to carry out their functions, they rely on the
                 right proteins to be present. Several high-throughput
                 technologies have been used to map out which proteins are
                 expressed in which tissues; however, the data have not
                 previously been systematically compared and integrated. We
                 present a comprehensive evaluation of tissue expression data
                 from a variety of experimental techniques and show that these
                 agree surprisingly well with each other and with results from
                 literature curation and text mining. We further found that
                 most datasets support the assumed but not demonstrated
                 distinction between tissue-specific and ubiquitous expression.
                 By developing comparable confidence scores for all types of
                 evidence, we show that it is possible to improve both quality
                 and coverage by combining the datasets. To facilitate use and
                 visualization of our work, we have developed the TISSUES
                 resource (http://tissues.jensenlab.org), which makes all the
                 scored and integrated data available through a single
                 user-friendly web interface.},
  Journal     = {PeerJ},
  Volume      = {3},
  Pages       = {e1054},
  Month       = {06},
  Year        = {2015},
  Keywords    = {Databases; Immunohistochemistry; Mass spectrometry;
                 Microarrays; RNA sequencing; Tissue expression;
                 Tissue-specificity},
  Language    = {en},
  Pmid        = {26157623},
  Doi         = {10.7717/peerj.1054},
  Pmc         = {PMC4493645}
}



@article{Yi2010-az,
  Title       = {Gene expression atlas for human embryogenesis},
  Author      = {Yi, Hong and Xue, Lu and Guo, Ming-Xiong and Ma, Jian and
                 Zeng, Yan and Wang, Wei and Cai, Jin-Yang and Hu, Hai-Ming and
                 Shu, Hong-Bing and Shi, Yun-Bo and Li, Wen-Xin},
  Abstract    = {Human embryogenesis is believed to involve an integrated set
                 of complex yet coordinated development of different organs and
                 tissues mediated by the changes in the spatiotemporal
                 expression of many genes. Here, we report a genome-wide
                 expression analysis during wk 4-9 of human embryogenesis, a
                 critical period when most organs develop. About half of all
                 human genes are expressed, and 18.6\% of the expressed genes
                 were significantly regulated during this important period. We
                 further identified >5000 regulated genes, most of which
                 previously were not known to be associated with animal
                 development. Our study fills an important gap in mammalian
                 developmental studies by identifying functional pathways
                 involved in this critical but previously not studied period.
                 Our study also revealed that the genes involved here are
                 distinct from those during early embryogenesis, which include
                 three groups of maternal genes. Furthermore, we discovered
                 that genes in a given developmental process are regulated
                 coordinately. This led us to develop an easily searchable
                 database of this entire collection of gene expression
                 profiles, allowing for the identification new genes important
                 for a particular developmental process/pathway and deducing
                 the potential function of a novel gene. The validity of the
                 predictions from the database was demonstrated with two
                 examples through spatiotemporal analyses of the two novel
                 genes. Such a database should serve as a highly valuable
                 resource for the molecular analysis of human development and
                 pathogenesis.},
  Journal     = {FASEB Journal},
  Volume      = {24},
  Number      = {9},
  Pages       = {3341--3350},
  Month       = {09},
  Year        = {2010},
  Language    = {en},
  Issn        = {0892-6638, 1530-6860},
  Pmid        = {20430792},
  Doi         = {10.1096/fj.10-158782},
  Pmc         = {PMC2923361}
}


@article{Mabbott2013-xf,
  Title       = {An expression atlas of human primary cells: inference of gene
                 function from coexpression networks},
  Author      = {Mabbott, Neil A and Baillie, J Kenneth and Brown, Helen and
                 Freeman, Tom C and Hume, David A},
  Abstract    = {BACKGROUND: The specialisation of mammalian cells in time and
                 space requires genes associated with specific pathways and
                 functions to be co-ordinately expressed. Here we have combined
                 a large number of publically available microarray datasets
                 derived from human primary cells and analysed large
                 correlation graphs of these data. RESULTS: Using the network
                 analysis tool BioLayout Express3D we identify robust
                 co-associations of genes expressed in a wide variety of cell
                 lineages. We discuss the biological significance of a number
                 of these associations, in particular the coexpression of key
                 transcription factors with the genes that they are likely to
                 control. CONCLUSIONS: We consider the regulation of genes in
                 human primary cells and specifically in the human mononuclear
                 phagocyte system. Of particular note is the fact that these
                 data do not support the identity of putative markers of
                 antigen-presenting dendritic cells, nor classification of M1
                 and M2 activation states, a current subject of debate within
                 immunological field. We have provided this data resource on
                 the BioGPS web site
                 (http://biogps.org/dataset/2429/primary-cell-atlas/) and on
                 macrophages.com (http://www.macrophages.com/hu-cell-atlas).},
  Journal     = {BMC Genomics},
  Volume      = {14},
  Pages       = {632},
  Month       = {09},
  Year        = {2013},
  Language    = {en},
  Issn        = {1471-2164},
  Pmid        = {24053356},
  Doi         = {10.1186/1471-2164-14-632},
  Pmc         = {PMC3849585}
}



@article{Su2004-kc,
  Title       = {A gene atlas of the mouse and human protein-encoding
                 transcriptomes},
  Author      = {Su, Andrew I and Wiltshire, Tim and Batalov, Serge and Lapp,
                 Hilmar and Ching, Keith A and Block, David and Zhang, Jie and
                 Soden, Richard and Hayakawa, Mimi and Kreiman, Gabriel and
                 Cooke, Michael P and Walker, John R and Hogenesch, John B},
  Abstract    = {The tissue-specific pattern of mRNA expression can indicate
                 important clues about gene function. High-density
                 oligonucleotide arrays offer the opportunity to examine
                 patterns of gene expression on a genome scale. Toward this
                 end, we have designed custom arrays that interrogate the
                 expression of the vast majority of protein-encoding human and
                 mouse genes and have used them to profile a panel of 79 human
                 and 61 mouse tissues. The resulting data set provides the
                 expression patterns for thousands of predicted genes, as well
                 as known and poorly characterized genes, from mice and humans.
                 We have explored this data set for global trends in gene
                 expression, evaluated commonly used lines of evidence in gene
                 prediction methodologies, and investigated patterns indicative
                 of chromosomal organization of transcription. We describe
                 hundreds of regions of correlated transcription and show that
                 some are subject to both tissue and parental allele-specific
                 expression, suggesting a link between spatial expression and
                 imprinting.},
  Journal     = {Proceedings of the National Academy of Sciences of the United
                 States of America},
  Volume      = {101},
  Number      = {16},
  Pages       = {6062--6067},
  Month       = {04},
  Year        = {2004},
  Language    = {en},
  Issn        = {0027-8424},
  Pmid        = {15075390},
  Doi         = {10.1073/pnas.0400782101},
  Pmc         = {PMC395923}
}


@article{Hawrylycz2012-mx,
  Title       = {An anatomically comprehensive atlas of the adult human brain
                 transcriptome},
  Author      = {Hawrylycz, Michael J and Lein, Ed S and Guillozet-Bongaarts,
                 Angela L and Shen, Elaine H and Ng, Lydia and Miller, Jeremy A
                 and van de Lagemaat, Louie N and Smith, Kimberly A and Ebbert,
                 Amanda and Riley, Zackery L and Abajian, Chris and Beckmann,
                 Christian F and Bernard, Amy and Bertagnolli, Darren and Boe,
                 Andrew F and Cartagena, Preston M and Chakravarty, M Mallar
                 and Chapin, Mike and Chong, Jimmy and Dalley, Rachel A and
                 David Daly, Barry and Dang, Chinh and Datta, Suvro and Dee,
                 Nick and Dolbeare, Tim A and Faber, Vance and Feng, David and
                 Fowler, David R and Goldy, Jeff and Gregor, Benjamin W and
                 Haradon, Zeb and Haynor, David R and Hohmann, John G and
                 Horvath, Steve and Howard, Robert E and Jeromin, Andreas and
                 Jochim, Jayson M and Kinnunen, Marty and Lau, Christopher and
                 Lazarz, Evan T and Lee, Changkyu and Lemon, Tracy A and Li,
                 Ling and Li, Yang and Morris, John A and Overly, Caroline C
                 and Parker, Patrick D and Parry, Sheana E and Reding, Melissa
                 and Royall, Joshua J and Schulkin, Jay and Sequeira, Pedro
                 Adolfo and Slaughterbeck, Clifford R and Smith, Simon C and
                 Sodt, Andy J and Sunkin, Susan M and Swanson, Beryl E and
                 Vawter, Marquis P and Williams, Derric and Wohnoutka, Paul and
                 Zielke, H Ronald and Geschwind, Daniel H and Hof, Patrick R
                 and Smith, Stephen M and Koch, Christof and Grant, Seth G N
                 and Jones, Allan R},
  Abstract    = {Neuroanatomically precise, genome-wide maps of transcript
                 distributions are critical resources to complement genomic
                 sequence data and to correlate functional and genetic brain
                 architecture. Here we describe the generation and analysis of
                 a transcriptional atlas of the adult human brain, comprising
                 extensive histological analysis and comprehensive microarray
                 profiling of ∼900 neuroanatomically precise subdivisions in
                 two individuals. Transcriptional regulation varies enormously
                 by anatomical location, with different regions and their
                 constituent cell types displaying robust molecular signatures
                 that are highly conserved between individuals. Analysis of
                 differential gene expression and gene co-expression
                 relationships demonstrates that brain-wide variation strongly
                 reflects the distributions of major cell classes such as
                 neurons, oligodendrocytes, astrocytes and microglia. Local
                 neighbourhood relationships between fine anatomical
                 subdivisions are associated with discrete neuronal subtypes
                 and genes involved with synaptic transmission. The neocortex
                 displays a relatively homogeneous transcriptional pattern, but
                 with distinct features associated selectively with primary
                 sensorimotor cortices and with enriched frontal lobe
                 expression. Notably, the spatial topography of the neocortex
                 is strongly reflected in its molecular topography-the closer
                 two cortical regions, the more similar their transcriptomes.
                 This freely accessible online data resource forms a
                 high-resolution transcriptional baseline for neurogenetic
                 studies of normal and abnormal human brain function.},
  Journal     = {Nature},
  Volume      = {489},
  Number      = {7416},
  Pages       = {391--399},
  Month       = {09},
  Year        = {2012},
  Language    = {en},
  Issn        = {0028-0836, 1476-4687},
  Pmid        = {22996553},
  Doi         = {10.1038/nature11405},
  Pmc         = {PMC4243026}
}

@article{Campain2010-ho,
  Title       = {Comparison study of microarray meta-analysis methods},
  Author      = {Campain, Anna and Yang, Yee Hwa},
  Abstract    = {BACKGROUND: Meta-analysis methods exist for combining multiple
                 microarray datasets. However, there are a wide range of issues
                 associated with microarray meta-analysis and a limited ability
                 to compare the performance of different meta-analysis methods.
                 RESULTS: We compare eight meta-analysis methods, five existing
                 methods, two naive methods and a novel approach (mDEDS).
                 Comparisons are performed using simulated data and two
                 biological case studies with varying degrees of meta-analysis
                 complexity. The performance of meta-analysis methods is
                 assessed via ROC curves and prediction accuracy where
                 applicable. CONCLUSIONS: Existing meta-analysis methods vary
                 in their ability to perform successful meta-analysis. This
                 success is very dependent on the complexity of the data and
                 type of analysis. Our proposed method, mDEDS, performs
                 competitively as a meta-analysis tool even as complexity
                 increases. Because of the varying abilities of compared
                 meta-analysis methods, care should be taken when considering
                 the meta-analysis method used for particular research.},
  Journal     = {BMC bioinformatics},
  Volume      = {11},
  Pages       = {408},
  Month       = {08},
  Year        = {2010},
  Language    = {en},
  Issn        = {1471-2105},
  Pmid        = {20678237},
  Doi         = {10.1186/1471-2105-11-408},
  Pmc         = {PMC2922198}
}

@article{Tseng2012-if,
  Title       = {Comprehensive literature review and statistical considerations
                 for microarray meta-analysis},
  Author      = {Tseng, George C and Ghosh, Debashis and Feingold, Eleanor},
  Abstract    = {With the rapid advances of various high-throughput
                 technologies, generation of '-omics' data is commonplace in
                 almost every biomedical field. Effective data management and
                 analytical approaches are essential to fully decipher the
                 biological knowledge contained in the tremendous amount of
                 experimental data. Meta-analysis, a set of statistical tools
                 for combining multiple studies of a related hypothesis, has
                 become popular in genomic research. Here, we perform a
                 systematic search from PubMed and manual collection to obtain
                 620 genomic meta-analysis papers, of which 333 microarray
                 meta-analysis papers are summarized as the basis of this paper
                 and the other 249 GWAS meta-analysis papers are discussed in
                 the next companion paper. The review in the present paper
                 focuses on various biological purposes of microarray
                 meta-analysis, databases and software and related statistical
                 procedures. Statistical considerations of such an analysis are
                 further scrutinized and illustrated by a case study. Finally,
                 several open questions are listed and discussed.},
  Journal     = {Nucleic Acids Research},
  Volume      = {40},
  Number      = {9},
  Pages       = {3785--3799},
  Month       = {05},
  Year        = {2012},
  Language    = {en},
  Issn        = {0305-1048, 1362-4962},
  Pmid        = {22262733},
  Doi         = {10.1093/nar/gkr1265},
  Pmc         = {PMC3351145}
}

@article{Afroz2016-xk,
  Title       = {Transcriptome meta-analysis reveals a dysregulation in extra
                 cellular matrix and cell junction associated gene signatures
                 during Dengue virus infection},
  Author      = {Afroz, Sumbul and Giddaluru, Jeevan and Abbas, Mohd Manzar and
                 Khan, Nooruddin},
  Abstract    = {Dengue Viruses (DENVs) cause one of the most prevalent
                 arthropod-borne viral diseases affecting millions of people
                 worldwide. Identification of genes involved in DENV
                 pathogenesis would help in deciphering molecular mechanisms
                 responsible for the disease progression. Here, we carried out
                 a meta-analysis of publicly available gene expression data of
                 dengue patients and further validated the meta-profile using
                 in-vitro infection in THP-1 cells. Our findings reveal that
                 DENV infection modulates expression of several genes and
                 signalling pathways including interferons, detoxification of
                 ROS and viral assembly. Interestingly, we have identified
                 novel gene signatures comprising of INADL/PATJ and CRTAP
                 (Cartilage Associated Protein), which were significantly
                 down-regulated across all patient data sets as well as in DENV
                 infected THP-1 cells. PATJ and CRTAP genes are involved in
                 maintaining cell junction integrity and collagen assembly
                 (extracellular matrix component) respectively, which together
                 play a crucial role in cell-cell adhesion. Our results
                 categorically reveal that overexpression of CRTAP and PATJ
                 genes restrict DENV infection, thereby suggesting a critical
                 role of these genes in DENV pathogenesis. Conclusively, these
                 findings emphasize the utility of meta-analysis approach in
                 identifying novel gene signatures that might provide
                 mechanistic insights into disease pathogenesis and possibly
                 lead towards the development of better therapeutic
                 interventions.},
  Journal     = {Scientific Reports},
  Volume      = {6},
  Pages       = {33752},
  Month       = {09},
  Year        = {2016},
  Language    = {en},
  Issn        = {2045-2322},
  Pmid        = {27651116},
  Doi         = {10.1038/srep33752},
  Pmc         = {PMC5030657}
}

@article{Walsh2015-nf,
  Title       = {Microarray {Meta-Analysis} and {Cross-Platform} Normalization:
                 Integrative Genomics for Robust Biomarker Discovery},
  Author      = {Walsh, Christopher J and Hu, Pingzhao and Batt, Jane and
                 Santos, Claudia C Dos},
  Abstract    = {The diagnostic and prognostic potential of the vast quantity
                 of publicly-available microarray data has driven the
                 development of methods for integrating the data from different
                 microarray platforms. Cross-platform integration, when
                 appropriately implemented, has been shown to improve
                 reproducibility and robustness of gene signature biomarkers.
                 Microarray platform integration can be conceptually divided
                 into approaches that perform early stage integration
                 (cross-platform normalization) versus late stage data
                 integration (meta-analysis). A growing number of statistical
                 methods and associated software for platform integration are
                 available to the user, however an understanding of their
                 comparative performance and potential pitfalls is critical for
                 best implementation. In this review we provide evidence-based,
                 practical guidance to researchers performing cross-platform
                 integration, particularly with an objective to discover
                 biomarkers.},
  Journal     = {Microarrays},
  Volume      = {4},
  Number      = {3},
  Pages       = {389--406},
  Month       = {08},
  Year        = {2015},
  Keywords    = {biomarker; meta-analysis; microarray platform; normalization},
  Language    = {en},
  Issn        = {2076-3905},
  Pmid        = {27600230},
  Doi         = {10.3390/microarrays4030389},
  Pmc         = {PMC4996376}
}

@article{Rung2013-ul,
  Title       = {Reuse of public genome-wide gene expression data},
  Author      = {Rung, Johan and Brazma, Alvis},
  Abstract    = {Our understanding of gene expression has changed dramatically
                 over the past decade, largely catalysed by technological
                 developments. High-throughput experiments - microarrays and
                 next-generation sequencing - have generated large amounts of
                 genome-wide gene expression data that are collected in public
                 archives. Added-value databases process, analyse and annotate
                 these data further to make them accessible to every biologist.
                 In this Review, we discuss the utility of the gene expression
                 data that are in the public domain and how researchers are
                 making use of these data. Reuse of public data can be very
                 powerful, but there are many obstacles in data preparation and
                 analysis and in the interpretation of the results. We will
                 discuss these challenges and provide recommendations that we
                 believe can improve the utility of such data.},
  Journal     = {Nature Reviews Genetics},
  Volume      = {14},
  Number      = {2},
  Pages       = {89--99},
  Month       = {02},
  Year        = {2013},
  Language    = {en},
  Issn        = {1471-0056, 1471-0064},
  Pmid        = {23269463},
  Doi         = {10.1038/nrg3394}
}

@article{Taminau2014-hr,
  Title       = {Comparison of merging and meta-analysis as alternative
                 approaches for integrative gene expression analysis},
  Author      = {Taminau, Jonatan and Lazar, Cosmin and Meganck, Stijn and
                 Nowé, Ann},
  Abstract    = {An increasing amount of microarray gene expression data sets
                 is available through public repositories. Their huge potential
                 in making new findings is yet to be unlocked by making them
                 available for large-scale analysis. In order to do so it is
                 essential that independent studies designed for similar
                 biological problems can be integrated, so that new insights
                 can be obtained. These insights would remain undiscovered when
                 analyzing the individual data sets because it is well known
                 that the small number of biological samples used per
                 experiment is a bottleneck in genomic analysis. By increasing
                 the number of samples the statistical power is increased and
                 more general and reliable conclusions can be drawn. In this
                 work, two different approaches for conducting large-scale
                 analysis of microarray gene expression data-meta-analysis and
                 data merging-are compared in the context of the identification
                 of cancer-related biomarkers, by analyzing six independent
                 lung cancer studies. Within this study, we investigate the
                 hypothesis that analyzing large cohorts of samples resulting
                 in merging independent data sets designed to study the same
                 biological problem results in lower false discovery rates than
                 analyzing the same data sets within a more conservative
                 meta-analysis approach.},
  Journal     = {ISRN bioinformatics},
  Volume      = {2014},
  Pages       = {345106},
  Month       = {01},
  Year        = {2014},
  Language    = {en},
  Issn        = {2090-7338},
  Pmid        = {25937953},
  Doi         = {10.1155/2014/345106},
  Pmc         = {PMC4393058}
}


@article{LinsingerHampel,
  Title     = {The influence of different evaluation techniques on the results
               of interlaboratory comparisons},
  Author    = {Linsinger, Thomas Peter Josef and Kandler, Wolfgang and Krska, R
               and Grasserbauer, Manfred},
  Abstract  = {The influence of different evaluation techniques on the results
               of an interlaboratory comparison for the determination of
               nutrients in ground- and surface water was investigated. The
               outlier-test procedure was found to influence the
               interlaboratory standard deviations (SDs), but not the averages.
               It was shown that even small differences in the numbers of
               outliers detected can change the SD severely. Comparing the
               outlier-test procedures of Hampel, Grubbs and Graf-Henning, it
               was found that Hampel's test detected the most outliers, thus
               generally resulting in smaller SDs between interlaboratory
               comparisons. The Graf-Henning test detected the fewest outliers
               and its application resulted in the highest SDs of the three
               test procedures investigated. The comparison of different
               summarising indices, namely the rescaled sum of z-scores,
               average of absolute z-scores and average deviation showed no
               comparability. Possibilities to improve the comparability of
               interlaboratory comparisons and to minimise misunderstandings
               are suggested.},
  Journal   = {Accreditation and Quality Assurance},
  Publisher = {Springer-Verlag},
  Volume    = {3},
  Number    = {8},
  Pages     = {322--327},
  Month     = {08},
  Year      = {1998},
  Language  = {en},
  Issn      = {0949-1775, 1432-0517},
  Doi       = {10.1007/s007690050254}
}

@article{CorrelationImpactingFactors,
  title     = {Understanding Correlation: Factors That Affect the Size of r},
  Author    = {Goodwin, Laura D and Leech, Nancy L},
  Abstract  = {The authors describe and illustrate 6 factors that
               affect the size of a Pearson correlation: (a) the amount of
               variability in the data, (b) differences in the shapes of the 2
               distributions, (c) lack of linearity, (d) the presence of 1 or
               more ``outliers,'' (e) characteristics of the sample, and (f)
               measurement error. Also discussed are ways to determine whether
               these factors are likely affecting the correlation, as well as
               ways to estimate the size of the influence or reduce the
               influence of each.},
  Journal   = {Journal of experimental education},
  Publisher = {Routledge},
  Volume    = {74},
  Number    = {3},
  Pages     = {249--266},
  Month     = {04},
  Year      = {2006},
  Issn      = {0022-0973},
  Doi       = {10.3200/JEXE.74.3.249-266}
}

@article{Liu2004-kf,
  Title    = {On-line outlier detection and data cleaning},
  Author   = {Liu, Hancong and Shah, Sirish and Jiang, Wei},
  Abstract = {Outliers are observations that do not follow the statistical
              distribution of the bulk of the data, and consequently may lead
              to erroneous results with respect to statistical analysis. Many
              conventional outlier detection tools are based on the assumption
              that the data is identically and independently distributed. In
              this paper, an outlier-resistant data filter-cleaner is proposed.
              The proposed data filter-cleaner includes an on-line
              outlier-resistant estimate of the process model and combines it
              with a modified Kalman filter to detect and ``clean'' outliers.
              The advantage over existing methods is that the proposed method
              has the following features: (a) a priori knowledge of the process
              model is not required; (b) it is applicable to autocorrelated
              data; (c) it can be implemented on-line; and (d) it tries to only
              clean (i.e., detects and replaces) outliers and preserves all
              other information in the data.},
  Journal  = {Computers \& chemical engineering},
  Volume   = {28},
  Number   = {9},
  Pages    = {1635--1647},
  Month    = {08},
  Year     = {2004},
  Keywords = {Data preprocessing; Outlier detection; Breakdown point; Data
              filter-cleaner; Time series analysis},
  Issn     = {0098-1354},
  Doi      = {10.1016/j.compchemeng.2004.01.009}
}

@article{Davies1993-nv,
  Title     = {The Identification of Multiple Outliers},
  Author    = {Davies, Laurie and Gather, Ursula},
  Abstract  = {One approach to identifying outliers is to assume that the
               outliers have a different distribution from the remaining
               observations. In this article we define outliers in terms of
               their position relative to the model for the good observations.
               The outlier identification problem is then the problem of
               identifying those observations that lie in a so-called outlier
               region. Methods based on robust statistics and outward testing
               are shown to have the highest possible breakdown points in a
               sense derived from Donoho and Huber. But a more detailed
               analysis shows that methods based on robust statistics perform
               better with respect to worst-case behavior. A concrete outlier
               identifier based on a suggestion of Hampel is given.},
  Journal   = {Journal of the American Statistical Association},
  Publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  Volume    = {88},
  Number    = {423},
  Pages     = {782--792},
  Year      = {1993},
  Issn      = {0162-1459},
  Doi       = {10.2307/2290763}
}

@article{Pearson2002-im,
  Title    = {Outliers in process modeling and identification},
  Author   = {Pearson, R K},
  Abstract = {Model-based control strategies like model predictive control
              (MPC) require models of process dynamics accurate enough that the
              resulting controllers perform adequately in practice. Often,
              these models are obtained by fitting convenient model structures
              (e.g., linear finite impulse response (FIR) models, linear
              pole-zero models, nonlinear Hammerstein or Wiener models, etc.)
              to observed input-output data. Real measurement data records
              frequently contain ``outliers'' or ``anomalous data points,''
              which can badly degrade the results of an otherwise reasonable
              empirical model identification procedure. This paper considers
              some real datasets containing outliers, examines the influence of
              outliers on linear and nonlinear system identification, and
              discusses the problems of outlier detection and data cleaning.
              Although no single strategy is universally applicable, the Hampel
              filter described here is often extremely effective in practice},
  Journal  = {IEEE Transactions on Control Systems Technology},
  Volume   = {10},
  Number   = {1},
  Pages    = {55--63},
  Month    = {01},
  Year     = {2002},
  Keywords = {FIR filters;median filters;model reference adaptive control
              systems;nonlinear filters;predictive control;Hampel filter;Wiener
              models;data cleaning;linear finite impulse response models;linear
              pole-zero models;median filters;model predictive
              control;model-based control strategies;nonlinear
              Hammerstein;nonlinear filters;observed input-output data;outlier
              detection;process dynamics;process identification;process
              modeling;real datasets;robust
              statistics;Cleaning;Degradation;Finite impulse response
              filter;Fitting;Least squares approximation;Nonlinear
              filters;Nonlinear systems;Predictive control;Predictive
              models;Robustness},
  Issn     = {1063-6536},
  Doi      = {10.1109/87.974338}
}

@article{Lewczuk2006-wq,
  Title       = {International quality control survey of neurochemical dementia
                 diagnostics},
  Author      = {Lewczuk, Piotr and Beck, Georg and Ganslandt, Oliver and
                 Esselmann, Hermann and Deisenhammer, Florian and Regeniter,
                 Axel and Petereit, Hela-Felicitas and Tumani, Hayrettin and
                 Gerritzen, Andreas and Oschmann, Patrick and Schröder,
                 Johannes and Schönknecht, Peter and Zimmermann, Klaus and
                 Hampel, Harald and Bürger, Katharina and Otto, Markus and
                 Haustein, Sabine and Herzog, Karin and Dannenberg, Rainer and
                 Wurster, Ulrich and Bibl, Mirko and Maler, Juan Manuel and
                 Reubach, Udo and Kornhuber, Johannes and Wiltfang, Jens},
  Affiliation = {Department of Psychiatry and Psychotherapy, University of
                 Erlangen-Nuremberg, Erlangen, Germany.},
  Abstract    = {Currently, neurochemical dementia diagnostics
                 (NDD) are increasingly entering routine clinical
                 neurochemistry, offering improved early and differential
                 diagnosis of dementias. However, there is an obvious lack of
                 standardization in pre-analytical sample handling and
                 systematic quality surveys. Therefore, in this study, 14
                 laboratories in Germany, Austria, and Switzerland were given
                 aliquots of a human cerebrospinal fluid (CSF) sample, and were
                 asked to measure Alzheimer's disease (AD) biomarkers (amyloid
                 beta (Abeta) peptides, total Tau protein, and phosphorylated
                 Tau protein (P-tau(181P))) according to their routine
                 protocols. RESULTS: The inter-laboratory coefficients of
                 variation of the results obtained by the laboratories
                 participating in this study were in the range of 20-30\%.
                 Although the results of this quality control survey are
                 promising, the quality of measurements has to be further
                 optimized.},
  Journal     = {Neuroscience letters},
  Volume      = {409},
  Number      = {1},
  Pages       = {1--4},
  Month       = {11},
  Year        = {2006},
  Language    = {en},
  Issn        = {0304-3940},
  Pmid        = {17045397},
  Doi         = {10.1016/j.neulet.2006.07.009}
}

@article{Rocke1983-qa,
  Title     = {Robust statistical analysis of interlaboratory studies},
  Author    = {Rocke, David M},
  Abstract  = {A common procedure in testing analytical methods is to send a
               portion of each of a number of samples to each of several
               laboratories. The results of such a study are submitted to
               statistical analysis to determine the two important variance
               components in the problem: replication error and laboratory
               bias. Outliers are relatively common in these data both among
               laboratory effects and among the residuals. This paper presents
               a method of analysis for interlaboratory studies that is robust
               to the existence of outliers and long-tailed distributions of
               random effects. Theoretical considerations as well as a Monte
               Carlo study are adduced as support for this new technique.},
  Journal   = {Biometrika},
  Publisher = {Oxford University Press},
  Volume    = {70},
  Number    = {2},
  Pages     = {421--431},
  Month     = {08},
  Year      = {1983},
  Issn      = {0006-3444},
  Doi       = {10.1093/biomet/70.2.421}
}

@article{Apfalter1999-ca,
  Title     = {Interlaboratory comparison study for the determination of
               halogenated hydrocarbons in water},
  Author    = {Apfalter, S and Krska, R and Linsinger, T and Oberhauser, A and
               Kandler, W and Grasserbauer, M},
  Abstract  = {Sixty laboratories of five different countries participated in a
               large-scale interlaboratory comparison test for the
               determination of halogenated hydrocarbons in water. Participants
               used their in-house method with 44 laboratories applying head
               space GC ECD analysis and 5 using liquid/liquid extraction. A
               set of two artificially produced samples was prepared; the
               halogenated hydrocarbons investigated were trichloroethylene,
               tetrachloroethylene, 1,1,1-trichloroethane, trichloromethane,
               tetrachloromethane, 1,1-dichloroethylene, dichloromethane,
               dibromochloromethane, bromodichloromethane, 1,2-dichloroethane
               and tribromomethane. The procedure of sample preparation,
               storage and distribution was monitored by an extensive quality
               assurance system including homogeneity tests, stability tests,
               and trend analysis of the submitted data. The analytical results
               submitted by the participants exhibited RSD values of up to 35\%
               and outlier rates of up to 19\%. The percentage of false
               positive and false negative results was at the highest 12\% for
               selected substances. Recovery rates varying from 86\% to 106\%
               proved the correctness of the analytical results submitted by
               the participants and showed that the procedure developed in this
               study for sample preparation and distribution is well suited for
               the performance of large-scale interlaboratory comparison tests
               of halogenated hydrocarbons in water.},
  Journal   = {Fresenius' journal of analytical chemistry},
  Publisher = {Springer-Verlag},
  Volume    = {364},
  Number    = {7},
  Pages     = {660--665},
  Month     = {08},
  Year      = {1999},
  Language  = {en},
  Issn      = {0937-0633, 1432-1130},
  Doi       = {10.1007/s002160051409}
}

@unpublished{Wang2017-hc,
  Title    = {Enabling cross-study analysis of {RNA-Sequencing} data},
  Author   = {Wang, Qingguo and Armenia, Joshua and Zhang, Chao and Penson,
              Alexander V and Reznik, Ed and Zhang, Liguo and Ochoa, Angelica
              and Gross, Benjamin E and Iacobuzio-Donahue, Christine A and
              Betel, Doron and Taylor, Barry S and Gao, Jianjiong and Schultz,
              Nikolaus},
  Abstract = {Driven by the recent advances of next generation sequencing (NGS)
              technologies and an urgent need to decode complex human diseases,
              a multitude of large-scale studies were conducted recently that
              have resulted in an unprecedented volume of whole transcriptome
              sequencing (RNA-seq) data. While these data offer new
              opportunities to identify the mechanisms underlying disease, the
              comparison of data from different sources poses a great
              challenge, due to differences in sample and data processing.
              Here, we present a pipeline that processes and unifies RNA-seq
              data from different studies, which includes uniform realignment
              and gene expression quantification as well as batch effect
              removal. We find that uniform alignment and quantification is not
              sufficient when combining RNA-seq data from different sources and
              that the removal of other batch effects is essential to
              facilitate data comparison. We have processed data from the
              Genotype Tissue Expression project (GTEx) and The Cancer Genome
              Atlas (TCGA) and have successfully corrected for study-specific
              biases, enabling comparative analysis across studies. The
              normalized data are available for download via GitHub (at
              https://github.com/mskcc/RNAseqDB).},
  Journal  = {bioRxiv},
  Pages    = {110734},
  Month    = {02},
  Year     = {2017},
  Language = {en},
  Doi      = {10.1101/110734}
}

@article{Sudmant2015-zt,
  Title       = {Meta-analysis of {RNA-seq} expression data across species,
                 tissues and studies},
  Author      = {Sudmant, Peter H and Alexis, Maria S and Burge, Christopher B},
  Affiliation = {Department of Biology and Biological Engineering,
                 Massachusetts Institute of Technology, Cambridge, MA, 02142,
                 USA. Department of Biology and Biological Engineering,
                 Massachusetts Institute of Technology, Cambridge, MA, 02142,
                 USA. Program in Computational and Systems Biology,
                 Massachusetts Institute of Technology, Cambridge, MA, 02142,
                 USA. Department of Biology and Biological Engineering,
                 Massachusetts Institute of Technology, Cambridge, MA, 02142,
                 USA. cburge@mit.edu. Program in Computational and Systems
                 Biology, Massachusetts Institute of Technology, Cambridge, MA,
                 02142, USA. cburge@mit.edu.},
  Abstract    = {BACKGROUND: Differences in gene expression drive phenotypic
                 differences between species, yet major organs and tissues
                 generally have conserved gene expression programs. Several
                 comparative transcriptomic studies have observed greater
                 similarity in gene expression between homologous tissues from
                 different vertebrate species than between diverse tissues of
                 the same species. However, a recent study by Lin and
                 colleagues reached the opposite conclusion. These studies
                 differed in the species and tissues analyzed, and in technical
                 details of library preparation, sequencing, read mapping,
                 normalization, gene sets, and clustering methods. RESULTS: To
                 better understand gene expression evolution we reanalyzed data
                 from four studies, including that of Lin, encompassing 6-13
                 tissues each from 11 vertebrate species using standardized
                 mapping, normalization, and clustering methods. An analysis of
                 independent data showed that the set of tissues chosen by Lin
                 et al. were more similar to each other than those analyzed by
                 previous studies. Comparing expression in five common tissues
                 from the four studies, we observed that samples clustered
                 exclusively by tissue rather than by species or study,
                 supporting conservation of organ physiology in mammals.
                 Furthermore, inter-study distances between homologous tissues
                 were generally less than intra-study distances among different
                 tissues, enabling informative meta-analyses. Notably, when
                 comparing expression divergence of tissues over time to
                 expression variation across 51 human GTEx tissues, we could
                 accurately predict the clustering of expression for arbitrary
                 pairs of tissues and species. CONCLUSIONS: These results
                 provide a framework for the design of future evolutionary
                 studies of gene expression and demonstrate the utility of
                 comparing RNA-seq data across studies.},
  Journal     = {Genome biology},
  Volume      = {16},
  Pages       = {287},
  Month       = {12},
  Year        = {2015},
  Language    = {en},
  Issn        = {1465-6906},
  Pmid        = {26694591},
  Doi         = {10.1186/s13059-015-0853-4},
  Pmc         = {PMC4699362}
}

@article{Rau2014-va,
  Title       = {Differential meta-analysis of {RNA-seq} data from multiple
                 studies},
  Author      = {Rau, Andrea and Marot, Guillemette and Jaffrézic, Florence},
  Affiliation = {INRA, UMR1313 Génétique animale et biologie intégrative, 78352
                 Jouy-en-Josas, France. andrea.rau@jouy.inra.fr.},
  Abstract    = {BACKGROUND: High-throughput sequencing is now regularly used
                 for studies of the transcriptome (RNA-seq), particularly for
                 comparisons among experimental conditions. For the time being,
                 a limited number of biological replicates are typically
                 considered in such experiments, leading to low detection power
                 for differential expression. As their cost continues to
                 decrease, it is likely that additional follow-up studies will
                 be conducted to re-address the same biological question.
                 RESULTS: We demonstrate how p-value combination techniques
                 previously used for microarray meta-analyses can be used for
                 the differential analysis of RNA-seq data from multiple
                 related studies. These techniques are compared to a negative
                 binomial generalized linear model (GLM) including a fixed
                 study effect on simulated data and real data on human melanoma
                 cell lines. The GLM with fixed study effect performed well for
                 low inter-study variation and small numbers of studies, but
                 was outperformed by the meta-analysis methods for moderate to
                 large inter-study variability and larger numbers of studies.
                 CONCLUSIONS: The p-value combination techniques illustrated
                 here are a valuable tool to perform differential meta-analyses
                 of RNA-seq data by appropriately accounting for biological and
                 technical variability within studies as well as additional
                 study-specific effects. An R package metaRNASeq is available
                 on the CRAN
                 (http://cran.r-project.org/web/packages/metaRNASeq).},
  Journal     = {BMC bioinformatics},
  Volume      = {15},
  Pages       = {91},
  Month       = {03},
  Year        = {2014},
  Language    = {en},
  Issn        = {1471-2105},
  Pmid        = {24678608},
  Doi         = {10.1186/1471-2105-15-91},
  Pmc         = {PMC4021464}
}

@article{Danielsson2015-cn,
  Title    = {Assessing the consistency of public human tissue {RNA-seq} data
              sets},
  Author   = {Danielsson, Frida and James, Tojo and Gomez-Cabrero, David and
              Huss, Mikael},
  Abstract = {Sequencing-based gene expression methods like RNA-sequencing
              (RNA-seq) have become increasingly common, but it is often
              claimed that results obtained in different studies are not
              comparable owing to the influence of laboratory batch effects,
              differences in RNA extraction and sequencing library preparation
              methods and bioinformatics processing pipelines. It would be
              unfortunate if different experiments were in fact incomparable,
              as there is great promise in data fusion and meta-analysis
              applied to sequencing data sets. We therefore compared reported
              gene expression measurements for ostensibly similar samples
              (specifically, human brain, heart and kidney samples) in several
              different RNA-seq studies to assess their overall consistency and
              to examine the factors contributing most to systematic
              differences. The same comparisons were also performed after
              preprocessing all data in a consistent way, eliminating potential
              bias from bioinformatics pipelines. We conclude that published
              human tissue RNA-seq expression measurements appear relatively
              consistent in the sense that samples cluster by tissue rather
              than laboratory of origin given simple preprocessing
              transformations. The article is supplemented by a detailed
              walkthrough with embedded R code and figures.},
  Journal  = {Briefings in bioinformatics},
  Volume   = {16},
  Number   = {6},
  Pages    = {941--949},
  Month    = {11},
  Year     = {2015},
  Keywords = {RNA-seq; clustering; gene expression; meta-analysis; public data},
  Language = {en},
  Issn     = {1467-5463, 1477-4054},
  Pmid     = {25829468},
  Doi      = {10.1093/bib/bbv017},
  Pmc      = {PMC4652619}
}


@article{De_Siqueira_Santos2014-dp,
  Title     = {A comparative study of statistical methods used to identify
               dependencies between gene expression signals},
  Author    = {de Siqueira Santos, Suzana and Takahashi, Daniel Yasumasa and
               Nakata, Asuka and Fujita, André},
  Abstract  = {One major task in molecular biology is to understand the
               dependency among genes to model gene regulatory networks.
               Pearson's correlation is the most common method used to measure
               dependence between gene expression signals, but it works well
               only when data are linearly associated. For other types of
               association, such as non-linear or non-functional relationships,
               methods based on the concepts of rank correlation and
               information theory-based measures are more adequate than the
               Pearson's correlation, but are less used in applications, most
               probably because of a lack of clear guidelines for their use.
               This work seeks to summarize the main methods (Pearson's,
               Spearman's and Kendall's correlations; distance correlation;
               Hoeffding's D measure; Heller–Heller–Gorfine measure; mutual
               information and maximal information coefficient) used to
               identify dependency between random variables, especially gene
               expression data, and also to evaluate the strengths and
               limitations of each method. Systematic Monte Carlo simulation
               analyses ranging from sample size, local dependence and
               linear/non-linear and also non-functional relationships are
               shown. Moreover, comparisons in actual gene expression data are
               carried out. Finally, we provide a suggestive list of methods
               that can be used for each type of data set.},
  Journal   = {Briefings in bioinformatics},
  Publisher = {Oxford University Press},
  Volume    = {15},
  Number    = {6},
  Pages     = {906--918},
  Month     = {11},
  Year      = {2014},
  Issn      = {1467-5463},
  Doi       = {10.1093/bib/bbt051}
}

@article{Yu2015-uh,
  Title       = {Complementing tissue characterization by integrating
                 transcriptome profiling from the Human Protein Atlas and from
                 the {FANTOM5} consortium},
  Author      = {Yu, Nancy Yiu-Lin and Hallström, Björn M and Fagerberg, Linn
                 and Ponten, Fredrik and Kawaji, Hideya and Carninci, Piero and
                 Forrest, Alistair R R and {Fantom Consortium} and Hayashizaki,
                 Yoshihide and Uhlén, Mathias and Daub, Carsten O},
  Affiliation = {Department of Biosciences and Nutrition, Karolinska Institute,
                 Huddinge, 14183, Sweden Science for Life Laboratory,
                 Karolinska Institute, Solna, 17121, Sweden. Science for Life
                 Laboratory, KTH-Royal Institute of Technology, Solna, 17121,
                 Sweden. Science for Life Laboratory, KTH-Royal Institute of
                 Technology, Solna, 17121, Sweden. Department of Immunology,
                 Genetics and Pathology, Science for Life Laboratory, Uppsala
                 University, Uppsala, 751 85, Sweden. RIKEN Preventive Medicine
                 and Diagnosis Innovation Program, Wako, Saitama 351-0198,
                 Japan RIKEN Center for Life Science Technologies (CLST),
                 Division of Genomic Technologies, RIKEN Yokohama Institute,
                 Tsurumi-ku, Yokohama, 230-0045, Japan RIKEN Omics Science
                 Center1, Yokohama, Kanagawa, 230-0045, Japan. RIKEN Center for
                 Life Science Technologies (CLST), Division of Genomic
                 Technologies, RIKEN Yokohama Institute, Tsurumi-ku, Yokohama,
                 230-0045, Japan RIKEN Omics Science Center1, Yokohama,
                 Kanagawa, 230-0045, Japan. RIKEN Center for Life Science
                 Technologies (CLST), Division of Genomic Technologies, RIKEN
                 Yokohama Institute, Tsurumi-ku, Yokohama, 230-0045, Japan
                 RIKEN Omics Science Center1, Yokohama, Kanagawa, 230-0045,
                 Japan. RIKEN Center for Life Science Technologies (CLST),
                 Division of Genomic Technologies, RIKEN Yokohama Institute,
                 Tsurumi-ku, Yokohama, 230-0045, Japan RIKEN Omics Science
                 Center1, Yokohama, Kanagawa, 230-0045, Japan. RIKEN Preventive
                 Medicine and Diagnosis Innovation Program, Wako, Saitama
                 351-0198, Japan RIKEN Omics Science Center1, Yokohama,
                 Kanagawa, 230-0045, Japan. Science for Life Laboratory,
                 KTH-Royal Institute of Technology, Solna, 17121, Sweden.
                 Department of Biosciences and Nutrition, Karolinska Institute,
                 Huddinge, 14183, Sweden Science for Life Laboratory,
                 Karolinska Institute, Solna, 17121, Sweden RIKEN Center for
                 Life Science Technologies (CLST), Division of Genomic
                 Technologies, RIKEN Yokohama Institute, Tsurumi-ku, Yokohama,
                 230-0045, Japan RIKEN Omics Science Center1, Yokohama,
                 Kanagawa, 230-0045, Japan carsten.daub@ki.se.},
  Abstract    = {Understanding the normal state of human tissue transcriptome
                 profiles is essential for recognizing tissue disease states
                 and identifying disease markers. Recently, the Human Protein
                 Atlas and the FANTOM5 consortium have each published extensive
                 transcriptome data for human samples using Illumina-sequenced
                 RNA-Seq and Heliscope-sequenced CAGE. Here, we report on the
                 first large-scale complex tissue transcriptome comparison
                 between full-length versus 5'-capped mRNA sequencing data.
                 Overall gene expression correlation was high between the 22
                 corresponding tissues analyzed (R > 0.8). For genes
                 ubiquitously expressed across all tissues, the two data sets
                 showed high genome-wide correlation (91\% agreement), with
                 differences observed for a small number of individual genes
                 indicating the need to update their gene models. Among the
                 identified single-tissue enriched genes, up to 75\% showed
                 consensus of 7-fold enrichment in the same tissue in both
                 methods, while another 17\% exhibited multiple tissue
                 enrichment and/or high expression variety in the other data
                 set, likely dependent on the cell type proportions included in
                 each tissue sample. Our results show that RNA-Seq and CAGE
                 tissue transcriptome data sets are highly complementary for
                 improving gene model annotations and highlight biological
                 complexities within tissue transcriptomes. Furthermore,
                 integration with image-based protein expression data is highly
                 advantageous for understanding expression specificities for
                 many genes.},
  Journal     = {Nucleic Acids Research},
  Volume      = {43},
  Number      = {14},
  Pages       = {6787--6798},
  Month       = {08},
  Year        = {2015},
  Language    = {en},
  Issn        = {0305-1048, 1362-4962},
  Pmid        = {26117540},
  Doi         = {10.1093/nar/gkv608},
  Pmc         = {PMC4538815}
}


@article{Kryuchkova-Mostacci2017-mk,
  Title       = {A benchmark of gene expression tissue-specificity metrics},
  Author      = {Kryuchkova-Mostacci, Nadezda and Robinson-Rechavi, Marc},
  Affiliation = {Department of Ecology and Evolution, University of Lausanne,
                 Lausanne, Switzerland; Swiss Institute of Bioinformatics,
                 Lausanne, Switzerland. Department of Ecology and Evolution,
                 University of Lausanne, Lausanne, Switzerland; Swiss Institute
                 of Bioinformatics, Lausanne, Switzerland.},
  Abstract    = {One of the major properties of genes is their expression
                 pattern. Notably, genes are often classified as tissue
                 specific or housekeeping. This property is of interest to
                 molecular evolution as an explanatory factor of, e.g.
                 evolutionary rate, as well as a functional feature which may
                 in itself evolve. While many different methods of measuring
                 tissue specificity have been proposed and used for such
                 studies, there has been no comparison or benchmarking of these
                 methods to our knowledge, and little justification of their
                 use. In this study, we compare nine measures of tissue
                 specificity. Most methods were established for ESTs and
                 microarrays, and several were later adapted to RNA-seq. We
                 analyse their capacity to distinguish gene categories, their
                 robustness to the choice and number of tissues used and their
                 capture of evolutionary conservation signal.},
  Journal     = {Briefings in bioinformatics},
  Volume      = {18},
  Number      = {2},
  Pages       = {205--214},
  Month       = {03},
  Year        = {2017},
  Keywords    = {RNA-seq; expression; human; microarray; mouse; tissue
                 specificity},
  Language    = {en},
  Issn        = {1467-5463, 1477-4054},
  Pmid        = {26891983},
  Doi         = {10.1093/bib/bbw008},
  Pmc         = {PMC5444245}
}


@article{Kim2017-dz,
  Title       = {{TissGDB}: tissue-specific gene database in cancer},
  Author      = {Kim, Pora and Park, Aekyung and Han, Guangchun and Sun, Hua
                 and Jia, Peilin and Zhao, Zhongming},
  Affiliation = {Center for Precision Health, School of Biomedical Informatics,
                 The University of Texas Health Science Center at Houston,
                 Houston, TX 77030, USA. College of Pharmacy and Research
                 Institute of Life and Pharmaceutical Sciences, Sunchon
                 National University, Suncheon 57922, Korea. Human Genetics
                 Center, School of Public Health, The University of Texas
                 Health Science Center at Houston, Houston, TX 77030, USA.},
  Abstract    = {Tissue-specific gene expression is critical in understanding
                 biological processes, physiological conditions, and disease.
                 The identification and appropriate use of tissue-specific
                 genes (TissGenes) will provide important insights into disease
                 mechanisms and organ-specific therapeutic targets. To better
                 understand the tissue-specific features for each cancer type
                 and to advance the discovery of clinically relevant genes or
                 mutations, we built TissGDB (Tissue specific Gene DataBase in
                 cancer) available at http://zhaobioinfo.org/TissGDB. We
                 collected and curated 2461 tissue specific genes (TissGenes)
                 across 22 tissue types that matched the 28 cancer types of The
                 Cancer Genome Atlas (TCGA) from three representative
                 tissue-specific gene expression resources: The Human Protein
                 Atlas (HPA), Tissue-specific Gene Expression and Regulation
                 (TiGER), and Genotype-Tissue Expression (GTEx). For these 2461
                 TissGenes, we performed gene expression, somatic mutation, and
                 prognostic marker-based analyses across 28 cancer types using
                 TCGA data. Our analyses identified hundreds of TissGenes,
                 including genes that universally kept or lost tissue-specific
                 gene expression, with other features: cancer type-specific
                 isoform expression, fusion with oncogenes or tumor suppressor
                 genes, and markers for protective or risk prognosis. TissGDB
                 provides seven categories of annotations: TissGeneSummary,
                 TissGeneExp, TissGene-miRNA, TissGeneMut, TissGeneNet,
                 TissGeneProg, TissGeneClin.},
  Journal     = {Nucleic Acids Research},
  Month       = {09},
  Year        = {2017},
  Language    = {en},
  Issn        = {0305-1048, 1362-4962},
  Pmid        = {29036590},
  Doi         = {10.1093/nar/gkx850}
}

@article{Liang2006-mk,
  Title       = {Detecting and profiling tissue-selective genes},
  Author      = {Liang, Shuang and Li, Yizheng and Be, Xiaobing and Howes,
                 Steve and Liu, Wei},
  Affiliation = {Bioinformatics, Wyeth Research, Cambridge, Massachusetts
                 02140, USA.},
  Abstract    = {The widespread use of DNA microarray technologies has
                 generated large amounts of data from various tissue and/or
                 cell types. These data set the stage to answer the question of
                 tissue specificity of human transcriptome in a comprehensive
                 manner. Our focus is to uncover the tissue-gene relationship
                 by identifying genes that are preferentially expressed in a
                 small number of tissue types. The tissue selectivity would
                 shed light on the potential physiological functions of these
                 genes and provides an indispensable reference to compare
                 against disease pathophysiology and to identify or validate
                 tissue-specific drug targets. Here we describe a systematic
                 computational and statistical approach to profile gene
                 expression data to identify tissue-selective genes with the
                 use of a more extensive data set and a well-established
                 multiple-comparison procedure with error rate control.
                 Expression data of 35,152 probe sets in 97 normal human tissue
                 types were analyzed, and 3,919 genes were identified to be
                 selective to one or a few tissue types. We presented results
                 of these tissue-selective genes and compared them to those
                 identified by other studies.},
  Journal     = {Physiological Genomics},
  Volume      = {26},
  Number      = {2},
  Pages       = {158--162},
  Month       = {07},
  Year        = {2006},
  Language    = {en},
  Issn        = {1094-8341, 1531-2267},
  Pmid        = {16684803},
  Doi         = {10.1152/physiolgenomics.00313.2005}
}


@ARTICLE{Cavalli2011-bo,
  title       = "{SpeCond}: a method to detect condition-specific gene
                 expression",
  author      = "Cavalli, Florence M G and Bourgon, Richard and Huber, Wolfgang
                 and Vaquerizas, Juan M and Luscombe, Nicholas M",
  affiliation = "EMBL-European Bioinformatics Institute, Wellcome Trust Genome
                 Campus, Cambridge CB10 1SD, UK. florence@ebi.ac.uk",
  abstract    = "Transcriptomic studies routinely measure expression levels
                 across numerous conditions. These datasets allow
                 identification of genes that are specifically expressed in a
                 small number of conditions. However, there are currently no
                 statistically robust methods for identifying such genes. Here
                 we present SpeCond, a method to detect condition-specific
                 genes that outperforms alternative approaches. We apply the
                 method to a dataset of 32 human tissues to determine 2,673
                 specifically expressed genes. An implementation of SpeCond is
                 freely available as a Bioconductor package at
                 http://www.bioconductor.org/packages/release/bioc/html/SpeCond.html.",
  journal     = "Genome biology",
  volume      =  12,
  number      =  10,
  pages       = "R101",
  month       =  oct,
  year        =  2011,
  language    = "en",
  issn        = "1465-6906",
  pmid        = "22008066",
  doi         = "10.1186/gb-2011-12-10-r101",
  pmc         = "PMC3333772"
}


@ARTICLE{Xiao2010-mz,
  title       = "{TiSGeD}: a database for tissue-specific genes",
  author      = "Xiao, Sheng-Jian and Zhang, Chi and Zou, Quan and Ji,
                 Zhi-Liang",
  affiliation = "Key Laboratory for Cell Biology and Tumor Cell Engineering,
                 the Ministry of Education of China, School of Life Sciences,
                 Fujian, P R China.",
  abstract    = "UNLABELLED: The tissue-specific genes are a group of genes
                 whose function and expression are preferred in one or several
                 tissues/cell types. Identification of these genes helps better
                 understanding of tissue-gene relationship, etiology and
                 discovery of novel tissue-specific drug targets. In this
                 study, a statistical method is introduced to detect
                 tissue-specific genes from more than 123 125 gene expression
                 profiles over 107 human tissues, 67 mouse tissues and 30 rat
                 tissues. As a result, a novel subject-specialized repository,
                 namely the tissue-specific genes database (TiSGeD), is
                 developed to represent the analyzed results. Auxiliary
                 information of tissue-specific genes was also collected from
                 biomedical literatures. AVAILABILITY:
                 http://bioinf.xmu.edu.cn/databases/TiSGeD/index.html.",
  journal     = "Bioinformatics",
  volume      =  26,
  number      =  9,
  pages       = "1273--1275",
  month       =  may,
  year        =  2010,
  language    = "en",
  issn        = "1367-4803, 1367-4811",
  pmid        = "20223836",
  doi         = "10.1093/bioinformatics/btq109",
  pmc         = "PMC2859128"
}


@ARTICLE{Karthik2016-mu,
  title       = "Elucidating tissue specific genes using the Benford
                 distribution",
  author      = "Karthik, Deepak and Stelzer, Gil and Gershanov, Sivan and
                 Baranes, Danny and Salmon-Divon, Mali",
  affiliation = "Department of Molecular Biology, Ariel University, Ariel,
                 40700, Israel. Department of Molecular Biology, Ariel
                 University, Ariel, 40700, Israel. Department of Molecular
                 Biology, Ariel University, Ariel, 40700, Israel. Department of
                 Molecular Biology, Ariel University, Ariel, 40700, Israel.
                 Department of Molecular Biology, Ariel University, Ariel,
                 40700, Israel. malisa@ariel.ac.il.",
  abstract    = "BACKGROUND: The RNA-seq technique is applied for the
                 investigation of transcriptional behaviour. The reduction in
                 sequencing costs has led to an unprecedented trove of gene
                 expression data from diverse biological systems. Subsequently,
                 principles from other disciplines such as the Benford law,
                 which can be properly judged only in data-rich systems, can
                 now be examined on this high-throughput transcriptomic
                 information. The Benford law, states that in many count-rich
                 datasets the distribution of the first significant digit is
                 not uniform but rather logarithmic. RESULTS: All tested
                 digital gene expression datasets showed a Benford-like
                 distribution when observing an entire gene set. This
                 phenomenon was conserved in development and does not
                 demonstrate tissue specificity. However, when obedience to the
                 Benford law is calculated for individual expressed genes
                 across thousands of cells, genes that best and least adhere to
                 the Benford law are enriched with tissue specific or cell
                 maintenance descriptors, respectively. Surprisingly, a
                 positive correlation was found between the obedience a gene
                 exhibits to the Benford law and its expression level, despite
                 the former being calculated solely according to first digit
                 frequency while totally ignoring the expression value itself.
                 Nevertheless, genes with low expression that exhibit Benford
                 behavior demonstrate tissue specific associations. These
                 observations were extended to predict the likelihood of tissue
                 specificity based on Benford behaviour in a supervised
                 learning approach. CONCLUSIONS: These results demonstrate the
                 applicability and potential predictability of the Benford law
                 for gleaning biological insight from simple count data.",
  journal     = "BMC genomics",
  volume      =  17,
  pages       = "595",
  month       =  aug,
  year        =  2016,
  keywords    = "Benford law; Gene expression; RNA-seq",
  language    = "en",
  issn        = "1471-2164",
  pmid        = "27506195",
  doi         = "10.1186/s12864-016-2921-x",
  pmc         = "PMC4979126"
}


@ARTICLE{tiger,
  title       = "{TiGER}: a database for tissue-specific gene expression and
                 regulation",
  author      = "Liu, Xiong and Yu, Xueping and Zack, Donald J and Zhu, Heng
                 and Qian, Jiang",
  affiliation = "Wilmer Institute, Johns Hopkins University School of Medicine,
                 Maumenee Building 844, 600 N, Wolfe Street, Baltimore, MD
                 21287, USA. xliu09@gmail.com",
  abstract    = "BACKGROUND: Understanding how genes are expressed and
                 regulated in different tissues is a fundamental and
                 challenging question. However, most of currently available
                 biological databases do not focus on tissue-specific gene
                 regulation. RESULTS: The recent development of computational
                 methods for tissue-specific combinational gene regulation,
                 based on transcription factor binding sites, enables us to
                 perform a large-scale analysis of tissue-specific gene
                 regulation in human tissues. The results are stored in a web
                 database called TiGER (Tissue-specific Gene Expression and
                 Regulation). The database contains three types of data
                 including tissue-specific gene expression profiles,
                 combinatorial gene regulations, and cis-regulatory module
                 (CRM) detections. At present the database contains expression
                 profiles for 19,526 UniGene genes, combinatorial regulations
                 for 7,341 transcription factor pairs and 6,232 putative CRMs
                 for 2,130 RefSeq genes. CONCLUSION: We have developed and made
                 publicly available a database, TiGER, which summarizes and
                 provides large scale data sets for tissue-specific gene
                 expression and regulation in a variety of human tissues. This
                 resource is available at 1.",
  journal     = "BMC bioinformatics",
  volume      =  9,
  pages       = "271",
  month       =  jun,
  year        =  2008,
  language    = "en",
  issn        = "1471-2105",
  pmid        = "18541026",
  doi         = "10.1186/1471-2105-9-271",
  pmc         = "PMC2438328"
}


@article{Jiang2016-sv,
  Title    = {Identifying and functionally characterizing tissue-specific and
              ubiquitously expressed human {lncRNAs}},
  Author   = {Jiang, Chunjie and Li, Yongsheng and Zhao, Zheng and Lu, Jianping
              and Chen, Hong and Ding, Na and Wang, Guangjuan and Xu, Juan and
              Li, Xia},
  Abstract = {Recent advances in transcriptome sequencing have made it possible
              to distinguish ubiquitously expressed long non-coding RNAs (UE
              lncRNAs) from tissue-specific lncRNAs (TS lncRNAs), thereby
              providing clues to their cellular functions. Here, we assembled
              and functionally characterized a consensus lncRNA transcriptome
              by curating hundreds of RNA-seq datasets across normal human
              tissues from 16 independent studies. In total, 1,184 UE and 2,583
              TS lncRNAs were identified. These different lncRNA populations
              had several distinct features. Specifically, UE lncRNAs were
              associated with genomic compaction and highly conserved exons and
              promoter regions. We found that UE lncRNAs are regulated at the
              transcriptional level (with especially strong regulation of
              enhancers) and are associated with epigenetic modifications and
              post-transcriptional regulation. Based on these observations we
              propose a novel way to predict the functions of UE and TS lncRNAs
              through analysis of their genomic location and similarities in
              epigenetic modifications. Our characterization of UE and TS
              lncRNAs may provide a foundation for lncRNA genomics and the
              delineation of complex disease mechanisms.},
  Journal  = {Oncotarget},
  Volume   = {7},
  Number   = {6},
  Pages    = {7120--7133},
  Month    = {02},
  Year     = {2016},
  Keywords = {epigenetic regulation; functional prediction; genomic structure;
              tissue-specific lncRNAs; ubiquitously expressed lncRNAs},
  Language = {en},
  Issn     = {1949-2553},
  Pmid     = {26760768},
  Doi      = {10.18632/oncotarget.6859},
  Pmc      = {PMC4872773}
}



@article{Hampel1974,
  Title     = {The Influence Curve and its Role in Robust Estimation},
  Author    = {Hampel, Frank R},
  Abstract  = {Abstract This paper treats essentially the first derivative of
               an estimator viewed as functional and the ways in which it can
               be used to study local robustness properties. A theory of robust
               estimation ?near? strict parametric models is briefly sketched
               and applied to some classical situations. Relations between von
               Mises functionals, the jackknife and U-statistics are indicated.
               A number of classical and new estimators are discussed,
               including trimmed and Winsorized means, Huber-estimators, and
               more generally maximum likelihood and M-estimators. Finally, a
               table with some numerical robustness properties is given.},
  Journal   = {Journal of the American Statistical Association},
  Publisher = {Taylor \& Francis},
  Volume    = {69},
  Number    = {346},
  Pages     = {383--393},
  Month     = {06},
  Year      = {1974},
  Issn      = {0162-1459},
  Doi       = {10.1080/01621459.1974.10482962}
}


@article{Kadota2006-eb,
  Title    = {{ROKU}: a novel method for identification of tissue-specific
              genes},
  Author   = {Kadota, Koji and Ye, Jiazhen and Nakai, Yuji and Terada, Tohru
              and Shimizu, Kentaro},
  Abstract = {BACKGROUND: One of the important goals of microarray research is
              the identification of genes whose expression is considerably
              higher or lower in some tissues than in others. We would like to
              have ways of identifying such tissue-specific genes. RESULTS: We
              describe a method, ROKU, which selects tissue-specific patterns
              from gene expression data for many tissues and thousands of
              genes. ROKU ranks genes according to their overall tissue
              specificity using Shannon entropy and detects tissues specific to
              each gene if any exist using an outlier detection method. We
              evaluated the capacity for the detection of various specific
              expression patterns using synthetic and real data. We observed
              that ROKU was superior to a conventional entropy-based method in
              its ability to rank genes according to overall tissue specificity
              and to detect genes whose expression pattern are specific only to
              objective tissues. CONCLUSION: ROKU is useful for the detection
              of various tissue-specific expression patterns. The framework is
              also directly applicable to the selection of diagnostic markers
              for molecular classification of multiple classes.},
  Journal  = {BMC Bioinformatics},
  Volume   = {7},
  Pages    = {294},
  Month    = {06},
  Year     = {2006},
  Language = {en},
  Issn     = {1471-2105},
  Pmid     = {16764735},
  Doi      = {10.1186/1471-2105-7-294},
  Pmc      = {PMC1501047}
}


@ARTICLE{Yu2006-ha,
  title    = "Computational analysis of tissue-specific combinatorial gene
              regulation: predicting interaction between transcription factors
              in human tissues",
  author   = "Yu, Xueping and Lin, Jimmy and Zack, Donald J and Qian, Jiang",
  abstract = "Tissue-specific gene expression is generally regulated by more
              than a single transcription factor (TF). Multiple TFs work in
              concert to achieve tissue specificity. In order to explore these
              complex TF interaction networks, we performed a large-scale
              analysis of TF interactions for 30 human tissues. We first
              identified tissue-specific genes for 30 tissues based on gene
              expression databases. We then evaluated the relationships between
              TFs using the relative position and co-occurrence of their
              binding sites in the promoters of tissue-specific genes. The
              predicted TF-TF interactions were validated by both known
              protein-protein interactions and co-expression of their target
              genes. We found that our predictions are enriched in known
              protein-protein interactions (>80 times that of random
              expectation). In addition, we found that the target genes show
              the highest co-expression in the tissue of interest. Our findings
              demonstrate that non-tissue specific TFs play a large role in
              regulation of tissue-specific genes. Furthermore, they show that
              individual TFs can contribute to tissue specificity in different
              tissues by interacting with distinct TF partners. Lastly, we
              identified several tissue-specific TF clusters that may play
              important roles in tissue-specific gene regulation.",
  journal  = "Nucleic acids research",
  volume   =  34,
  number   =  17,
  pages    = "4925--4936",
  month    =  sep,
  year     =  2006,
  language = "en",
  issn     = "0305-1048, 1362-4962",
  pmid     = "16982645",
  doi      = "10.1093/nar/gkl595",
  pmc      = "PMC1635265"
}



@ARTICLE{Zhu2016-xo,
  title     = "Identification of {Tissue-Specific} {Protein-Coding} and
               Noncoding Transcripts across 14 Human Tissues Using {RNA-seq}",
  author    = "Zhu, Jinhang and Chen, Geng and Zhu, Sibo and Li, Suqing and
               Wen, Zhuo and {Bin Li} and Zheng, Yuanting and Shi, Leming",
  abstract  = "Many diseases and adverse drug reactions exhibit tissue
               specificity. To better understand the tissue-specific expression
               characteristics of transcripts in different human tissues, we
               deeply sequenced RNA samples from 14 different human tissues.
               After filtering many lowly expressed transcripts, 24,729
               protein-coding transcripts and 1,653 noncoding transcripts were
               identified. By analyzing highly expressed tissue-specific
               protein-coding transcripts (TSCTs) and noncoding transcripts
               (TSNTs), we found that testis expressed the highest numbers of
               TSCTs and TSNTs. Brain, monocytes, ovary, and heart expressed
               more TSCTs than the rest tissues, whereas brain, placenta,
               heart, and monocytes expressed more TSNTs than other tissues.
               Co-expression network constructed based on the TSCTs and TSNTs
               showed that each hub TSNT was co-expressed with several TSCTs,
               allowing functional annotation of TSNTs. Important biological
               processes and KEGG pathways highly related to the specific
               functions or diseases of each tissue were enriched with the
               corresponding TSCTs. These TSCTs and TSNTs may participate in
               the tissue-specific physiological or pathological processes. Our
               study provided a unique data set and systematic analysis of
               expression characteristics and functions of both TSCTs and TSNTs
               based on 14 distinct human tissues, and could facilitate future
               investigation of the mechanisms behind tissue-specific diseases
               and adverse drug reactions.",
  journal   = "Scientific Reports",
  publisher = "Nature Publishing Group",
  volume    =  6,
  pages     = "28400",
  month     =  jun,
  year      =  2016,
  language  = "en",
  issn      = "2045-2322, 2045-2322",
  pmid      = "27329541",
  doi       = "10.1038/srep28400",
  pmc       = "PMC4916594"
}



@ARTICLE{Martinez2008-bm,
  title    = "Defining diversity, specialization, and gene specificity in
              transcriptomes through information theory",
  author   = "Martínez, Octavio and Reyes-Valdés, M Humberto",
  abstract = "The transcriptome is a set of genes transcribed in a given tissue
              under specific conditions and can be characterized by a list of
              genes with their corresponding frequencies of transcription.
              Transcriptome changes can be measured by counting gene tags from
              mRNA libraries or by measuring light signals in DNA microarrays.
              In any case, it is difficult to completely comprehend the global
              changes that occur in the transcriptome, given that thousands of
              gene expression measurements are involved. We propose an approach
              to define and estimate the diversity and specialization of
              transcriptomes and gene specificity. We define transcriptome
              diversity as the Shannon entropy of its frequency distribution.
              Gene specificity is defined as the mutual information between the
              tissues and the corresponding transcript, allowing detection of
              either housekeeping or highly specific genes and clarifying the
              meaning of these concepts in the literature. Tissue
              specialization is measured by average gene specificity. We
              introduce the formulae using a simple example and show their
              application in two datasets of gene expression in human tissues.
              Visualization of the positions of transcriptomes in a system of
              diversity and specialization coordinates makes it possible to
              understand at a glance their interrelations, summarizing in a
              powerful way which transcriptomes are richer in diversity of
              expressed genes, or which are relatively more specialized. The
              framework presented enlightens the relation among transcriptomes,
              allowing a better understanding of their changes through the
              development of the organism or in response to environmental
              stimuli.",
  journal  = "Proceedings of the National Academy of Sciences of the United
              States of America",
  volume   =  105,
  number   =  28,
  pages    = "9709--9714",
  month    =  jul,
  year     =  2008,
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "18606989",
  doi      = "10.1073/pnas.0803479105",
  pmc      = "PMC2443819"
}



@ARTICLE{Anders2010-vq,
  title    = "Differential expression analysis for sequence count data",
  author   = "Anders, Simon and Huber, Wolfgang",
  abstract = "High-throughput sequencing assays such as RNA-Seq, ChIP-Seq or
              barcode counting provide quantitative readouts in the form of
              count data. To infer differential signal in such data correctly
              and with good statistical power, estimation of data variability
              throughout the dynamic range and a suitable error model are
              required. We propose a method based on the negative binomial
              distribution, with variance and mean linked by local regression
              and present an implementation, DESeq, as an R/Bioconductor
              package.",
  journal  = "Genome biology",
  volume   =  11,
  number   =  10,
  pages    = "R106",
  month    =  oct,
  year     =  2010,
  language = "en",
  issn     = "1465-6906",
  pmid     = "20979621",
  doi      = "10.1186/gb-2010-11-10-r106",
  pmc      = "PMC3218662"
}


@ARTICLE{Soneson2013-pd,
  title    = "A comparison of methods for differential expression analysis of
              {RNA-seq} data",
  author   = "Soneson, Charlotte and Delorenzi, Mauro",
  abstract = "BACKGROUND: Finding genes that are differentially expressed
              between conditions is an integral part of understanding the
              molecular basis of phenotypic variation. In the past decades, DNA
              microarrays have been used extensively to quantify the abundance
              of mRNA corresponding to different genes, and more recently
              high-throughput sequencing of cDNA (RNA-seq) has emerged as a
              powerful competitor. As the cost of sequencing decreases, it is
              conceivable that the use of RNA-seq for differential expression
              analysis will increase rapidly. To exploit the possibilities and
              address the challenges posed by this relatively new type of data,
              a number of software packages have been developed especially for
              differential expression analysis of RNA-seq data. RESULTS: We
              conducted an extensive comparison of eleven methods for
              differential expression analysis of RNA-seq data. All methods are
              freely available within the R framework and take as input a
              matrix of counts, i.e. the number of reads mapping to each
              genomic feature of interest in each of a number of samples. We
              evaluate the methods based on both simulated data and real
              RNA-seq data. CONCLUSIONS: Very small sample sizes, which are
              still common in RNA-seq experiments, impose problems for all
              evaluated methods and any results obtained under such conditions
              should be interpreted with caution. For larger sample sizes, the
              methods combining a variance-stabilizing transformation with the
              'limma' method for differential expression analysis perform well
              under many different conditions, as does the nonparametric SAMseq
              method.",
  journal  = "BMC bioinformatics",
  volume   =  14,
  pages    = "91",
  month    =  mar,
  year     =  2013,
  language = "en",
  issn     = "1471-2105",
  pmid     = "23497356",
  doi      = "10.1186/1471-2105-14-91",
  pmc      = "PMC3608160"
}


