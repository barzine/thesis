%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\RequirePackage{nag}
\documentclass[a4paper, headinclude, footinclude, BCOR=1cm]{scrbook}
\KOMAoptions{headsepline = true, footsepline = false}

\input{config.tex}
\input{glossary.tex}

%\RequirePackage{enumitem}
%\SetLabelAlign{myright}{\hss\llap{$#1$}}
%\newlist{where}{description}{1}
%\setlist[where]{labelwidth=2cm,labelsep=1em,
%                        leftmargin=!,align=myright,font=\normalfont}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\title{Formulas: many different formulas that have been typeset already}
\author{Mitra Barzine}
\maketitle

\begin{comment}

\begin{equation}
  \tag{}
\end{equation}
where:
\quad\begin{eqlist}
    \item[\textbullet\ ]
\end{eqlist}

\end{comment}

\chapter{Stats}
\section{The expectation}
\begin{equation}\label{eq:expectation}
    \tag{Expectation}
    \begin{split}
E[X] & = x_1p_1 + x_2p_2+ \cdot +x_kp_k \\
     & = weighted average(X) \\
     & = \mu_X
 \end{split}
\end{equation}
where:%\\
\quad\begin{eqlist}
    \item[\textbullet\ $E$] is the expectation
    \item[\textbullet\ $X$] is a random variable
    \item[\textbullet\ $x_1$, $x_2$, \ldots, $x_k$] are possible value of $X$
    \item[\textbullet\ $p_1$, $p_2$, \ldots, $p_k$] are the probabilities of the different
        values of $X$ and their sum is equal to 1.
    \item[\textbullet\ $\mu_X$] is the theoretical average of X
\end{eqlist}


\section{The variance}

\begin{equation}\label{eq:variance}
  \tag{Variance}
  \begin{split}
    Var(X) & =  \frac{\sum{(x_{i}-\bar{x})^{2}}}{N-1} \\ & = sd^{2}(X) \\
           & = E[X^2] - E[X]^2
  \end{split}
\end{equation}
where:
\quad\begin{eqlist}
    \item[\textbullet\ $X$] is a random variable
    \item[\textbullet\ $x$] is one observation of $X$
    \item[\textbullet\ $\bar{x}$] is the mean of all observed values of $X$
    \item[\textbullet\ $N$] is the number of observations of $X$
    \item[\textbullet\ $sd^2$] is another notation of the variance as
        the standard deviation is equal to the square root of the variance.
    \item[\textbullet\ ${E[X], E[X^2]}$] are respectively the expectation of $X$ and $X^2$
\end{eqlist}


\section{The covariance}

The covariance is the measure of the joint variability of two random variables,
\eg\ $X$ and $Y$.
Specifically, it allows quantifying the degree to which
two variables are linearly associated.

\begin{equation}
  \tag{Covariance}
  cov(X,Y) =  \frac{\sum{(x_{i}-\bar{x})(y_{i}-\bar{y})}}{N-1}
\end{equation}
where:
\quad\begin{eqlist}
    \item[\textbullet\ $X,Y$] are random variables
    \item[\textbullet\ $x,y$] are respectively one observation of $X$ and $Y$
    \item[\textbullet\ $\bar{x},\bar{y}$] are the means
        of all observed values of $X$ and $Y$
    \item[\textbullet\ $N$] is the number of observations of $X$ and $Y$
\end{eqlist}

\begin{equation}
    \tag{Sample Pearson correlation}
    \begin{split}
    r_{xy} & = \frac{\sum ^n _{i=1}(x_i - \bar{x})(y_i - \bar{y})}%
    {\sqrt{\sum ^n _{i=1}(x_i - \bar{x})^2} \sqrt{\sum ^n _{i=1}(y_i - \bar{y})^2}}\\
           & = \frac{\sum\limits_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})}
            {\sqrt{\sum\limits_{i=1}^n (x_i-\bar{x})^2 \sum\limits_{i=1}^n (y_i-\bar{y})^2}}
    \end{split}
    %\frac{\sum\limits_{i=1}^n (x_i-\bar{x})(y_i-\bar{y})}{(n-1)s_x s_y}
\end{equation}
where:
\quad\begin{eqlist}
    \item[\textbullet\ $X,Y$] are random variables
    \item[\textbullet\ $x,y$] are respectively one observation of $X$ and $Y$
    \item[\textbullet\ $\bar{x},\bar{y}$] are the means
        of all observed values of $X$ and $Y$
    \item[\textbullet\ $n$] is the number of observations of $X$ and $Y$
\end{eqlist}

\chapter{Other}

\section{canonical RPKM formula}

\begin{equation}
     \tag{Canonical RPKM formula}\label{eq:rpkm-fx}
 \hat{\mu}_{ij} = \frac{f_i}{F_j\cdot10^{-6} \cdot \ell_i\cdot10^{-3}}
                = \frac{f_i}{F_j\cdot\ell_i}\cdot10^{9} \text{\,}
 \end{equation}

 where: \\{\small
 $\hat{\mu}_{ij}$ is the normalised expression for \emph{feature} (\eg\ gene or
 transcript) $i$ in sample $j$,\\
 $f_i$ is the count number of the fragments (or reads) mapped to
 \emph{feature} $i$ in sample $j$,\\
 $F_j$ is the total count number of all the fragments (or reads) mapped in
 sample $j$,\\
 $\ell_i$ is the length of \emph{feature} $i$.
 }






\end{document}


