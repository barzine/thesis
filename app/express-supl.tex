\chapter[Supp. material for chap. \getrefnumber{ch:expression}]%
{Supplementary material for Chapter \getrefnumber{ch:expression}}
\label{ch:SupplExpress}
\chaptermark{Supplementary material for Chapter \getrefnumber{ch:expression}}

\section{Correlation}\label{sec:CorrMore}
Correlation can be considered as a scaled version of the covariance
(\Cref{eq:covariance}) of two random variables.
Correlation coefficients are adimensional and varie in a restricted range $[-1,1]$.
While $1$ and $-1$ mean a perfect correlation (either positive or negative),
a value equals to $0$ expresses that the two variables are independent.
A value within $\mathopen]-1,0\mathclose[$
or $\mathopen]0,1\mathclose[$ needs more interpretation. In biology, if the
coefficient is within $[-0.5,0.5]$, the variables are often considered as
independent.

\emph{Spearman} and \emph{Pearson} are only two methods to compute correlations
among other ones.
%Albeit, they are the two most popular ones in Biology.

\subsection{Spearman correlation}\label{subsec:SpearmanCor}
The Spearman correlation coefficient (usually noted as $\rho$)
is more robust than the Pearson correlation.
However, it only assesses the monotonic dependence between two variables.
The Spearman correlation coefficient is defined
as the Pearson correlation of the \emph{ranked values} of two variables.
Spearman correlations are widely used
within the literature for biological studies~\mycite{VTpaper,Uhlen2014,Danielsson2015-cn,Yu2015-uh}.

\subsection{Pearson correlation}\label{subsec:PearsonCor}
The Pearson correlation coefficient (usually noted as $r$) assesses the linear
dependence between two variables.
It is invariant to systematic addition of a constant
or to simple scaling factors between the two variables.


The correlation coefficients computed for this thesis rely on the \emph{Sample
correlation coefficient} (as opposed to the \emph{Population}
formula --- see \cref{eq:PearsonPopCor}).

The (sample) Pearson correlation coefficient can be defined
as the following equation
(indeed, many rearrangements are possible) :
\begin{equation}\label{eq:PearsonCor}
    \tag{(Sample) Pearson correlation coefficient}
    \begin{split}
        r_{x,y} & = \frac{\sum ^n _{i=1}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum ^n _{i=1}(x_i - \bar{x})^2}
        \sqrt{\sum ^n _{i=1}(y_i - \bar{y})^2}} \\
                & = corr(x,y)
    \end{split}
\end{equation}
where:
\quad\begin{eqlist}
    \item[\textbullet\ $x,y$] are observed values of two random variables $X$ and $Y$
    \item[\textbullet\ $n$] is the sample size of $x$ and $y$
    \item[\textbullet\ $i$] is the index of the current observed value $x$ or $y$
    \item[\textbullet\ $\bar{x}, \bar{y}$] are respectively the sample ($x$ and $y$) means (see \Cref{eq:mean})
    \item[\textbullet\ $corr(X,Y)$] is another notation of $r_{x,y}$
\end{eqlist}

\begin{equation}\label{eq:mean}
    \tag{Mean}
    \bar{x}=\frac{1}{n}\sum_{i=1}^n x_i
\end{equation}
where:
\quad\begin{eqlist}
    \item[\textbullet\ $x$] is the possible observed values of $X$
    \item[\textbullet\ $n$] is the sample size of $x$
    \item[\textbullet\ $i$] is the index of the current observed value of $x$
\end{eqlist}


\subsection{Different advantages of Pearson and Spearman correlations}\label{subsec:PearsonVsSpearman}

Pearson correlations are easier to understand, interpret and then to use as predictor
while Spearman correlations are more robust and thus better fitted for interstudy
comparisons.
Computationally, correlations (Spearman in particular) can be challenging to compute,
especially for large matrices such as gene expression matrices \mycite{Wang2014-xd}.

\begin{comment}
Spearman correlations report on the strength and direction
of a monotonic relationship (specifically for ordinal data i.e.\ ranks)
between two variables.
It can also be used on interval or ratio data
even though Pearson correlation are usually better fitted to these kinds of data.
Pearson correlation measure the linear relationship between two variables
(interval scale) (true value).
\end{comment}

\cite{De_Siqueira_Santos2014-dp} review Spearman and Pearson correlations
along with six other statistical methods.
They also summarise many use cases of each of these methods
in the general context of gene expression study.

\section{Data visualisation}
%\subsection{Unlogged expression profiles}
\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{0.35\textwidth}
        \centering \includegraphics[width=\textwidth]{expressed/density_noLog2/castle.pdf}
        \caption{Castle}\label{fig:densityCastle_nolog2}
    \end{subfigure}%
~%
    \begin{subfigure}[b]{0.35\textwidth}
        \centering \includegraphics[width=\textwidth]{expressed/density_noLog2/vt.pdf}
        \caption{Brawand}\label{fig:densityBrawand_nolog2}
    \end{subfigure}

    \begin{subfigure}[b]{0.35\textwidth}
        \centering \includegraphics[width=\textwidth]{expressed/density_noLog2/ibm.pdf}
        \caption{Illumina Body Map}\label{fig:densityIBM_nolog2}
    \end{subfigure}%
~%
    \begin{subfigure}[b]{0.35\textwidth}
        \centering \includegraphics[width=\textwidth]{expressed/density_noLog2/uhlen.pdf}
        \caption{Uhlen}\label{fig:densityUhlen_nolog2}
    \end{subfigure}

    \begin{subfigure}[b]{0.35\textwidth}
        \centering \includegraphics[width=\textwidth]{expressed/density_noLog2/gtex.pdf}
        \caption{Gtex}\label{fig:densityGtex_nolog2}
    \end{subfigure}%
~%
    \begin{subfigure}[b]{0.35\textwidth}
        \centering \includegraphics[width=\textwidth]{expressed/density_noLog2/cutler.pdf}
        \caption{Cutler}\label{fig:densityCutler_nolog2}
    \end{subfigure}

    \begin{subfigure}[b]{0.35\textwidth}
        \centering \includegraphics[width=\textwidth]{expressed/density_noLog2/kuster.pdf}
        \caption{Kuster}\label{fig:densityKuster_nolog2}
    \end{subfigure}%
~%
    \begin{subfigure}[b]{0.35\textwidth}
        \centering \includegraphics[width=\textwidth]{expressed/density_noLog2/pandey.pdf}
        \caption{Pandey}\label{fig:densityPandey_nolog2}
    \end{subfigure}
    \caption{Profile of expression across the transcriptome (protein coding
    genes only) and proteome datasets}\label{fig:distribPlot_noLog2}
\end{figure}

%\subsection{Anscombe quartet}

\begin{figure}[!ht]
    \includegraphics[scale=0.40]{expressed/AnscombePanel.pdf}\centering
    \caption[Anscombe quartet --- why data should always visualy checked]
    {\label{fig:Anscombe}\textbf{Anscombe quartet --- why data should always
    visually checked.}\smallbreak{} All the datasets, while presenting
    different distribution, have equal or very similar descriptive statistic
    indicators. Their means and variances (for both $x$ and $y$ variables),
    their Pearson correlation between $x$ and $y$,
    as their linear regressions are very similar when not equal.}
\end{figure}


\section{Other additional material}


The population correlation coefficient ($\rho$) of two random variable $X$ and $Y$
is defined as:
\begin{equation}\label{eq:PearsonPopCor}
     \tag{Population correlation coefficient}
     \begin{split}
         \rho_{X,Y} & = \frac{cov(X,Y)}{\sigma_X \sigma_Y}\\
                    & = corr(X,Y)
     \end{split}
\end{equation}
where:
\quad\begin{eqlist}
    \item[\textbullet\ $X,Y$] are two random variables
    \item[\textbullet\ $cov(X,Y)$] is the covariance of $X$ and $Y$
        (see \Cref{eq:covariance})
    \item[\textbullet\ $\sigma_{X},\sigma_{Y}$] are the standard deviations
        of $X$ and $Y$ (see \Cref{eq:sd})
    \item[\textbullet\ $corr(X,Y)$] is another notation of $\rho_{X,Y}$
\end{eqlist}

The covariance is the measure of the joint variability of two random variables,
\eg\ $X$ and $Y$.
Specifically, it allows quantifying the degree to which
two variables are linearly associated.

\begin{equation}
    \tag{Covariance}\label{eq:covariance}
        cov(X,Y) =  \frac{\sum{(x_{i}-\bar{x})(y_{i}-\bar{y})}}{N-1}
\end{equation}
where:
\quad\begin{eqlist}
       \item[\textbullet\ $X,Y$] are random variables
       \item[\textbullet\ $x,y$] are respectively one observation of $X$ and $Y$
       \item[\textbullet\ $\bar{x},\bar{y}$] are the means
           of all observed values of $X$ and $Y$
       \item[\textbullet\ $N$] is the number of observations of $X$ and $Y$
\end{eqlist}

The standard deviation ($sd$ or $\sigma$) measures the amount of dispersion of the
possible values of a random variable around its expected value ($E$) (theoretical average).
\begin{equation}\label{eq:sd}
    \tag{Standard deviation}
    \begin{split}
        sd(X) & = \sqrt{E[X^2]-(E[X])^2} \\
              & = \sqrt{Var(X)}
    \end{split}
\end{equation}
where:
\quad\begin{eqlist}
    \item[\textbullet\ $X$] is a random variable
    \item[\textbullet\ ${E[X],E[X^2]}$] are respectively the expected values
        (or theoretical averages) of $X$ and $X^2$ (see \cref{eq:expectation})
\end{eqlist}

\begin{equation}\label{eq:expectation}
    \tag{Expectation}
    \begin{split}
        E[X] & = x_1p_1 + x_2p_2+ \cdot +x_kp_k \\
             & = \mathsf{weighted average}(X) \\
             & = \mu_X
    \end{split}
\end{equation}
where:%\\
\quad\begin{eqlist}
    \item[\textbullet\ $E$] is the expectation
    \item[\textbullet\ $X$] is a random variable
    \item[\textbullet\ $x_1$, $x_2$, \ldots, $x_k$] are possible value of $X$
    \item[\textbullet\ $p_1$, $p_2$, \ldots, $p_k$] are the probabilities of
        the different values of $X$ and their sum is equal to 1.
    \item[\textbullet\ $\mu_X$] is the theoretical average of X
\end{eqlist}

\begin{equation}\label{eq:variance}
    \tag{Variance}
    \begin{split}
        Var(X) & =  \frac{\sum{(x_{i}-\bar{x})^{2}}}{N-1} \\ & = sd^{2}(X)
    \end{split}
\end{equation}
where:
\quad\begin{eqlist}
    \item[\textbullet\ $X$] is a random variable
    \item[\textbullet\ $x$] is one observation of $X$
    \item[\textbullet\ $\bar{x}$] is the mean of all observed values of $X$
    \item[\textbullet\ $N$] is the number of observations of $X$
    \item[\textbullet\ $sd^2$] is another notation of the variance as
           the standard deviation is equal to the square root of the variance.
\end{eqlist}
