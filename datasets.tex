\chapter{Available high-throughput normal human Datasets}
\label{ch:datasets}

\begin{comment}
\setlength{\epigraphwidth}{0.57\textwidth}
\setlength{\epigraphrule}{0.1pt}
\epigraph{Data! Data! Data! I can’t make bricks without clay!}{Sherlock Homes
    (Sir Arthur Conan Doyle)}
\end{comment}

In the past few years, many laboratories studied the expression
of the genes within normal humans at the transcriptome and at
the proteome levels. In this chapter, I review the data I use within my thesis
and how it has been processed.

When not stated otherwise, all the computational processing of the \Rnaseq\ part
described here have been performed by myself under the supervision of
the Dr Alvis Brazma. I also received general feedback from Dr Mar Gonzalez-Portà,
Dr Johan Rung and Dr Nuno Fonseca. The proteome data has been processed by
Dr James Wright from the Wellcome Trust Sanger Institute.


\section{Introduction}

Every dataset with which I worked is fitting three main criteria.
First, they comprise human normal samples from at least three kinds of tissues.
Secondly, they are non-targeted high-throughput \ie\ gene expression
quantifications are based on \Rnaseq\ for the transcriptome or on \ms\ for the
proteome. These technologies allow in theory to study the whole repertoire of
\glspl{RNA} or proteins in a sample.
Finally, the \emph{raw} data is available and reusable.


\section{RNA-Seq Transcriptome data}

There are a few more studies that I wanted to use on the
transcriptomic side, but the reusability point was often the critical reason
why they have not been included.

Indeed, many times I encountered data with ambiguous encoding format
and, as the studies were a little bit outdated,
I was also unable to get the information from the original authors.
I describe hereafter the 5 transcriptomic datasets I used
in the chronological order of their first public release.
\Cref{tab:Trans5DF} summarises the main characteristics of the different
datasets.

\begin{sidewaystable}
           \centering
           \caption{\label{tab:Trans5DF}General description of the 5 transcriptomic
           dataset (\Rnaseq) used for this study}
       \begin{tabular}{@{}cccccccccc@{}}
       \toprule
       \multicolumn{1}{c|}
           {\multirow{2}{*}{ArrayExpress ID}} &
            \multicolumn{1}{c|}{\multirow{2}{*}{Data ID}} &
            \multicolumn{2}{c|}{\begin{tabular}[c]{@{}c@{}}Library\\Preparation\end{tabular}} &
            \multicolumn{2}{c|}{Sequencing} &
            \multicolumn{2}{c|}{Replicates} &
            \multicolumn{1}{c|}{\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Tissue\\
                    Number\end{tabular}}} &
            \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Multi-sampling\\ from the \\ same
            individual\end{tabular}} \\
            \cmidrule(lr){3-8}
            \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &
            \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Whole\\ RNA\end{tabular}} &
            \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}PolyA\\ selected\end{tabular}} &
            \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Single\\ end\end{tabular}} &
            \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Paired\\ end\end{tabular}} &
            \multicolumn{1}{c|}{Biological} & \multicolumn{1}{c|}{Technical} &
            \multicolumn{1}{c|}{} &  \\
       \midrule
       E-MTAB-305 & Castle & Y &  & Y &  &  &  & 11 &  \\
       E-GEOD-30352 & Brawand &  & Y & Y &  & Y &  & 8 &  \\
       E-MTAB-513 & IBM &  & Y & Y & Y &  & (Y) & 16 &  \\
       E-MTAB-2836 \footnotesize{(and E-MTAB-1733)}& Uhlén &  & Y &  & Y & Y & Y & 32 &  \\
       E-MTAB-2919 & Gtex (v4)  & Y &  &  & Y & Y &  & 54 & Y \\
       \bottomrule
       \end{tabular}
\end{sidewaystable}

\subsection{Castle et al. dataset}

This dataset has been published along with the \paper{\citetitle{castleData}}
by \citet{castleData} who were interested in exploring the whole RNA repertoire
with sequencing-based technology. They essentially focused their study
on the non-coding part.
\begin{comment}
    %following are results that I removed based on Isabelle suggestions
and found that
while \glspl{mRNA} could be highly tissue-specific, \glspl{ncRNA} have generally
greater tissue-specific expression patterns.
\end{comment}

They used multiple-donors pooled tissues samples %(purchased as total \gls{RNA})
and prepared the 11 libraries following a whole transcriptomic protocol
where nonribosomal \gls{RNA} transcripts are
specifically amplified by \gls{PCR} \citep{Armour:2009}.

They generated an average of 50 million sequence reads per tissue
using an Illumina Genome Analyser-II sequencer (single-end).
They trimmed their original reads to 28 \gls{nt}
and released them through EMBL archives (\ENA{ERP000257}
and \ArrayExpress{E-MTAB-305}).

Despite several limitations (lack of replicates, old technology, small reads),
I used this dataset for two main reasons. First, it is the oldest available
\Rnaseq\ data I found that was performed on Human normal tissues. Thus, the
results congruence of this dataset to the others gives a rough assessment about
the extent of \Rnaseq\ datasets that can be used in an atlas. Secondly as
\Rnaseq\ studies are prepared mainly with polyA-selected protocols nowadays,
I was interested to gauge how the library protocols --- and the presence of
\glspl{ncRNA} --- can affect the quantifications and then the final outcomes.


\subsection{Brawand et al. dataset}

In the corresponding article entitled \paper{\citetitle{VTpaper}},
\citet{VTpaper} focused their interest on the
evolution of the mammalian transcriptomes --- while there were existing studies
on the matter, the sequencing approach was then creating new perspectives.

They collected 6 organs from 10 different vertebrates:
9 mammalians (including Human) and a bird. They have two biological replicates
per tissue: one male and one female for every tissue but the testis (two males).
They used a polyA-selected protocol to prepare their 131 libraries (including 23
for \species{Homo sapiens}).
Hence, the samples are largely enriched in protein coding genes.

They generated an average of 3.2 billion reads of 76 base pairs per sample
using an Illumina Genome Analyser IIx (single-end) and they released them
through \gls{GEO} (accession number: GSE30352).
I personally retrieved the data from
\ArrayExpress{E-GEOD-30352}\footnote{ArrayExpress routinely imports
datasets from \gls{GEO} on a weekly basis.}.


\subsection{Illumina Body Map 2.0}
This dataset has been first created in 2010 and released in
2011\footnote{See: \citetitle{ibmEnsembl} - \cite{ibmEnsembl}} by Illumina
mostly to advertise its most recent technology improvement at that time:
the paired-end sequencing. Indeed, until then, all the sequencing was done
from only one end of the \gls{DNA} or \gls{cDNA} fragments.\footnote{From that
date, most of the following transcriptome studies based on \Rnaseq\ are using
paired-end sequencing.}

It comprises 16 tissues (one donor per tissue), which were prepared with a
polyA-selected library preparation protocol.

Although each sample has been sequenced twice and that we have in principle
\emph{technical} replicates, these are not ``regular'' technical
replicates. \emph{Technical} replicates,
by contrast to \emph{biological} replicates,
usually imply that their processing uses the same sample source and protocols.
Thus, the error and the noise due to a specific technique could be determined.
Here, however, each tissue has been sequenced once with a singled-end protocol
and once with a paired-end one.

The sequencing was performed with an Illumina HiSeq 2000 and the reads were
released through \ArrayExpress{E-MTAB-503} (\ENA{ERP000546}).

Despite the lack of biological replicates, I used this dataset as it was for an
extended time the most extensive freely available \Rnaseq\ dataset of human
tissues and such has been referenced many times since it was released.

\subsection{Uhlén et al. dataset}

Uhlén et al.\ have created an atlas,
\href{http://www.proteinatlas.org/}{Human Protein Atlas}\footnote{%
\href{http://www.proteinatlas.org/}{http://www.proteinatlas.org/}},
revolving mostly around the spatial
distribution of the proteins through the Human body. They use many approaches
and techniques which also include \Rnaseq. They first released their \Rnaseq\
data of 27 normal tissues as a part of their article \paper{\citetitle{Uhlen2014}}
\citep{Uhlen2014}. Later, they extended their dataset with new samples and 5 new
tissues. The latest version was published with \paper{\citetitle{Uhlen2015}}
\citep{Uhlen2015} in \textit{Science}.

There are \emph{technical} and --- at least two different --- \emph{biological}
replicates for the 32 tissues.
Except for a very small number, the tissues have both male and female donors.

The 200 libraries have been prepared following a polyA-selected protocol and
have been sequenced (paired-end) with an Illumina HiSeq 2000 or 2500. I started
to work with the first version (\ArrayExpress{E-MTAB-1733}) and then
with the extended version (\ArrayExpress{E-MTAB-2836}).

At the time of the redaction of this thesis, this dataset is the freely available
most important one either regarding the number of tissues
(see \Cref{tab:Trans5DF}) or the number of samples (see \Cref{tab:Lib5DF}).


\subsection{GTEx data}

The Genotype-Tissue Expression (\gls{GTEx}) project is funded by the \gls{NIH}
Common Fund and aims to establish a resource database and associated tissue bank
for the study of the relationship between genetic variation and gene expression
and other molecular phenotypes in multiple reference tissues. The project was first
explained in a paper from the \cite{GTEx2013}. It consists to quickly collect
many tissues from postmortem donors so genotype-tissue expression analyses could
be done, notably \gls{eQTL} variants studies which study the modulation
of \gls{RNA} expression in function of \glspl{SNP}. The results of the
analyses are released through the GTEx portal (%
\href{http://gtexportal.org}{http://gtexportal.org}). The issue 6235 of
\emph{Science} comprises
many articles from this project. The most relevant to my work is
\paper{\citetitle{GTExTranscript}} from \cite{GTExTranscript}. While they study
the landscape of expression through the different tissues across the donors, they
put emphasis on the variation inter- and intra-individuals across the tissues.

As the project is quite ambitious and the collection and sequencing of the samples
are taking time, several freezes of the data have been released. My work is
including samples up to the fourth release of the pilot phase (v4). This
release includes 54 tissue/cell types (53 normal and one tumoral)
collected on 551 individuals.
The 3,276 libraries were prepared from whole \gls{RNA} extracts and then sequenced
with a paired-end protocol on Illumina HiSeq 2000/2500 sequencers which produced
an average of 80 million reads.

The raw data is available for privacy reasons only through controlled access via
\dbGaP{phs000424.v4.p1} (access number specific to the version of the data I used
in my study). While getting access can take time, in principle every request for
academic research should be granted.

\section{Mass spectrometry Proteome data}

While the transcriptomic data was retrieved and then processed within the \EBI\
either by Dr Nuno Fonseca or myself, the proteomic data have been picked and
handled by Dr Jyoti Choudary and Dr James Wright from the Wellcome Trust
Sanger Institute.

Until a couple of years ago, compared to the transcriptome, the proteome world
was regrettably lacking on normal human tissues expression quantification
experiments. In fact, while there were human protein maps available
(\eg\ the \href{www.proteinatlas}{Human Proteome Map}%
\footnote{\href{http://www.proteinatlas.org}{www.proteinatlas.org}}), these
are mostly reporting the spatial expression of proteins (as they are based
on immunohistochemistry or other means of identification) than quantifying
their (non-targeted) abundance in each tissue.

Then, in 2014, two different groups of authors, \cite{PandeyData}
and \cite{KusterData}, published (in \textit{Nature},
issue 7502) their own \emph{``draft of the human proteome''}
based on the study of tissues with \ms. These two datasets complement a previous
smaller one that was publicly released but never published.

Hereafter, I present these 3 datasets that I use in my thesis.

\subsection{Pandey Lab data}

\cite{PandeyData} created the \href{http://www.humanproteomemap.org/}%
{Human Proteome Map}\footnote{%
\href{http://www.humanproteomemap.org/}{www.humanproteomemap.org}} which
they released along \paper{\citetitle{PandeyData}}.

For their study, they have processed 30 kinds of histological normal human
tissues and cell line samples (17 adult tissues, 7 fetal tissues and 6
haematopoietic cell types). The samples were created from pooled samples of three
individuals (generally two males and one female).

Then, they prepared their libraries with a label-free method to quantify
as many proteins they could. They fractionated the samples to protein level by
\gls{SDS-PAGE} and then at peptide level by \gls{RPLC} to create 85 experimental
samples. Finally, they use state-of-art \gls{MS/MS} protocols
(with high-resolution and high accuracy \glspl{FTMS}:
Thermo Scientific Orbitrap instruments).
They generated about 25 million of (\gls{HCD})
high-resolution mass spectra which account for 2,212 \gls{LC-MS/MS} profiles.

The raw spectra were retrieved from ProteomeXchange via the repository
\Pride{PXD000561}.

While their effort to generate high quality raw data was highly appraised
by the scientific community, their processing
(identification and quantification) methods were
criticised (see~\cite{Ezkurdia2014-qx}).

\subsection{Kuster data}

In their human proteome approach,
\cite{KusterData} combined newly generated \gls{LC-MS/MS} spectrum
data (about 40\%) with already published one
(either from their colleagues or accessible through repositories ---
for the remaining 60\%).
The data comprised 16,857 experiments involving tissues, body fluids and cell
lines. They used all the data they could access from \gls{PTM} to affinity
purification studies.

They reprocessed the whole collection of spectra to maximise proteome coverage
and make it available through their own repositories: ProteomicsDB\footnote{%
\href{https://www.proteomicsdb.org/}{www.proteomicsdb.org}}.

The subset of data considered in my thesis is also
known as the [protein] Human BodyMap which is the part that was primary generated
by the Kuster lab itself for this study. It corresponds to 1,087 \gls{LC-MS/MS}
profiles and comprises 48 experiments covering 36 tissues (adult and fetal) and
cell lines. Overall that represents about 14 million of (\gls{HCD}/\gls{CID})
spectra from Thermo Scientific instruments.

This raw data was downloaded from \Proteomicsdb{PRDB000042}.

\subsection{Cutler data}

This data was generated prior to the \dataset{Pandey} and the \dataset{Kuster}
data as it was released in 2011 through PeptideAtlas\footnote{%
\href{http://www.peptideatlas.org/}{www.peptideatlas.org}}
\citep{PeptideAtlas}.

It was created by Paul Cutler at Roche Pharmaceuticals.
It comprises 10 different tissues (1,618 \gls{CID} Thermo Scientific raw files).

While this data was never published on its own, it has been used in different
studies. Indeed, the \dataset{Cutler} data is one the datasets that
\cite{KusterData} are using in their original study to create ProteomicsDB.

The raw files were accessed and downloaded from \Proteomicsdb{PRDB000012}.

\section{Constant processing pipelines}

For many reasons, I only used data reprocessed from raw files despite many
ready available quantifications for most of the datasets.

In fact, the original authors often released
quantification either directly (\eg\ \cite{Krupp2012})
or only upon requests (\eg\ \cite{PandeyData}).
Third-parties could also distribute quantification of expression values either
from the original studies (\eg\ BioGPS \citep{BioGPS1} or
Harmonizome \citep{Harmonizome}) or
reprocessed from raw as EBI Gene Expression Atlas \citep{EBIgxa}\footnote{Actually,
nowadays, I would probably be able to use quantification data downloaded
from \EBI\ Gene Expression Atlas for most of the analyses of this study,}.
Unfortunately, when I started my study (and at the time of the redaction
of this thesis), the available \Rnaseq\ expression values of these studies
are the products of different methodologies, \eg\ \dataset{\Gtex}
data \citep{GTExTranscript} and \dataset{Castle} data \citep{Krupp2012}.

Intuitively, we expect that different processing protocols produce
different results.

Indeed, along my work, I noticed many potential bias sources that impact
\Rnaseq\ outputs. Many of them have since then been reported in the literature;
annotations \citep{annotationDiff},
contamination \citep{contaminationRNAseq},
quality controls \citep{qualityRNAseq} and
mapping and quantifications pipelines \citep{Fonseca2014}
have great effects on the final quantification. Finally, the normalisation
method of the quantified data also greatly impacts the final expression values
\citep{Dillies2013}, \citep{normalisation2}.

For all these reasons, reprocessing all the transcriptomic datasets was the
logical first step of this study.

Likewise, the proteomic datasets were reprocessed from the raw spectra by Dr
James Wright. Indeed, the many steps from peptide identifications to the
normalisation of the protein expression values can be (and have been) processed
with various methods and parameters.


\subsection{Transcriptome RNA-Seq raw data processing}

While I downloaded and entirely processed four of the transcriptomic datasets
myself (\dataset{Castle}, \dataset{Brawand}, \dataset{IBM} and \dataset{Uhlén}
data), it was not the case for the \Gtex\ dataset.

Since the \Gtex\ data is involved in many project within the \EBI\
and due to its huge amount of files (number and  size -- see \Cref{tab:Lib5DF}),
it was agreed that this would be processed centrally by one person and then
redistributed to all the other interested parties. Dr Nuno Fonseca had this
tremendous task and provided me with quantification data (produced with the
Human genome GRCh38 and ENSEMBL 76 annotation).

\begin{table}
\centering
\caption[Technical description of the 5 transcriptomic datasets]{%
\label{tab:Lib5DF}\textbf{Technical description of the 5 transcriptomic
    datasets}\\\footnotesize{I processed all the datasets but the one in
    \textit{\color{darkgray}italic}.\\
    For the Brawand dataset, I only processed the \species{Homo sapiens} part.}}
\begin{tabular}{@{}cccccc@{}}
\toprule
Dataset & \begin{tabular}[c]{@{}c@{}}Sample number\\(biologic)\end{tabular} &
\begin{tabular}[c]{@{}c@{}}Library\\number\end{tabular} &
\begin{tabular}[c]{@{}c@{}}File\\number\end{tabular} &
\begin{tabular}[c]{@{}c@{}}Total size of\\the fastq\\raw files (GB) \end{tabular}&
    \begin{tabular}[c]{@{}c@{}}Mean number of\\biologic samples per\\tissues
    [min,max]\end{tabular} \\
\midrule
Castle        & 11    & 11    & 11    & 58    & 10 (mixture)    \\
Brawand       & 18    & 21    & 23    & 111   & 2.8  [2,3]      \\
{\small Illumina Body Map} & 16    & 36    & 48    & 1,004  & 1 \\
Uhlén         & 122   & 200   & 400   & 1,851  & 3.81    [2,11] \\
    \textit{\color{darkgray}\Gtex\ (v4)}  &
    \textit{\color{darkgray}3,276}  & \textit{\color{darkgray}3,276}  &
    \textit{\color{darkgray}6,552}  &
    \textit{\color{darkgray}$\sim$ 50,000}  & \textit{\color{darkgray}60.67 [4,214]}\\
\bottomrule
\end{tabular}
\end{table}

For the sake of consistency and to avoid more biases \citep{h38vsh37},
that led me to reprocess all the other four \Rnaseq\ datasets
to comply with the reference used for the \Gtex\ samples\footnote{Actually,
as I had access to the different datasets through an extended period of
times, I produced results based on GRCh37 (for various annotations) for subset of
the datasets several times. The results series are congruent together.}.

Hence, unless indicated otherwise, the results presented in the current work are
from these genome reference and annotation version.

In the early stages of my research, I was processing each of the different steps
sequentially and semi-manually with the help of custom made scripts.
While the \EBI\ cluster greatly facilitated the handling of the numerous files,
the task was quite tedious: particularly due to the necessary jobs monitoring of
each step and the integrity checks of the intermediate files between them.
Additionally, although working perfectly within the \EBI\ infrastructure,
the scripts I wrote would need a fair amount of work to be usable elsewhere and
thus to achieve reproducibility.

Fortunately, Dr Nuno Fonseca developed and released a meta-pipeline:
\irap\footnote{https://nunofonseca.github.io/irap/}, an ``integrated RNA-seq
analysis Pipeline''. This tool allows
the automation of the typical (and state-of-the art) workflow to study
\Rnaseq. Apart of remarkably speeding up the data processing, it also
decreases the risk of inconstant parameters from one script to another.



Average Number of samples per tissues different => quantification averaged for
most of the analysis to avoid skewness.

I am using only gene levels quantification and not isoforms.




\begin{figure}
    \includegraphics[scale=0.75]{additional/pipelineTrans.pdf}\centering
    \caption[General steps for processing the transcriptomic
    data]{\label{fig:pipelineTrans}\textbf{General steps for processing the
    transcriptome} [TK]}
  \end{figure}


\subsection{Proteome raw data}

Similarly to the transcriptome issue, there is the proteome which is actually
trickier (possible problem with Pandey data analyses). Really depends which
threshold and \gls{FDR} tolerate. And what database and algorithm are used to perform
the identification of the proteins. More messy.

All the data has been processed by James.

Small problem about mapping back proteins to transcripts.



And again describe the methodology.

  \begin{figure}
      \includegraphics[scale=0.75]{additional/pipelineProteins.pdf}\centering
      \caption[General steps for processing the proteome
      data]{\label{fig:pipelineProt}\textbf{General steps for processing the
      proteome} [TK] }
  \end{figure}



\begin{comment}
They found that almost half of the proteins are expressed in all analysed tissues
(with an enrichment for the metabolism enzymes).
\end{comment}
